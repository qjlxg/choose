import scrapy
import pandas as pd
import json
import re

# å¯¼å…¥å¿…è¦çš„Firebase Firestoreæ¨¡å—
from firebase_admin import credentials, firestore, initialize_app

# è¯·ç¡®ä¿ä½ å·²ç»é€šè¿‡ `pip install firebase-admin pandas lxml html5lib` å®‰è£…äº†æ‰€æœ‰ä¾èµ–åº“ã€‚

# Firestoreæ•°æ®åº“åˆå§‹åŒ–
# è¿™é‡Œçš„__firebase_configå’Œ__app_idæ˜¯æ¥è‡ªCanvasç¯å¢ƒçš„å…¨å±€å˜é‡
# å¦‚æœåœ¨æœ¬åœ°æµ‹è¯•ï¼Œè¯·æ›¿æ¢ä¸ºä½ çš„Firebaseé…ç½®
firebase_config = json.loads(__firebase_config)
cred = credentials.Certificate(firebase_config)
app = initialize_app(cred)
db = firestore.client()

class FundSpider(scrapy.Spider):
    name = 'fund_spider'

    # åŸºé‡‘ä»£ç ã€å¹´ä»½å’Œå­£åº¦åˆ—è¡¨ï¼Œç”¨äºç”Ÿæˆçˆ¬å–ä»»åŠ¡
    # ä½ å¯ä»¥æ ¹æ®éœ€è¦ä¿®æ”¹è¿™äº›åˆ—è¡¨
    fund_list = ['017836', '020398', '000001']
    years_to_scrape = [2023, 2024, 2025]
    quarters_to_scrape = [1, 2, 3, 4]

    def start_requests(self):
        """
        ç”Ÿæˆæ‰€æœ‰åŸºé‡‘ã€å¹´ä»½å’Œå­£åº¦çš„çˆ¬å–è¯·æ±‚ã€‚
        """
        for fund_code in self.fund_list:
            for year in self.years_to_scrape:
                for quarter in self.quarters_to_scrape:
                    # æ„é€ åŒ…å«å¹´ä»½å’Œå­£åº¦çš„URLï¼Œä»¥è·å–å®Œæ•´çš„æŒä»“æ•°æ®
                    url = f'http://fundf10.eastmoney.com/FundArchivesDatas.aspx?type=jjcc&code={fund_code}&topline=10&year={year}&quarter={quarter}'
                    
                    # é™„å¸¦å…ƒæ•°æ®ï¼Œä»¥ä¾¿åœ¨å›è°ƒå‡½æ•°ä¸­è¯†åˆ«
                    yield scrapy.Request(url, self.parse, meta={'fund_code': fund_code, 'year': year, 'quarter': quarter})

    def parse(self, response):
        """
        è§£æç½‘é¡µå“åº”ï¼Œæå–åŸºé‡‘æŒä»“æ•°æ®ã€‚
        """
        fund_code = response.meta['fund_code']
        year = response.meta['year']
        quarter = response.meta['quarter']

        try:
            # ç½‘é¡µå†…å®¹æ˜¯ä¸€ä¸ªJavaScriptå˜é‡ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–
            content_match = re.search(r'var apidata = { content:"(.*)"', response.text, re.S)
            if not content_match:
                self.log(f'â„¹ï¸ è­¦å‘Šï¼šæœªåœ¨å“åº”ä¸­æ‰¾åˆ°åŸºé‡‘ {fund_code} åœ¨ {year} å¹´ç¬¬ {quarter} å­£åº¦çš„æ•°æ®å†…å®¹ã€‚')
                return

            html_content = content_match.group(1)
            
            # ä½¿ç”¨pandasçš„read_htmlå‡½æ•°è§£æHTMLè¡¨æ ¼
            # lxmlå’Œhtml5libæ˜¯å¯é€‰çš„è§£æå™¨ï¼Œå¦‚æœå‡ºç°é”™è¯¯ï¼Œè¯·ç¡®ä¿å·²å®‰è£…
            dfs = pd.read_html(html_content, parser='lxml')
            
            if dfs:
                df = dfs[0]

                # æ•°æ®æ¸…æ´—ä¸é‡æ„
                df.columns = [col[0] if isinstance(col, tuple) else col for col in df.columns]
                df = df.iloc[:, 1:] # ç§»é™¤"åºå·"åˆ—
                df.insert(0, 'åŸºé‡‘ä»£ç ', fund_code)
                df.insert(1, 'å¹´ä»½', year)
                df.insert(2, 'å­£åº¦', quarter)

                # å°†æ•°æ®è½¬æ¢ä¸ºJSONæ ¼å¼
                data_records = df.to_dict('records')
                
                # å°†æ•°æ®ä¿å­˜åˆ°Firestore
                collection_path = f'artifacts/{__app_id}/public/data/fund_holdings'
                for record in data_records:
                    doc_ref = db.collection(collection_path).add(record)
                    self.log(f'ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ° Firestore: {doc_ref.id}')

                self.log(f'âœ… æˆåŠŸè·å–åŸºé‡‘ {fund_code} åœ¨ {year} å¹´ç¬¬ {quarter} å­£åº¦çš„æŒä»“æ•°æ®ï¼Œè®°å½•æ•°ï¼š{len(df)}')
            else:
                self.log(f'â„¹ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°åŸºé‡‘ {fund_code} åœ¨ {year} å¹´ç¬¬ {quarter} å­£åº¦çš„æ•°æ®è¡¨æ ¼')

        except Exception as e:
            self.log(f'âŒ é”™è¯¯ - åŸºé‡‘ {fund_code}, å¹´ä»½ {year}, å­£åº¦ {quarter}: {e}')
