# -*- coding: utf-8 -*-
import scrapy
import pandas as pd
import re
import os

class FundSpider(scrapy.Spider):
    name = 'fund_earning'

    start_urls = [
        'http://fund.eastmoney.com/data/fundranking.html#tall;cgt;r;zsd;p;st;r;tt;1;;2;20'
    ]

    # åŸºé‡‘ä»£ç å’Œå¹´ä»½çš„åˆ—è¡¨ï¼Œå¯ä»¥æ ¹æ®éœ€è¦è‡ªå®šä¹‰
    # ç¤ºä¾‹: [(åŸºé‡‘ä»£ç , å¹´ä»½)]
    funds_to_scrape = [
        ('017836', 2025),
        ('020398', 2023),
        ('020398', 2024),
        ('020398', 2025),
        ('017836', 2024),
        ('017836', 2023)
    ]

    def parse(self, response):
        """
        è¿™ä¸ªæ–¹æ³•å°†ä¸å†ç”¨äºç›´æ¥çˆ¬å–åŸºé‡‘æ’åï¼Œè€Œæ˜¯ç”ŸæˆæŒä»“æ•°æ®çš„è¯·æ±‚ã€‚
        """
        for fund_code, year in self.funds_to_scrape:
            # è®¿é—®åŸºé‡‘æŒä»“è¯¦æƒ…é¡µé¢ï¼Œè¿™é‡Œé€šè¿‡ä¿®æ”¹ URL å‚æ•°æ¥è·å–å®Œæ•´çš„æŒä»“æ•°æ®
            # ç§»é™¤ topline å‚æ•°ï¼Œæˆ–è€…å°†å®ƒçš„å€¼è®¾ç½®å¾—è¶³å¤Ÿå¤§ï¼Œä¾‹å¦‚ 1000
            url = f'http://fundf10.eastmoney.com/FundArchivesDatas.aspx?type=jjcc&code={fund_code}&year={year}&topline=1000'
            yield scrapy.Request(url, callback=self.parse_fund_data, meta={'fund_code': fund_code, 'year': year})

    def parse_fund_data(self, response):
        """
        è§£æåŸºé‡‘æŒä»“æ•°æ®ã€‚
        """
        fund_code = response.meta['fund_code']
        year = response.meta['year']

        try:
            # ä»å“åº”æ–‡æœ¬ä¸­æå– var apidata = { ... } éƒ¨åˆ†
            data_str = re.search(r'var apidata=\{ content:\"(.*?)\",', response.text, re.DOTALL).group(1)
            
            # ä½¿ç”¨ pandas è¯»å– HTML è¡¨æ ¼ã€‚è¿™é‡Œéœ€è¦ html5lib ä¾èµ–ã€‚
            # è§£å†³ 'Missing optional dependency 'html5lib'' é”™è¯¯
            tables = pd.read_html(data_str, encoding='utf-8')
            
            if not tables:
                self.logger.info(f'âŒ æœªæ‰¾åˆ°æ•°æ®è¡¨ - åŸºé‡‘ {fund_code}, å¹´ä»½ {year}')
                return

            # è§£æå¹¶ä¿å­˜æ¯ä¸ªå­£åº¦çš„æŒä»“æ•°æ®
            for i, df in enumerate(tables):
                # å­£åº¦ä¿¡æ¯é€šå¸¸åœ¨è¡¨æ ¼ä¸Šæ–¹
                quarter_info = re.findall(r'(\d{4}å¹´\då­£åº¦)', data_str)[i] if len(re.findall(r'(\d{4}å¹´\då­£åº¦)', data_str)) > i else f'ç¬¬{i+1}å­£åº¦'
                
                # ç¡®ä¿ DataFrame åŒ…å«æˆ‘ä»¬éœ€è¦çš„åˆ—ï¼Œå¹¶è¿›è¡Œæ¸…ç†
                if 'è‚¡ç¥¨ä»£ç ' in df.columns and 'å å‡€å€¼æ¯”ä¾‹' in df.columns:
                    # è·å–åŸºé‡‘åç§°å’ŒåŸºé‡‘ä»£ç 
                    fund_name_match = re.search(r'([\u4e00-\u9fa5]+)\s+ç¬¬', data_str)
                    fund_name = fund_name_match.group(1) if fund_name_match else fund_code

                    # ä¸ºæ•°æ®æ·»åŠ å¹´ä»½å’Œå­£åº¦ä¿¡æ¯
                    df['åŸºé‡‘ä»£ç '] = fund_code
                    df['åŸºé‡‘åç§°'] = fund_name
                    df['å¹´ä»½'] = year
                    df['å­£åº¦'] = quarter_info
                    
                    # æ¸…ç†åˆ—åä¸­çš„ç©ºæ ¼
                    df.columns = df.columns.str.replace(r'\s+','', regex=True)
                    
                    # å®šä¹‰ä¿å­˜è·¯å¾„å’Œæ–‡ä»¶å
                    # ä¾‹å¦‚: fund_data/æŒä»“_017836_2025_4å­£åº¦.csv
                    filename = os.path.join('fund_data', f'æŒä»“_{fund_code}_{year}_{quarter_info}.csv')

                    # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
                    if not os.path.exists('fund_data'):
                        os.makedirs('fund_data')

                    # å°†æ•°æ®ä¿å­˜ä¸º CSV æ–‡ä»¶
                    df.to_csv(filename, index=False, encoding='utf-8-sig')
                    self.logger.info(f'âœ… æˆåŠŸè·å–åŸºé‡‘ {fund_code} åœ¨ {quarter_info} çš„æŒä»“æ•°æ®ï¼Œè®°å½•æ•°ï¼š{len(df)}')
                    self.logger.info(f'ğŸ’¾ æ•°æ®å·²ä¿å­˜: {filename}')
                else:
                    self.logger.warning(f'âš ï¸ è¡¨æ ¼ç»“æ„ä¸åŒ¹é…ï¼Œæ— æ³•è§£ææŒä»“æ•°æ® - åŸºé‡‘ {fund_code}, å¹´ä»½ {year}, è¡¨ {i+1}')
            
        except Exception as e:
            self.logger.error(f'âŒ æœªçŸ¥é”™è¯¯ - åŸºé‡‘ {fund_code}, å¹´ä»½ {year}: {e}')
            self.logger.info('ğŸ’¡ æç¤º: å¦‚æœä½ çœ‹åˆ° "Missing optional dependency \'html5lib\'" é”™è¯¯ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š')
            self.logger.info('pip install html5lib')
            self.logger.info('pip install lxml')
