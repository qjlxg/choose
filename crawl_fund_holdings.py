# -*- coding: utf-8 -*-
"""
ä¸€ä¸ªç”¨äºçˆ¬å–å¤©å¤©åŸºé‡‘ç½‘å…¨å¸‚åœºåŸºé‡‘æŒä»“æ•°æ®çš„Pythonè„šæœ¬
ç»ˆæä¿®å¤ç‰ˆï¼šé’ˆå¯¹GitHub Actionsç¯å¢ƒçš„æ·±åº¦ä¼˜åŒ–
"""
import os
import time
import requests
import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException, StaleElementReferenceException
from bs4 import BeautifulSoup
import logging
import random
from typing import List, Dict, Optional, Tuple
import json

# --- é…ç½®æ—¥å¿—ç³»ç»Ÿï¼ˆè¯¦ç»†ç‰ˆï¼‰ ---
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('crawler.log', encoding='utf-8')
    ]
)

# --- è§£æMarkdownæ–‡ä»¶ ---
def parse_markdown_file(file_path: str) -> List[Dict[str, str]]:
    """è§£æMarkdownæ–‡ä»¶ï¼Œæå–åŸºé‡‘ä»£ç ã€‚"""
    if not os.path.exists(file_path):
        logging.error(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return []
    
    fund_codes = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        lines = content.strip().split('\n')
        for line in lines:
            if '| è¡ŒåŠ¨ä¿¡å·' in line:
                continue
            
            parts = [p.strip() for p in line.split('|')]
            if len(parts) >= 9:
                fund_code = parts[1]
                action_signal = parts[8].lower()

                if "å¼±ä¹°å…¥" in action_signal or "å¼ºä¹°å…¥" in action_signal:
                    fund_codes.append({'code': fund_code, 'name': 'N/A'})
        
        logging.info(f"âœ… æå– {len(fund_codes)} ä¸ªåŸºé‡‘ä»£ç ")
        return fund_codes

    except Exception as e:
        logging.error(f"âŒ Markdownè§£æé”™è¯¯: {e}")
        return []

# --- è‚¡ç¥¨ä¿¡æ¯ç¼“å­˜ ---
stock_info_cache = {}

# --- å¢å¼ºUser-Agentæ±  ---
user_agent_pool = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/121.0",
]

# --- ä¿®å¤ï¼šè·å–è‚¡ç¥¨ä¿¡æ¯ï¼ˆé™çº§ç­–ç•¥ï¼‰ ---
def get_stock_info(stock_code: str) -> Dict[str, str]:
    """è·å–è‚¡ç¥¨è¡Œä¸šå’Œæ¦‚å¿µä¿¡æ¯ï¼Œæ”¯æŒé™çº§ç­–ç•¥ã€‚"""
    if not stock_code or stock_code == '':
        return {'æ‰€å±è¡Œä¸š': 'æœªçŸ¥', 'æ¦‚å¿µä¸»é¢˜': 'æœªçŸ¥'}
    
    if stock_code in stock_info_cache:
        return stock_info_cache[stock_code]
    
    info = {'æ‰€å±è¡Œä¸š': 'æœªçŸ¥', 'æ¦‚å¿µä¸»é¢˜': 'æœªçŸ¥'}
    
    if not re.match(r'^\d{6}$', stock_code):
        stock_info_cache[stock_code] = info
        return info
    
    # é™çº§ç­–ç•¥1ï¼šä½¿ç”¨é›ªçƒAPIï¼ˆæ›´ç¨³å®šï¼‰
    try:
        snowball_url = f"https://stock.xueqiu.com/v5/stock/quote.json?symbol={stock_code}&extend=detail"
        headers = {
            "User-Agent": random.choice(user_agent_pool),
            "Accept": "application/json",
            "Referer": "https://xueqiu.com/",
        }
        
        response = requests.get(snowball_url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if 'data' in data and 'items' in data['data'] and data['data']['items']:
                item = data['data']['items'][0]
                if 'industry' in item:
                    info['æ‰€å±è¡Œä¸š'] = item['industry']
                if 'concept' in item:
                    info['æ¦‚å¿µä¸»é¢˜'] = ', '.join(item['concept'][:5])
                stock_info_cache[stock_code] = info
                logging.debug(f"âœ… é›ªçƒAPI: {stock_code} -> {info['æ‰€å±è¡Œä¸š']}")
                return info
    except Exception as e:
        logging.debug(f"é›ªçƒAPIå¤±è´¥ {stock_code}: {e}")
    
    # é™çº§ç­–ç•¥2ï¼šä½¿ç”¨ä¸œæ–¹è´¢å¯Œç§»åŠ¨ç«¯ï¼ˆæ›´ç¨³å®šï¼‰
    try:
        if stock_code.startswith(('60', '68', '69')):
            market = 'sh'
        else:
            market = 'sz'
        
        em_url = f"https://push2.eastmoney.com/api/qt/stock/details/get?secid={market}{stock_code}"
        headers = {
            "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15",
            "Referer": "https://quote.eastmoney.com/",
        }
        
        response = requests.get(em_url, headers=headers, timeout=8)
        if response.status_code == 200:
            data = response.json()
            if 'data' in data:
                # å°è¯•ä»APIå“åº”ä¸­æå–è¡Œä¸šä¿¡æ¯
                if 'industry' in data['data']:
                    info['æ‰€å±è¡Œä¸š'] = data['data']['industry']
                stock_info_cache[stock_code] = info
                logging.debug(f"âœ… EMç§»åŠ¨ç«¯: {stock_code} -> {info['æ‰€å±è¡Œä¸š']}")
                return info
    except Exception as e:
        logging.debug(f"EMç§»åŠ¨ç«¯å¤±è´¥ {stock_code}: {e}")
    
    # é™çº§ç­–ç•¥3ï¼šä½¿ç”¨é»˜è®¤åˆ†ç±»
    try:
        if stock_code.startswith('60'):
            info['æ‰€å±è¡Œä¸š'] = 'æ²ªä¸»æ¿-ä¼ ç»Ÿè¡Œä¸š'
        elif stock_code.startswith('68'):
            info['æ‰€å±è¡Œä¸š'] = 'ç§‘åˆ›æ¿-ç§‘æŠ€æˆé•¿'
        elif stock_code.startswith('30'):
            info['æ‰€å±è¡Œä¸š'] = 'æ·±åˆ›ä¸šæ¿-æˆé•¿å‹'
        elif stock_code.startswith('00'):
            info['æ‰€å±è¡Œä¸š'] = 'æ·±ä¸»æ¿-æˆç†Ÿä¼ä¸š'
        elif stock_code.startswith('002'):
            info['æ‰€å±è¡Œä¸š'] = 'æ·±ä¸­å°æ¿-ä¸­å°å‹ä¼ä¸š'
        else:
            info['æ‰€å±è¡Œä¸š'] = 'å…¶ä»–æ¿å—'
        
        stock_info_cache[stock_code] = info
        logging.debug(f"âœ… é»˜è®¤åˆ†ç±»: {stock_code} -> {info['æ‰€å±è¡Œä¸š']}")
    except Exception as e:
        logging.debug(f"é»˜è®¤åˆ†ç±»å¤±è´¥ {stock_code}: {e}")
    
    time.sleep(random.uniform(0.1, 0.3))  # æœ€å°å»¶æ—¶
    return info

# --- é…ç½®Seleniumï¼ˆGitHub Actionsä¼˜åŒ–ï¼‰ ---
def setup_driver() -> Optional[webdriver.Chrome]:
    """é…ç½®ChromeDriverï¼Œé’ˆå¯¹GitHub Actionsç¯å¢ƒä¼˜åŒ–ã€‚"""
    logging.info("ğŸ”§ é…ç½®ChromeDriver...")
    try:
        chrome_options = Options()
        
        # GitHub Actionsç‰¹å®šé…ç½®
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-images')
        chrome_options.add_argument('--disable-javascript')  # å…³é”®ï¼šç¦ç”¨JSå‡å°‘åçˆ¬
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        
        # åæ£€æµ‹é…ç½®
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # æ€§èƒ½ä¼˜åŒ–
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--allow-running-insecure-content')
        chrome_options.add_argument('--disable-features=VizDisplayCompositor')
        
        # GitHub Actionsè·¯å¾„
        chromedriver_path = '/usr/bin/chromedriver'
        service = Service(chromedriver_path)
        
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        # éšè—webdriverå±æ€§
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
        driver.set_page_load_timeout(45)
        driver.implicitly_wait(8)
        
        logging.info("âœ… ChromeDriverå¯åŠ¨æˆåŠŸ")
        return driver
        
    except WebDriverException as e:
        logging.error(f"âŒ ChromeDriverå¯åŠ¨å¤±è´¥: {e}")
        return None

# --- å¢å¼ºï¼šç­‰å¾…æ•°æ®åŠ è½½ï¼ˆå¤šç­–ç•¥ï¼‰ ---
def wait_for_data_load(driver: webdriver.Chrome, fund_code: str, timeout: int = 45) -> bool:
    """å¤šç­–ç•¥ç­‰å¾…æ•°æ®åŠ è½½å®Œæˆ"""
    logging.info(f"â³ ç­‰å¾…æ•°æ®åŠ è½½ (åŸºé‡‘ {fund_code})...")
    
    start_time = time.time()
    max_wait = timeout
    
    while time.time() - start_time < max_wait:
        try:
            # ç­–ç•¥1ï¼šç­‰å¾…å¹´ä»½é€‰æ‹©å™¨å¡«å……
            select_elem = WebDriverWait(driver, 5).until(
                EC.presence_of_element_located((By.ID, "jjcc"))
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰option
            options = driver.find_elements(By.CSS_SELECTOR, "#jjcc option")
            if len(options) > 1:
                logging.info(f"âœ… æ‰¾åˆ° {len(options)-1} ä¸ªå¹´ä»½é€‰é¡¹")
                return True
            
            # ç­–ç•¥2ï¼šæ£€æŸ¥è¡¨æ ¼æ˜¯å¦è¿˜åœ¨åŠ è½½
            cctable = driver.find_element(By.ID, "cctable")
            if "æ•°æ®åŠ è½½ä¸­" not in cctable.text:
                # æ£€æŸ¥æ˜¯å¦æœ‰è¡¨æ ¼è¡Œ
                rows = driver.find_elements(By.CSS_SELECTOR, "#cctable tr")
                if len(rows) > 1:
                    logging.info(f"âœ… è¡¨æ ¼åŠ è½½å®Œæˆï¼Œ{len(rows)-1} è¡Œæ•°æ®")
                    return True
            
            # ç­–ç•¥3ï¼šæ£€æŸ¥pagebaræ˜¯å¦åŠ è½½
            pagebar = driver.find_element(By.ID, "pagebar")
            if pagebar.text.strip():
                logging.info("âœ… åˆ†é¡µæ§ä»¶å·²åŠ è½½")
                return True
                
        except TimeoutException:
            pass
        except Exception as e:
            logging.debug(f"ç­‰å¾…æ£€æŸ¥å¼‚å¸¸: {e}")
        
        # åŠ¨æ€ç­‰å¾…
        elapsed = time.time() - start_time
        remaining = max_wait - elapsed
        wait_time = min(3, remaining / 3)  # è‡ªé€‚åº”ç­‰å¾…
        time.sleep(wait_time)
    
    logging.warning(f"âš ï¸  æ•°æ®åŠ è½½è¶…æ—¶ ({timeout}s)")
    return False

# --- ä¿®å¤ï¼šæ™ºèƒ½å¹´ä»½é€‰æ‹©ï¼ˆå¢å¼ºç‰ˆï¼‰ ---
def select_year_intelligently(driver: webdriver.Chrome, target_year: str) -> Tuple[bool, str]:
    """æ™ºèƒ½é€‰æ‹©å¹´ä»½ï¼Œæ”¯æŒå¤šç§é€‰æ‹©å™¨"""
    try:
        logging.info(f"ğŸ¯ é€‰æ‹©å¹´ä»½: {target_year}")
        
        # ç­‰å¾…é€‰æ‹©å™¨å‡ºç°
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.ID, "jjcc"))
        )
        
        # å¤šç§ç­‰å¾…ç­–ç•¥
        max_attempts = 3
        for attempt in range(max_attempts):
            try:
                # ç­–ç•¥1ï¼šç›´æ¥æŸ¥æ‰¾option
                options = driver.find_elements(By.CSS_SELECTOR, "#jjcc option")
                available_years = []
                
                for option in options:
                    option_text = option.text.strip()
                    year_match = re.search(r'(\d{4})', option_text)
                    if year_match:
                        available_years.append(year_match.group(1))
                
                if available_years:
                    logging.info(f"ğŸ“‹ æ‰¾åˆ°å¹´ä»½: {available_years}")
                    
                    # æ™ºèƒ½åŒ¹é…
                    target_int = int(target_year)
                    selected_year = None
                    
                    # ç²¾ç¡®åŒ¹é…
                    for year in [str(target_int), str(target_int-1), str(target_int-2)]:
                        if year in available_years:
                            selected_year = year
                            break
                    
                    # æœ€è¿‘å¹´ä»½
                    if not selected_year:
                        selected_year = max(available_years, key=lambda x: int(x))
                    
                    # æ‰§è¡Œé€‰æ‹©
                    select_elem = driver.find_element(By.ID, "jjcc")
                    option_index = available_years.index(selected_year)
                    
                    # JavaScripté€‰æ‹©
                    driver.execute_script(f"""
                        var select = document.getElementById('jjcc');
                        select.selectedIndex = {option_index};
                        select.dispatchEvent(new Event('change', {{bubbles: true}}));
                    """)
                    
                    logging.info(f"âœ… é€‰æ‹©æˆåŠŸ: {selected_year}")
                    time.sleep(3)
                    return True, selected_year
                
                # ç­–ç•¥2ï¼šå¦‚æœæ²¡æœ‰optionï¼Œå°è¯•ç‚¹å‡»å…¶ä»–æ§ä»¶
                logging.info(f"å°è¯•ç­–ç•¥ {attempt+1}: æŸ¥æ‰¾å…¶ä»–å¹´ä»½æ§ä»¶")
                
                # æŸ¥æ‰¾å¯èƒ½çš„å¹´ä»½æŒ‰é’®
                year_selectors = [
                    "//label[contains(text(), '202')]",
                    "//div[contains(@class, 'year')]//a[contains(text(), '202')]",
                    "//input[contains(@value, '202')]",
                    ".year-tab a",
                    "[data-year]",
                ]
                
                for selector in year_selectors:
                    try:
                        elements = driver.find_elements(By.XPATH, selector)
                        for element in elements:
                            if element.is_displayed() and element.is_enabled():
                                year_text = element.text.strip()
                                year_match = re.search(r'(\d{4})', year_text)
                                if year_match and str(year_match.group(1)) == target_year:
                                    driver.execute_script("arguments[0].click();", element)
                                    logging.info(f"âœ… ç‚¹å‡»å¹´ä»½æŒ‰é’®: {year_text}")
                                    time.sleep(4)
                                    return True, target_year
                    except:
                        continue
                
            except Exception as e:
                logging.debug(f"å¹´ä»½é€‰æ‹©å°è¯• {attempt+1} å¤±è´¥: {e}")
                time.sleep(2)
        
        logging.error("âŒ æ‰€æœ‰å¹´ä»½é€‰æ‹©ç­–ç•¥å¤±è´¥")
        return False, "é€‰æ‹©å¤±è´¥"
        
    except Exception as e:
        logging.error(f"âŒ å¹´ä»½é€‰æ‹©å¼‚å¸¸: {e}")
        return False, str(e)

# --- å¢å¼ºï¼šè§£ææŒä»“è¡¨æ ¼ï¼ˆæ”¯æŒå½“å‰é¡µé¢ï¼‰ ---
def parse_current_holdings(driver: webdriver.Chrome, fund_code: str, default_year: str = None) -> List[Dict]:
    """è§£æå½“å‰æ˜¾ç¤ºçš„æŒä»“æ•°æ®ï¼ˆå¤‡ç”¨ç­–ç•¥ï¼‰"""
    try:
        logging.info("ğŸ“‹ è§£æå½“å‰é¡µé¢æŒä»“æ•°æ®...")
        
        # ç­‰å¾…è¡¨æ ¼åŠ è½½
        WebDriverWait(driver, 15).until(
            EC.presence_of_element_located((By.ID, "cctable"))
        )
        
        # é¢å¤–ç­‰å¾…
        time.sleep(3)
        
        # è·å–é¡µé¢æºç 
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'lxml')
        
        # æŸ¥æ‰¾è¡¨æ ¼
        cctable = soup.find(id="cctable")
        if not cctable:
            logging.warning("æœªæ‰¾åˆ°cctable")
            return []
        
        # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨åŠ è½½
        if "æ•°æ®åŠ è½½ä¸­" in cctable.text:
            logging.warning("è¡¨æ ¼ä»åœ¨åŠ è½½")
            return []
        
        holdings = []
        rows = cctable.find_all('tr')
        
        if len(rows) <= 1:
            # å°è¯•å…¶ä»–ç»“æ„
            table_divs = cctable.find_all('div', class_=re.compile(r'table|grid|row'))
            if table_divs:
                logging.info(f"ä½¿ç”¨divç»“æ„ï¼Œæ‰¾åˆ° {len(table_divs)} ä¸ªå…ƒç´ ")
                for div in table_divs[:30]:  # é™åˆ¶æ•°é‡
                    cols = div.find_all(['td', 'div', 'span'])
                    if len(cols) >= 4:
                        try:
                            # æå–è‚¡ç¥¨ä»£ç 
                            stock_code = ''
                            for col in cols[1:3]:
                                col_text = col.text.strip()
                                code_match = re.search(r'(\d{6})', col_text)
                                if code_match:
                                    stock_code = code_match.group(1)
                                    break
                            
                            if stock_code:
                                stock_name = cols[2].text.strip() if len(cols) > 2 else ''
                                stock_info = get_stock_info(stock_code)
                                
                                data = {
                                    'åŸºé‡‘ä»£ç ': fund_code,
                                    'å¹´ä»½': default_year or 'å½“å‰å¹´ä»½',
                                    'è‚¡ç¥¨ä»£ç ': stock_code,
                                    'è‚¡ç¥¨åç§°': stock_name,
                                    'æ‰€å±è¡Œä¸š': stock_info['æ‰€å±è¡Œä¸š'],
                                    'æ¦‚å¿µä¸»é¢˜': stock_info['æ¦‚å¿µä¸»é¢˜'],
                                    'æŒä»“å æ¯”': cols[3].text.strip() if len(cols) > 3 else '',
                                    'æŒè‚¡æ•°': cols[4].text.strip() if len(cols) > 4 else '',
                                    'å¸‚å€¼': cols[5].text.strip() if len(cols) > 5 else '',
                                    'æŠ¥å‘Šæ—¥æœŸ': cols[0].text.strip() if len(cols) > 0 else ''
                                }
                                holdings.append(data)
                        except Exception as e:
                            continue
            else:
                logging.warning("æœªæ‰¾åˆ°è¡¨æ ¼æ•°æ®")
                return []
        else:
            # æ ‡å‡†è¡¨æ ¼ç»“æ„
            logging.info(f"ä½¿ç”¨tableç»“æ„ï¼Œæ‰¾åˆ° {len(rows)-1} è¡Œæ•°æ®")
            for row in rows[1:]:
                cols = row.find_all('td')
                if len(cols) >= 4:
                    try:
                        # æå–è‚¡ç¥¨ä»£ç 
                        stock_code = ''
                        for col in cols[1:3]:
                            col_text = col.text.strip()
                            code_match = re.search(r'(\d{6})', col_text)
                            if code_match:
                                stock_code = code_match.group(1)
                                break
                        
                        if stock_code:
                            stock_name = cols[2].text.strip() if len(cols) > 2 else ''
                            stock_info = get_stock_info(stock_code)
                            
                            data = {
                                'åŸºé‡‘ä»£ç ': fund_code,
                                'å¹´ä»½': default_year or 'å½“å‰å¹´ä»½',
                                'è‚¡ç¥¨ä»£ç ': stock_code,
                                'è‚¡ç¥¨åç§°': stock_name,
                                'æ‰€å±è¡Œä¸š': stock_info['æ‰€å±è¡Œä¸š'],
                                'æ¦‚å¿µä¸»é¢˜': stock_info['æ¦‚å¿µä¸»é¢˜'],
                                'æŒä»“å æ¯”': cols[3].text.strip() if len(cols) > 3 else '',
                                'æŒè‚¡æ•°': cols[4].text.strip() if len(cols) > 4 else '',
                                'å¸‚å€¼': cols[5].text.strip() if len(cols) > 5 else '',
                                'æŠ¥å‘Šæ—¥æœŸ': cols[0].text.strip() if len(cols) > 0 else ''
                            }
                            holdings.append(data)
                    except Exception as e:
                        logging.debug(f"è¡Œè§£æå¤±è´¥: {e}")
                        continue
        
        logging.info(f"âœ… å½“å‰é¡µé¢è§£æ: {len(holdings)} æ¡è®°å½•")
        return holdings
        
    except Exception as e:
        logging.error(f"å½“å‰é¡µé¢è§£æå¤±è´¥: {e}")
        return []

# --- ç»ˆæä¿®å¤ï¼šçˆ¬å–åŸºé‡‘æŒä»“ ---
def get_fund_holdings(driver: webdriver.Chrome, fund_code: str, years_to_crawl: List[str], max_retries: int = 3) -> pd.DataFrame:
    """ç»ˆæä¿®å¤ç‰ˆï¼šå¤šç­–ç•¥æ•°æ®è·å–"""
    if driver is None:
        logging.error("âŒ WebDriveræ— æ•ˆ")
        return pd.DataFrame()

    fund_holdings = []
    base_url = f"https://fundf10.eastmoney.com/ccmx_{fund_code}.html"
    logging.info(f"ğŸŒ è®¿é—®: {base_url}")

    # é¡µé¢åŠ è½½
    for attempt in range(max_retries):
        try:
            logging.info(f"ğŸš€ åŠ è½½å°è¯• {attempt+1}/{max_retries}")
            driver.get(base_url)
            
            # ç­‰å¾…åŸºæœ¬æ¡†æ¶
            WebDriverWait(driver, 30).until(
                EC.presence_of_element_located((By.ID, "cctable"))
            )
            
            # å…³é”®ç­‰å¾…ï¼šæ•°æ®åŠ è½½
            if not wait_for_data_load(driver, fund_code):
                if attempt == max_retries - 1:
                    logging.error(f"âŒ é¡µé¢åŠ è½½å¤±è´¥")
                    # æœ€åå°è¯•ï¼šç›´æ¥è§£æå½“å‰é¡µé¢
                    current_data = parse_current_holdings(driver, fund_code)
                    if current_data:
                        logging.info(f"âœ… å¤‡ç”¨è§£æ: {len(current_data)} æ¡è®°å½•")
                        return pd.DataFrame(current_data)
                    return pd.DataFrame()
                time.sleep(5)
                continue
            
            # éªŒè¯é¡µé¢
            page_source = driver.page_source
            if fund_code not in page_source:
                logging.warning(f"âš ï¸ é¡µé¢éªŒè¯å¤±è´¥")
                if attempt == max_retries - 1:
                    return pd.DataFrame()
                time.sleep(3)
                continue
            
            logging.info("âœ… é¡µé¢åŠ è½½æˆåŠŸ")
            break
            
        except Exception as e:
            logging.error(f"åŠ è½½å¼‚å¸¸: {e}")
            if attempt == max_retries - 1:
                return pd.DataFrame()
            time.sleep(2 ** attempt)

    # ç­–ç•¥1ï¼šå°è¯•å¹´ä»½é€‰æ‹©
    years_attempted = []
    for year in years_to_crawl:
        try:
            logging.info(f"ğŸ“… å°è¯•å¹´ä»½: {year}")
            success, selected_year = select_year_intelligently(driver, year)
            
            if success:
                logging.info(f"âœ… å¹´ä»½é€‰æ‹©æˆåŠŸ: {selected_year}")
                
                # ç­‰å¾…æ•°æ®åˆ·æ–°
                time.sleep(6)
                
                # è§£ææ•°æ®
                page_source = driver.page_source
                soup = BeautifulSoup(page_source, 'lxml')
                
                holdings = parse_holdings_table(soup, fund_code, selected_year)
                if holdings:
                    fund_holdings.extend(holdings)
                    years_attempted.append(selected_year)
                    logging.info(f"âœ… {len(holdings)} æ¡ {selected_year} å¹´æ•°æ®")
                else:
                    logging.warning(f"âš ï¸ {selected_year} å¹´æ— æ•°æ®")
                
                time.sleep(2)
            else:
                logging.warning(f"âŒ {year} å¹´é€‰æ‹©å¤±è´¥: {selected_year}")
                
        except Exception as e:
            logging.error(f"{year} å¹´å¤„ç†å¼‚å¸¸: {e}")
            continue

    # ç­–ç•¥2ï¼šå¦‚æœå¹´ä»½é€‰æ‹©å¤±è´¥ï¼Œè§£æå½“å‰æ˜¾ç¤ºæ•°æ®
    if not years_attempted:
        logging.info("ğŸ”„ å¤‡ç”¨ç­–ç•¥ï¼šè§£æå½“å‰æ˜¾ç¤ºæ•°æ®")
        current_data = parse_current_holdings(driver, fund_code, years_to_crawl[0])
        if current_data:
            fund_holdings.extend(current_data)
            logging.info(f"âœ… å½“å‰é¡µé¢: {len(current_data)} æ¡è®°å½•")
        else:
            logging.warning("âŒ å½“å‰é¡µé¢ä¹Ÿæ— æ•°æ®")

    return pd.DataFrame(fund_holdings)

# --- è§£ææŒä»“è¡¨æ ¼ï¼ˆç®€åŒ–ç‰ˆï¼‰ ---
def parse_holdings_table(soup: BeautifulSoup, fund_code: str, year: str) -> List[Dict]:
    """è§£ææŒä»“è¡¨æ ¼"""
    cctable = soup.find(id="cctable")
    if not cctable:
        return []
    
    if "æ•°æ®åŠ è½½ä¸­" in cctable.text:
        return []
    
    holdings = []
    rows = cctable.find_all('tr')
    
    if len(rows) > 1:
        for row in rows[1:]:
            cols = row.find_all('td')
            if len(cols) >= 4:
                try:
                    # æå–è‚¡ç¥¨ä»£ç 
                    stock_code = ''
                    for col in cols[1:3]:
                        col_text = col.text.strip()
                        code_match = re.search(r'(\d{6})', col_text)
                        if code_match:
                            stock_code = code_match.group(1)
                            break
                    
                    if stock_code:
                        stock_name = cols[2].text.strip() if len(cols) > 2 else ''
                        stock_info = get_stock_info(stock_code)
                        
                        data = {
                            'åŸºé‡‘ä»£ç ': fund_code,
                            'å¹´ä»½': year,
                            'è‚¡ç¥¨ä»£ç ': stock_code,
                            'è‚¡ç¥¨åç§°': stock_name,
                            'æ‰€å±è¡Œä¸š': stock_info['æ‰€å±è¡Œä¸š'],
                            'æ¦‚å¿µä¸»é¢˜': stock_info['æ¦‚å¿µä¸»é¢˜'],
                            'æŒä»“å æ¯”': cols[3].text.strip() if len(cols) > 3 else '',
                            'æŒè‚¡æ•°': cols[4].text.strip() if len(cols) > 4 else '',
                            'å¸‚å€¼': cols[5].text.strip() if len(cols) > 5 else '',
                            'æŠ¥å‘Šæ—¥æœŸ': cols[0].text.strip() if len(cols) > 0 else ''
                        }
                        holdings.append(data)
                except Exception as e:
                    continue
    
    return holdings

# --- ä¸»å‡½æ•° ---
def main():
    """ä¸»å‡½æ•°"""
    current_year = time.localtime().tm_year
    years_to_crawl = [str(current_year), str(current_year - 1), str(current_year - 2)]
    
    request_delay = random.uniform(3, 5)

    logging.info("=== å¤©å¤©åŸºé‡‘æŒä»“çˆ¬å–å™¨ï¼ˆç»ˆæä¿®å¤ç‰ˆï¼‰ ===")
    logging.info(f"ğŸ¯ ç›®æ ‡å¹´ä»½: {', '.join(years_to_crawl)}")
    
    report_file = 'market_monitor_report.md'
    fund_list = parse_markdown_file(report_file)
    if not fund_list:
        logging.error("âŒ æ— åŸºé‡‘åˆ—è¡¨")
        return

    logging.info(f"ğŸ“Š çˆ¬å– {len(fund_list)} åªåŸºé‡‘")
    
    output_dir = "fund_data"
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    output_filename = os.path.join(output_dir, f"fund_holdings_{timestamp}.csv")
    
    driver = setup_driver()
    if driver is None:
        logging.error("âŒ æµè§ˆå™¨å¯åŠ¨å¤±è´¥")
        return
    
    all_holdings_df = pd.DataFrame()
    successful_funds = 0
    
    try:
        for i, fund in enumerate(fund_list, 1):
            fund_code = fund['code']
            
            logging.info(f"\n{'='*60}")
            logging.info(f"ğŸ”„ [{i}/{len(fund_list)}] {fund_code}")
            logging.info(f"{'='*60}")
            
            holdings_df = get_fund_holdings(driver, fund_code, years_to_crawl)
            
            if not holdings_df.empty:
                all_holdings_df = pd.concat([all_holdings_df, holdings_df], ignore_index=True)
                successful_funds += 1
                logging.info(f"âœ… {len(holdings_df)} æ¡è®°å½•")
                
                # é¢„è§ˆ
                if len(holdings_df) > 0:
                    sample = holdings_df.head(2)
                    for _, row in sample.iterrows():
                        logging.info(f"   {row['è‚¡ç¥¨ä»£ç ']} - {row['è‚¡ç¥¨åç§°'][:20]}...")
            else:
                logging.warning(f"âŒ {fund_code} æ— æ•°æ®")
            
            logging.info(f"ğŸ’¤ ç­‰å¾… {request_delay:.1f}s")
            time.sleep(request_delay)
            
    finally:
        driver.quit()
    
    # ä¿å­˜ç»“æœ
    if not all_holdings_df.empty:
        logging.info("\n" + "ğŸ‰" * 15)
        logging.info("ğŸ“Š ç»Ÿè®¡:")
        logging.info(f"   æ€»è®°å½•: {len(all_holdings_df)}")
        logging.info(f"   æˆåŠŸåŸºé‡‘: {successful_funds}/{len(fund_list)}")
        
        # è´¨é‡ç»Ÿè®¡
        if 'æ‰€å±è¡Œä¸š' in all_holdings_df.columns:
            industry_rate = (all_holdings_df['æ‰€å±è¡Œä¸š'] != 'æœªçŸ¥').mean()
            logging.info(f"   è¡Œä¸šè¦†ç›–: {industry_rate:.1%}")
        
        try:
            all_holdings_df.to_csv(output_filename, index=False, encoding='utf-8-sig')
            size = os.path.getsize(output_filename) / 1024
            logging.info(f"ğŸ’¾ ä¿å­˜: {size:.1f}KB")
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    else:
        logging.warning("âŒ æ— æ•°æ®")
        # åˆ›å»ºç©ºæ–‡ä»¶
        cols = ['åŸºé‡‘ä»£ç ', 'å¹´ä»½', 'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'æ‰€å±è¡Œä¸š', 'æ¦‚å¿µä¸»é¢˜', 
                'æŒä»“å æ¯”', 'æŒè‚¡æ•°', 'å¸‚å€¼', 'æŠ¥å‘Šæ—¥æœŸ']
        pd.DataFrame(columns=cols).to_csv(output_filename, index=False, encoding='utf-8-sig')

if __name__ == '__main__':
    main()
