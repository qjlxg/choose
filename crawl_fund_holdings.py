# -*- coding: utf-8 -*-
"""
ä¸€ä¸ªç”¨äºçˆ¬å–å¤©å¤©åŸºé‡‘ç½‘å…¨å¸‚åœºåŸºé‡‘æŒä»“æ•°æ®çš„Pythonè„šæœ¬
"""
import os
import time
import requests
import pandas as pd
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException
from bs4 import BeautifulSoup
import logging

# --- é…ç½®æ—¥å¿—ç³»ç»Ÿ ---
# é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œå¹¶è®¾ç½®çº§åˆ«ä¸º INFO
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- é…ç½®Selenium ---
def setup_driver():
    """é…ç½®å¹¶è¿”å›ä¸€ä¸ªæ— å¤´æ¨¡å¼çš„Chromeæµè§ˆå™¨é©±åŠ¨ã€‚"""
    logging.info("--- æ­£åœ¨å¯åŠ¨ ChromeDriver ---")
    try:
        chrome_options = Options()
        # æ— å¤´æ¨¡å¼ï¼Œä¸åœ¨çª—å£ä¸­æ˜¾ç¤º
        chrome_options.add_argument('--headless')
        # é’ˆå¯¹Linuxç¯å¢ƒçš„å¿…è¦å‚æ•°
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        
        # å°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ CHROMEDRIVER_PATHï¼Œå¦‚æœä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        chromedriver_path = os.getenv('CHROMEDRIVER_PATH', '/usr/lib/chromium-browser/chromedriver')
        service = Service(chromedriver_path)
        
        driver = webdriver.Chrome(service=service, options=chrome_options)
        logging.info("ğŸ‰ ChromeDriver å¯åŠ¨æˆåŠŸï¼")
        return driver
    except WebDriverException as e:
        # æ•è· WebDriver å¯åŠ¨å¤±è´¥çš„å¼‚å¸¸
        logging.error(f"âŒ ChromeDriver å¯åŠ¨å¤±è´¥ï¼š{e}")
        logging.error("è¯·æ£€æŸ¥ ChromeDriver è·¯å¾„ã€ç‰ˆæœ¬æ˜¯å¦ä¸ Chrome æµè§ˆå™¨åŒ¹é…ï¼Œä»¥åŠç³»ç»Ÿä¾èµ–æ˜¯å¦å®‰è£…ã€‚")
        return None

# --- çˆ¬å–å…¨å¸‚åœºåŸºé‡‘ä»£ç åˆ—è¡¨ ---
def get_all_fund_codes():
    """ä»å¤©å¤©åŸºé‡‘ç½‘è·å–æ‰€æœ‰åŸºé‡‘çš„ä»£ç åˆ—è¡¨ï¼Œå¹¶ç­›é€‰å‡ºCç±»åŸºé‡‘ã€‚"""
    logging.info("æ­£åœ¨çˆ¬å–å…¨å¸‚åœºåŸºé‡‘ä»£ç åˆ—è¡¨...")
    url = "http://fund.eastmoney.com/allfund.html"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œé¿å…ç½‘ç»œæ…¢å¡ä½
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        html = response.text
        # ä½¿ç”¨lxmlï¼Œè§£æé€Ÿåº¦æ›´å¿«
        soup = BeautifulSoup(html, 'lxml')
        
        fund_list = []
        # æ”¹è¿›ï¼šä½¿ç”¨æ›´ç²¾ç¡®çš„CSSé€‰æ‹©å™¨
        for a_tag in soup.select('#code_content a'):
            code_name_text = a_tag.get_text(strip=True)
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…åŸºé‡‘ä»£ç å’Œåç§°
            match = re.match(r'\((\d{6})\)(.+)', code_name_text)
            if match:
                code, name = match.groups()
                fund_list.append({'code': code, 'name': name.strip()})
        
        logging.info(f"å·²è·å– {len(fund_list)} åªåŸºé‡‘çš„ä»£ç ã€‚")
        
        # ç­›é€‰å‡ºåç§°ä»¥ "C" ç»“å°¾çš„åŸºé‡‘
        c_fund_list = [fund for fund in fund_list if fund['name'].endswith('C')]
        logging.info(f"å·²ç­›é€‰å‡º {len(c_fund_list)} åªåœºå¤–Cç±»åŸºé‡‘ã€‚")
        return c_fund_list

    except requests.exceptions.RequestException as e:
        logging.error(f"âŒ çˆ¬å–åŸºé‡‘ä»£ç åˆ—è¡¨å¤±è´¥ï¼š{e}")
        return []

# --- æ–°å¢ï¼šä¸“é—¨è§£ææŒä»“è¡¨æ ¼çš„å‡½æ•° ---
def parse_holdings_table(soup, fund_code, year):
    """ä¸“é—¨è§£ææŒä»“è¡¨æ ¼çš„å‡½æ•°"""
    holdings_table = soup.find(id="cctable")
    if not holdings_table:
        return []
    
    holdings = []
    rows = holdings_table.find_all('tr')
    # ç¡®ä¿æœ‰æ•°æ®è¡Œï¼ˆè‡³å°‘ä¸¤è¡Œï¼Œä¸€è¡Œè¡¨å¤´ï¼Œä¸€è¡Œæ•°æ®ï¼‰
    if not rows or len(rows) <= 1:
        return []
    
    # è§£æè¡¨æ ¼æ•°æ®
    for row in rows[1:]:  # è·³è¿‡è¡¨å¤´
        cols = row.find_all('td')
        if len(cols) >= 5:
            try:
                data = {
                    'fund_code': fund_code,
                    'year': year,
                    'stock_code': cols[1].text.strip() if len(cols) > 1 else '',
                    'stock_name': cols[2].text.strip() if len(cols) > 2 else '',
                    'proportion': cols[3].text.strip() if len(cols) > 3 else '',
                    'shares': cols[4].text.strip() if len(cols) > 4 else '',
                    'market_value': cols[5].text.strip() if len(cols) > 5 else '',
                    # å°è¯•è§£ææ›´å¤šå­—æ®µï¼Œå¦‚æŠ¥å‘Šæ—¥æœŸç­‰
                    'report_date': cols[0].text.strip() if len(cols) > 0 else ''
                }
                holdings.append(data)
            except Exception as e:
                logging.warning(f"è§£æè¡Œæ•°æ®å¤±è´¥: {e}")
                continue
    return holdings

# --- çˆ¬å–æŒ‡å®šåŸºé‡‘æŒä»“æ•°æ® ---
def get_fund_holdings(driver, fund_code, years_to_crawl, max_retries=3):
    """
    çˆ¬å–æŒ‡å®šåŸºé‡‘åœ¨è¿‘Nå¹´å†…çš„æŒä»“æ•°æ®ã€‚
    :param driver: Selenium WebDriverå®ä¾‹
    :param fund_code: åŸºé‡‘ä»£ç 
    :param years_to_crawl: çˆ¬å–çš„å¹´ä»½åˆ—è¡¨
    :param max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    :return: åŒ…å«æŒä»“æ•°æ®çš„DataFrame
    """
    if driver is None:
        logging.error("WebDriver å®ä¾‹ä¸å­˜åœ¨ï¼Œè·³è¿‡çˆ¬å–ã€‚")
        return pd.DataFrame()

    fund_holdings = []
    base_url = f"https://fundf10.eastmoney.com/ccmx_{fund_code}.html"

    # å¢åŠ æ—¥å¿—ï¼šè®°å½•è®¿é—®é¡µé¢å‰çš„çŠ¶æ€
    logging.info(f"è®¿é—®åŸºé‡‘ {fund_code} é¡µé¢: {base_url}")
    
    for attempt in range(max_retries):
        try:
            logging.info(f"å°è¯•è®¿é—®é¡µé¢ (ç¬¬{attempt+1}æ¬¡)...")
            driver.get(base_url)
            
            # ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´æ¥åº”å¯¹ç½‘ç»œæ…¢çš„æƒ…å†µ
            wait = WebDriverWait(driver, 30)
            wait.until(
                EC.any_of(
                    EC.presence_of_element_located((By.ID, "cctable")),
                    EC.presence_of_element_located((By.CLASS_NAME, "placeholder"))
                )
            )
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æŒä»“æ•°æ®
            page_source_check = driver.page_source
            if "æš‚æ— æ•°æ®" in page_source_check or "æ²¡æœ‰æ‰¾åˆ°" in page_source_check:
                logging.info(f"åŸºé‡‘ {fund_code} æš‚æ— æŒä»“æ•°æ®")
                return pd.DataFrame()
            
            logging.info("é¡µé¢åŠ è½½æˆåŠŸï¼Œå‡†å¤‡è§£ææ•°æ®ã€‚")
            break
        except TimeoutException:
            logging.warning(f"é¡µé¢åŠ è½½è¶…æ—¶ï¼ŒåŸºé‡‘ {fund_code} (ç¬¬{attempt+1}/{max_retries}æ¬¡é‡è¯•)")
            if attempt == max_retries - 1:
                logging.error(f"åŸºé‡‘ {fund_code} é¡µé¢åŠ è½½å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡ï¼Œè·³è¿‡ã€‚")
                return pd.DataFrame()
            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        except Exception as e:
            logging.error(f"è®¿é—®åŸºé‡‘ {fund_code} é¡µé¢æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ï¼š{e}")
            if attempt == max_retries - 1:
                return pd.DataFrame()
            time.sleep(2 ** attempt)

    # å¾ªç¯å¹´ä»½å¹¶è·å–æ•°æ®
    for year in years_to_crawl:
        try:
            logging.info(f"æ­£åœ¨çˆ¬å– {year} å¹´æŒä»“æ•°æ®...")
            
            # æ”¹è¿›ï¼šå¤šä¸ªXPathé€‰æ‹©å™¨ï¼Œå…¼å®¹ä¸åŒé¡µé¢ç»“æ„
            year_selectors = [
                f"//label[@value='{year}']",
                f"//div[@id='pagebar']//label[@value='{year}']",
            ]
            
            year_button = None
            for selector in year_selectors:
                try:
                    # æ˜¾å¼ç­‰å¾…ï¼Œç­‰å¾…æŒ‰é’®å¯ç‚¹å‡»
                    year_button = WebDriverWait(driver, 10).until(
                        EC.element_to_be_clickable((By.XPATH, selector))
                    )
                    break
                except TimeoutException:
                    continue
            
            if not year_button:
                logging.warning(f"æœªæ‰¾åˆ°åŸºé‡‘ {fund_code} åœ¨ {year} å¹´çš„æŒä»“æŒ‰é’®ï¼Œè·³è¿‡ã€‚")
                continue
            
            # æ»šåŠ¨åˆ°å…ƒç´ å¹¶ç‚¹å‡»
            driver.execute_script("arguments[0].scrollIntoView();", year_button)
            time.sleep(1) # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿é¡µé¢æ»šåŠ¨å’Œjsæ¸²æŸ“å®Œæˆ
            year_button.click()
            
            # ç­‰å¾…è¡¨æ ¼å†…å®¹æ›´æ–°
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.ID, "cctable"))
            )
            
            # è·å–é¡µé¢HTMLå†…å®¹å¹¶è§£æ
            page_source = driver.page_source
            soup = BeautifulSoup(page_source, 'lxml')
            
            holdings = parse_holdings_table(soup, fund_code, year)
            fund_holdings.extend(holdings)
            logging.info(f"âœ… æˆåŠŸè·å– {len(holdings)} æ¡ {year} å¹´çš„æŒä»“è®°å½•ã€‚")
            
        except TimeoutException:
            logging.warning(f"åŸºé‡‘ {fund_code} åœ¨ {year} å¹´çš„æŒä»“æŒ‰é’®æˆ–è¡¨æ ¼åŠ è½½è¶…æ—¶ï¼Œè·³è¿‡ã€‚")
            continue
        except Exception as e:
            logging.error(f"çˆ¬å–åŸºé‡‘ {fund_code} çš„ {year} å¹´æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
            continue
            
    return pd.DataFrame(fund_holdings)


def main():
    """ä¸»å‡½æ•°ï¼Œæ‰§è¡Œçˆ¬å–ä»»åŠ¡ã€‚"""
    # å®šä¹‰éœ€è¦çˆ¬å–çš„å¹´ä»½èŒƒå›´
    current_year = time.localtime().tm_year
    years_to_crawl = [str(current_year), str(current_year - 1), str(current_year - 2)]
    
    # æ”¹è¿›ï¼šé…ç½®å‚æ•°
    max_funds = 50  # æ–°å¢ï¼šé™åˆ¶æœ€å¤§åŸºé‡‘æ•°é‡
    request_delay = 1  # æ–°å¢ï¼šè¯·æ±‚å»¶æ—¶
    
    logging.info("=== å¤©å¤©åŸºé‡‘æŒä»“æ•°æ®çˆ¬å–å™¨ ===")
    logging.info(f"ç›®æ ‡å¹´ä»½: {', '.join(years_to_crawl)}")
    logging.info(f"æœ€å¤§åŸºé‡‘æ•°é‡: {max_funds}")
    
    # è·å– C ç±»åŸºé‡‘çš„ä»£ç åˆ—è¡¨
    all_fund_data = get_all_fund_codes()
    if not all_fund_data:
        logging.error("æ— æ³•è·å–åŸºé‡‘ä»£ç åˆ—è¡¨ï¼Œç¨‹åºé€€å‡ºã€‚")
        return

    # é™åˆ¶çˆ¬å–çš„åŸºé‡‘æ•°é‡
    if len(all_fund_data) > max_funds:
        all_fund_data = all_fund_data[:max_funds]
        logging.info(f"æ³¨æ„ï¼šåŸºé‡‘æ•°é‡å·²é™åˆ¶ä¸º {max_funds} åªã€‚")
    
    logging.info(f"ğŸ“Š å‡†å¤‡çˆ¬å– {len(all_fund_data)} åªåŸºé‡‘")
    
    # è®¾ç½®ä¸€ä¸ªæ–‡ä»¶è·¯å¾„æ¥å­˜å‚¨ç»“æœ
    output_dir = "fund_data"
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    timestamp = time.strftime('%Y%m%d_%H%M%S')
    output_filename = os.path.join(output_dir, f"fund_holdings_C_{timestamp}.csv")
    
    # å°è¯•å¯åŠ¨ WebDriverï¼Œå¦‚æœå¤±è´¥åˆ™ç›´æ¥é€€å‡º
    driver = setup_driver()
    if driver is None:
        return
        
    all_holdings_df = pd.DataFrame()
    successful_funds = 0
    
    try:
        for i, fund in enumerate(all_fund_data, 1):
            fund_code = fund['code']
            fund_name = fund['name']
            
            logging.info(f"\n--- [{i}/{len(all_fund_data)}] æ­£åœ¨å¤„ç†: {fund_name} ({fund_code}) ---")
            
            holdings_df = get_fund_holdings(driver, fund_code, years_to_crawl)
            if not holdings_df.empty:
                all_holdings_df = pd.concat([all_holdings_df, holdings_df], ignore_index=True)
                successful_funds += 1
                logging.info(f"âœ… æˆåŠŸè·å– {len(holdings_df)} æ¡æŒä»“è®°å½•")
            else:
                logging.info("âŒ æœªè·å–åˆ°æ•°æ®ï¼Œç»§ç»­ä¸‹ä¸€åªåŸºé‡‘ã€‚")
            
            # é€‚å½“å»¶æ—¶ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(request_delay)
            
    finally:
        logging.info("çˆ¬å–ä»»åŠ¡ç»“æŸï¼Œå…³é—­ WebDriverã€‚")
        driver.quit()
    
    if not all_holdings_df.empty:
        # ä¿å­˜æ–‡ä»¶å‰ï¼Œå…ˆæ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        logging.info("\nğŸ‰ æ•°æ®çˆ¬å–å®Œæˆ!")
        logging.info(f"ğŸ“ å·²ä¿å­˜åˆ°æ–‡ä»¶ï¼š{output_filename}")
        logging.info(f"ğŸ“ˆ æ€»è®°å½•æ•°: {len(all_holdings_df)}")
        logging.info(f"âœ… æˆåŠŸåŸºé‡‘: {successful_funds}/{len(all_fund_data)}")
        
        # ä¿å­˜æ•°æ®
        try:
            all_holdings_df.to_csv(output_filename, index=False, encoding='utf-8-sig')
        except Exception as e:
            logging.error(f"ä¿å­˜æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
            
    else:
        logging.info("æ²¡æœ‰çˆ¬å–åˆ°ä»»ä½•æ•°æ®ã€‚")

if __name__ == '__main__':
    main()
