import requests
from lxml import etree
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np
import time
import re
from fake_useragent import UserAgent
import os
from datetime import datetime
import json
import ast

class FundDataCrawler:
    def __init__(self, output_dir='fund_data'):
        self.session = requests.Session()
        self.ua = UserAgent()
        self.output_dir = output_dir
        self.setup_session()
        self.setup_driver()
        self.ensure_output_directory()
    
    def ensure_output_directory(self):
        """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)
            print(f"å·²åˆ›å»ºè¾“å‡ºç›®å½•: {self.output_dir}")
            
    def setup_session(self):
        """è®¾ç½®requestsä¼šè¯"""
        headers = {
            'User-Agent': self.ua.random,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Referer': 'https://fundf10.eastmoney.com/',
        }
        self.session.headers.update(headers)
    
    def setup_driver(self):
        """åˆå§‹åŒ–seleniumæµè§ˆå™¨é©±åŠ¨"""
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument(f'--user-agent={self.ua.random}')
        
        try:
            # ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ä¸‹è½½å¹¶å®‰è£…åˆé€‚çš„ chromedriver
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.wait = WebDriverWait(self.driver, 10)
            print("æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"æµè§ˆå™¨é©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.driver = None
    
    def close_driver(self):
        """å…³é—­æµè§ˆå™¨é©±åŠ¨"""
        if self.driver:
            self.driver.quit()
    
    def get_all_fund_codes(self):
        """
        çˆ¬å–å¤©å¤©åŸºé‡‘ç½‘æ‰€æœ‰åŸºé‡‘ä»£ç å’Œåç§°
        è¿”å›: DataFrameæ ¼å¼çš„åŸºé‡‘åˆ—è¡¨
        """
        url = "http://fund.eastmoney.com/allfund.html"
        
        try:
            print("æ­£åœ¨è·å–å…¨å¸‚åœºåŸºé‡‘åˆ—è¡¨...")
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # ä½¿ç”¨lxmlè§£æ
            html = etree.HTML(response.text)
            
            # XPathè·å–åŸºé‡‘ä»£ç å’Œåç§°
            fund_items = html.xpath('//*[@id="code_content"]/div/ul/li/div/a[1]/text()')
            
            fund_list = []
            for item in fund_items:
                # æå–6ä½åŸºé‡‘ä»£ç 
                code_match = re.search(r'\((\d{6})\)', item)
                if code_match:
                    code = code_match.group(1)
                    name = re.sub(r'^\(.*?ï¼‰', '', item).strip()
                    fund_list.append({
                        'fund_code': code,
                        'fund_name': name
                    })
            
            df = pd.DataFrame(fund_list)
            print(f"æˆåŠŸè·å– {len(df)} åªåŸºé‡‘")
            
            # ä¿å­˜åˆ°æœ¬åœ°
            output_path = os.path.join(self.output_dir, 'all_fund_list.csv')
            df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"åŸºé‡‘åˆ—è¡¨å·²ä¿å­˜è‡³: {output_path}")
            return df
            
        except Exception as e:
            print(f"è·å–åŸºé‡‘åˆ—è¡¨å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def get_fund_info(self, fund_code):
        """
        è·å–å•åªåŸºé‡‘çš„åŸºæœ¬ä¿¡æ¯
        """
        url = f"https://fundf10.eastmoney.com/jbgk_{fund_code}.html"
        
        try:
            response = self.session.get(url, timeout=10)
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æå–åŸºé‡‘åŸºæœ¬ä¿¡æ¯
            info = {}
            
            # åŸºé‡‘åç§°
            name_elem = soup.select_one('#bodydiv > div > div.fundInfo > div.title > h1')
            info['fund_name'] = name_elem.text.strip() if name_elem else ''
            
            # åŸºé‡‘ä»£ç 
            info['fund_code'] = fund_code
            
            # å…¶ä»–ä¿¡æ¯ï¼ˆæˆç«‹æ—¥æœŸã€åŸºé‡‘ç»ç†ç­‰ï¼‰
            info_table = soup.select_one('#bodydiv > div > div.fundInfo > div.info')
            if info_table:
                rows = info_table.find_all('p')
                for row in rows:
                    text = row.get_text().strip()
                    if 'æˆç«‹æ—¥æœŸ' in text:
                        info['establish_date'] = text.split('ï¼š')[-1].strip()
                    elif 'åŸºé‡‘ç»ç†' in text:
                        info['manager'] = text.split('ï¼š')[-1].strip()
                    elif 'åŸºé‡‘å…¬å¸' in text:
                        info['company'] = text.split('ï¼š')[-1].strip()
            
            return info
            
        except Exception as e:
            print(f"è·å–åŸºé‡‘ {fund_code} ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def get_fund_holdings(self, fund_code, years=None):
        """
        çˆ¬å–æŒ‡å®šåŸºé‡‘çš„æŒä»“æ•°æ®ï¼ˆä½¿ç”¨Seleniumï¼Œé€‚ç”¨äºccmxé¡µé¢ï¼‰
        years: çˆ¬å–çš„å¹´ä»½åˆ—è¡¨ï¼ŒNoneåˆ™çˆ¬å–æœ€æ–°æ•°æ®
        """
        if years is None:
            years = [datetime.now().year]
        
        all_holdings = []
        
        for year in years:
            try:
                print(f"æ­£åœ¨çˆ¬å–åŸºé‡‘ {fund_code} {year}å¹´æŒä»“...")
                
                if not self.driver:
                    print("æµè§ˆå™¨é©±åŠ¨ä¸å¯ç”¨ï¼Œè·³è¿‡åŠ¨æ€åŠ è½½")
                    continue
                
                # è®¿é—®åŸºé‡‘æŒä»“é¡µé¢
                url = f"https://fundf10.eastmoney.com/ccmx_{fund_code}.html"
                self.driver.get(url)
                time.sleep(3)
                
                # åˆ‡æ¢åˆ°æŒ‡å®šå¹´ä»½
                try:
                    year_button = self.wait.until(
                        EC.element_to_be_clickable(
                            (By.XPATH, f"//*[@id='pagebar']/div/label[@value='{year}']")
                        )
                    )
                    year_button.click()
                    time.sleep(3)
                except Exception as e:
                    print(f"å¹´ä»½åˆ‡æ¢å¤±è´¥ {year}: {e}")
                    continue
                
                # è§£ææŒä»“è¡¨æ ¼
                soup = BeautifulSoup(self.driver.page_source, 'html.parser')
                table = soup.select_one('#cctable > div > div')
                
                if not table:
                    print(f"æœªæ‰¾åˆ°åŸºé‡‘ {fund_code} {year}å¹´æŒä»“è¡¨æ ¼")
                    continue
                
                # è§£æè¡¨æ ¼æ•°æ®
                rows = table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´
                for row in rows:
                    cols = row.find_all(['td', 'th'])
                    if len(cols) >= 7:
                        holding = {
                            'fund_code': fund_code,
                            'year': year,
                            'stock_code': cols[1].text.strip() if cols[1].text.strip() else '',
                            'stock_name': cols[2].text.strip(),
                            'hold_ratio': cols[3].text.strip(),
                            'hold_value': cols[4].text.strip(),
                            'stock_price': cols[5].text.strip(),
                            'hold_shares': cols[6].text.strip(),
                        }
                        all_holdings.append(holding)
                
                print(f"åŸºé‡‘ {fund_code} {year}å¹´è·å–åˆ° {len(rows)} æ¡æŒä»“è®°å½•")
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                print(f"çˆ¬å–åŸºé‡‘ {fund_code} {year}å¹´æŒä»“å¤±è´¥: {e}")
                continue
        
        # è½¬æ¢ä¸ºDataFrame
        if all_holdings:
            df = pd.DataFrame(all_holdings)
            # æ•°æ®æ¸…æ´—
            df['hold_ratio'] = pd.to_numeric(df['hold_ratio'].str.replace('%', ''), errors='coerce')
            df['hold_value'] = pd.to_numeric(df['hold_value'].str.replace(',', ''), errors='coerce')
            df['stock_price'] = pd.to_numeric(df['stock_price'], errors='coerce')
            df['hold_shares'] = pd.to_numeric(df['hold_shares'].str.replace(',', ''), errors='coerce')
            return df
        else:
            return pd.DataFrame()

    def _detect_content_format(self, content):
        """
        æ£€æµ‹å†…å®¹æ ¼å¼ï¼šHTML æˆ– çº¯æ–‡æœ¬
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«HTMLæ ‡ç­¾
        html_pattern = re.compile(r'<(table|tr|td|th)[^>]*>', re.IGNORECASE)
        if html_pattern.search(content):
            return 'html'
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«åˆ¶è¡¨ç¬¦åˆ†éš”çš„è¡¨æ ¼
        text_pattern = re.compile(r'^\d+\t\d{5,6}\t', re.MULTILINE)
        if text_pattern.search(content):
            return 'text'
        
        return 'unknown'

    def _parse_html_content(self, content, fund_code, year):
        """
        è§£æHTMLæ ¼å¼çš„å†…å®¹
        """
        holdings = []
        soup = BeautifulSoup(content, 'html.parser')
        
        # æŸ¥æ‰¾æ‰€æœ‰æŒä»“è¡¨æ ¼
        tables = soup.find_all('table', class_=re.compile(r'w782|w790'))
        
        for table in tables:
            # æå–å­£åº¦ä¿¡æ¯
            h4_elem = table.find_previous('h4')
            if h4_elem:
                quarter_text = h4_elem.get_text()
                quarter_match = re.search(rf'{year}å¹´(\d+)å­£åº¦', quarter_text)
                quarter = quarter_match.group(1) if quarter_match else 'æœªçŸ¥'
            else:
                quarter = 'æœªçŸ¥'
            
            # è§£æè¡¨æ ¼è¡Œ
            rows = table.find('tbody').find_all('tr') if table.find('tbody') else table.find_all('tr')[1:]
            
            for row in rows:
                cols = row.find_all('td')
                if len(cols) >= 6:
                    # æå–è‚¡ç¥¨ä»£ç ï¼ˆä»é“¾æ¥ä¸­æå–ï¼‰
                    stock_code_link = cols[1].find('a')
                    stock_code = stock_code_link.get('href', '').split('r/')[-1].replace('/', '') if stock_code_link else cols[1].get_text().strip()
                    
                    # æå–è‚¡ç¥¨åç§°
                    stock_name_elem = cols[2].find('a')
                    stock_name = stock_name_elem.get_text().strip() if stock_name_elem else cols[2].get_text().strip()
                    
                    # æå–æ•°æ®
                    hold_ratio = cols[4].get_text().strip().replace('%', '')  # ç¬¬5åˆ—ï¼šå å‡€å€¼æ¯”ä¾‹
                    hold_shares = cols[5].get_text().strip().replace(',', '')  # ç¬¬6åˆ—ï¼šæŒè‚¡æ•°
                    hold_value = cols[6].get_text().strip().replace(',', '')   # ç¬¬7åˆ—ï¼šæŒä»“å¸‚å€¼
                    
                    # æå–åºå·
                    rank_elem = cols[0].get_text().strip()
                    rank = int(rank_elem) if rank_elem.isdigit() else len(holdings) + 1
                    
                    holding = {
                        'fund_code': fund_code,
                        'year': year,
                        'quarter': quarter,
                        'rank': rank,
                        'stock_code': stock_code,
                        'stock_name': stock_name,
                        'hold_ratio': hold_ratio,
                        'hold_shares': hold_shares,
                        'hold_value': hold_value,
                        'format': 'html'
                    }
                    holdings.append(holding)
        
        return holdings

    def _parse_text_content(self, content, fund_code, year):
        """
        è§£æçº¯æ–‡æœ¬æ ¼å¼çš„å†…å®¹ï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
        """
        holdings = []
        lines = content.split('\n')
        in_table = False
        current_quarter = ''
        data_rows = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # è¯†åˆ«å­£åº¦æ ‡é¢˜
            quarter_match = re.search(rf'{year}å¹´(\d+)å­£åº¦è‚¡ç¥¨æŠ•èµ„æ˜ç»†', line)
            if quarter_match:
                # å¤„ç†ä¸Šä¸€å­£åº¦æ•°æ®
                if data_rows:
                    holdings.extend(self._parse_text_table_rows(data_rows, fund_code, year, current_quarter))
                    data_rows = []
                current_quarter = quarter_match.group(1)
                in_table = True
                continue
            
            # è¯†åˆ«æ•°æ®è¡Œï¼ˆä»¥åºå·å¼€å¤´ï¼‰
            if in_table and re.match(r'^\d+\t', line):
                data_rows.append(line)
            elif in_table and ('æ˜¾ç¤ºå…¨éƒ¨æŒä»“æ˜ç»†' in line or '>>' in line):
                # è¡¨æ ¼ç»“æŸ
                if data_rows:
                    holdings.extend(self._parse_text_table_rows(data_rows, fund_code, year, current_quarter))
                    data_rows = []
                in_table = False
        
        # å¤„ç†æœ€åå­£åº¦
        if data_rows:
            holdings.extend(self._parse_text_table_rows(data_rows, fund_code, year, current_quarter))
        
        return holdings

    def _parse_text_table_rows(self, rows, fund_code, year, quarter):
        """
        è§£æçº¯æ–‡æœ¬è¡¨æ ¼è¡Œ
        """
        holdings = []
        for row in rows:
            fields = [f.strip() for f in row.split('\t') if f.strip()]
            if len(fields) < 6 or not fields[0].isdigit():
                continue
            
            rank = int(fields[0])
            stock_code = fields[1]
            stock_name = fields[2]
            
            # åŠ¨æ€æ£€æµ‹æ ¼å¼ï¼šQ2 æœ‰æ›´å¤šå­—æ®µï¼ˆæœ€æ–°ä»·ã€æ¶¨è·Œå¹…ã€ç›¸å…³èµ„è®¯åˆå¹¶ï¼‰
            if len(fields) >= 9:  # Q2 æ ¼å¼ï¼ˆåºå·+ä»£ç +åç§°+æœ€æ–°ä»·+æ¶¨è·Œå¹…+èµ„è®¯+æ¯”ä¾‹+æŒè‚¡+å¸‚å€¼ï¼‰
                hold_ratio = fields[6].replace('%', '')
                hold_shares = fields[7].replace(',', '')
                hold_value = fields[8].replace(',', '')
            else:  # Q1 æ ¼å¼ï¼ˆåºå·+ä»£ç +åç§°+èµ„è®¯+æ¯”ä¾‹+æŒè‚¡+å¸‚å€¼ï¼‰
                hold_ratio = fields[3].replace('%', '')
                hold_shares = fields[4].replace(',', '')
                hold_value = fields[5].replace(',', '')
            
            holding = {
                'fund_code': fund_code,
                'year': year,
                'quarter': quarter,
                'rank': rank,
                'stock_code': stock_code,
                'stock_name': stock_name,
                'hold_ratio': hold_ratio,
                'hold_shares': hold_shares,
                'hold_value': hold_value,
                'format': 'text'
            }
            holdings.append(holding)
        
        return holdings

    def get_fund_holdings_from_api(self, fund_code, years=None):
        """
        é€šè¿‡APIé“¾æ¥çˆ¬å–åŸºé‡‘æŒä»“æ•°æ® - æ™ºèƒ½æ ¼å¼æ£€æµ‹ç‰ˆ
        """
        if years is None:
            years = [datetime.now().year]
        
        all_holdings = []
        
        for year in years:
            try:
                print(f"æ­£åœ¨é€šè¿‡APIçˆ¬å–åŸºé‡‘ {fund_code} {year}å¹´æŒä»“...")
                
                # æ„å»ºAPIé“¾æ¥
                url = f"https://fundf10.eastmoney.com/FundArchivesDatas.aspx?type=jjcc&code={fund_code}&topline=10&year={year}"
                response = self.session.get(url, timeout=10)
                response.raise_for_status()
                
                # è§£æè¿”å›çš„JavaScriptæ•°æ®
                match = re.search(r'var apidata=(.*?);', response.text, re.DOTALL)
                if not match:
                    print(f"æœªåœ¨å“åº”ä¸­æ‰¾åˆ°åŸºé‡‘ {fund_code} {year}å¹´çš„æ•°æ®")
                    continue
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å®‰å…¨åœ°æå– content å­—ç¬¦ä¸²ï¼ˆå¤„ç†è½¬ä¹‰ï¼‰
                content_match = re.search(r'content:"(.*)"', match.group(1), re.DOTALL | re.MULTILINE)
                content = content_match.group(1) if content_match else ''
                
                if not content.strip():
                    print(f"åŸºé‡‘ {fund_code} {year}å¹´ content ä¸ºç©º")
                    continue
                
                # æ™ºèƒ½æ£€æµ‹æ ¼å¼å¹¶è§£æ
                content_format = self._detect_content_format(content)
                print(f"    æ£€æµ‹åˆ°å†…å®¹æ ¼å¼: {content_format}")
                
                if content_format == 'html':
                    holdings = self._parse_html_content(content, fund_code, year)
                elif content_format == 'text':
                    holdings = self._parse_text_content(content, fund_code, year)
                else:
                    print(f"    æœªçŸ¥å†…å®¹æ ¼å¼ï¼Œå°è¯•HTMLè§£æ...")
                    holdings = self._parse_html_content(content, fund_code, year)
                    if not holdings:
                        print(f"    HTMLè§£æå¤±è´¥ï¼Œå°è¯•æ–‡æœ¬è§£æ...")
                        holdings = self._parse_text_content(content, fund_code, year)
                
                all_holdings.extend(holdings)
                print(f"    è§£æåˆ° {len(holdings)} æ¡è®°å½• (æ ¼å¼: {content_format})")
                
                # è°ƒè¯•ï¼šå¦‚æœæ²¡æœ‰æ•°æ®ï¼Œæ‰“å°å†…å®¹é¢„è§ˆ
                if not holdings:
                    preview = content[:300].replace('\n', ' ').replace('\t', ' ')
                    print(f"    è°ƒè¯•ä¿¡æ¯ - content é¢„è§ˆ: {preview}...")
                
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                print(f"çˆ¬å–åŸºé‡‘ {fund_code} {year}å¹´æŒä»“å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        if all_holdings:
            df = pd.DataFrame(all_holdings)
            # æ•°æ®æ¸…æ´—ä¸ºæ•°å€¼ç±»å‹
            df['hold_ratio'] = pd.to_numeric(df['hold_ratio'], errors='coerce')
            df['hold_shares'] = pd.to_numeric(df['hold_shares'], errors='coerce')
            df['hold_value'] = pd.to_numeric(df['hold_value'], errors='coerce')
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            print(f"  æ•°æ®è´¨é‡æ£€æŸ¥:")
            print(f"    - æ€»è®°å½•æ•°: {len(df)}")
            if len(df) > 0:
                print(f"    - å¹³å‡æŒä»“æ¯”ä¾‹: {df['hold_ratio'].mean():.2f}%")
                print(f"    - æ€»æŒä»“å¸‚å€¼: {df['hold_value'].sum():,.2f}ä¸‡å…ƒ")
                print(f"    - æ•°æ®æ ¼å¼åˆ†å¸ƒ: {df['format'].value_counts().to_dict()}")
            
            return df
        else:
            print(f"åŸºé‡‘ {fund_code} æœªè·å–åˆ°ä»»ä½•æŒä»“æ•°æ®")
            return pd.DataFrame()
    
    def get_fund_holdings_from_api_backup(self, fund_code, years=None):
        """
        é€šè¿‡æ–°çš„APIé“¾æ¥çˆ¬å–åŸºé‡‘æŒä»“æ•°æ® - åŸå§‹ç‰ˆæœ¬ï¼ˆä½œä¸ºå¤‡ä»½ï¼‰
        """
        if years is None:
            years = [datetime.now().year]
        
        all_holdings = []
        
        for year in years:
            try:
                print(f"æ­£åœ¨é€šè¿‡APIå¤‡ä»½æ–¹æ³•çˆ¬å–åŸºé‡‘ {fund_code} {year}å¹´æŒä»“...")
                
                # æ„å»ºAPIé“¾æ¥
                url = f"https://fundf10.eastmoney.com/FundArchivesDatas.aspx?type=jjcc&code={fund_code}&topline=10&year={year}"
                response = self.session.get(url, timeout=10)
                response.raise_for_status()
                
                # è§£æè¿”å›çš„JavaScriptæ•°æ®
                match = re.search(r'var apidata=(.*?);', response.text, re.DOTALL)
                if not match:
                    print(f"æœªåœ¨å“åº”ä¸­æ‰¾åˆ°åŸºé‡‘ {fund_code} {year}å¹´çš„æ•°æ®")
                    continue
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å®‰å…¨åœ°æå– content å­—ç¬¦ä¸²
                content_match = re.search(r'content:"(.*)"', match.group(1), re.DOTALL)
                content = content_match.group(1) if content_match else ''
                
                # ä½¿ç”¨ BeautifulSoup è§£æ HTML å†…å®¹
                soup = BeautifulSoup(content, 'html.parser')
                
                # æ‰¾åˆ°æ‰€æœ‰çš„è¡¨æ ¼
                tables = soup.find_all('table', {'class': 'w780'})
                
                if not tables:
                    print(f"æœªæ‰¾åˆ°åŸºé‡‘ {fund_code} {year}å¹´æŒä»“è¡¨æ ¼")
                    continue
                
                for table in tables:
                    # è·å–å­£åº¦ä¿¡æ¯
                    quarter_info_elem = table.find_previous_sibling('h3')
                    quarter_info = quarter_info_elem.text.strip().split('  ')[0] if quarter_info_elem else f"{year}å¹´æœªçŸ¥å­£åº¦"
                    
                    # éå†è¡¨æ ¼ä¸­çš„æ¯ä¸€è¡Œ
                    rows = table.find_all('tr')[1:] # è·³è¿‡è¡¨å¤´
                    for row in rows:
                        cols = row.find_all('td')
                        if len(cols) >= 6:
                            holding = {
                                'fund_code': fund_code,
                                'year': year,
                                'quarter': quarter_info,
                                'stock_code': cols[1].text.strip(),
                                'stock_name': cols[2].text.strip(),
                                'hold_ratio': cols[3].text.strip().replace('%', ''),
                                'hold_shares': cols[4].text.strip().replace(',', ''),
                                'hold_value': cols[5].text.strip().replace(',', '')
                            }
                            all_holdings.append(holding)
                
                print(f"åŸºé‡‘ {fund_code} {year}å¹´è·å–åˆ° {len(all_holdings)} æ¡æŒä»“è®°å½•")

            except Exception as e:
                print(f"çˆ¬å–åŸºé‡‘ {fund_code} {year}å¹´æŒä»“å¤±è´¥: {e}")
                continue
        
        if all_holdings:
            df = pd.DataFrame(all_holdings)
            # æ•°æ®æ¸…æ´—
            df['hold_ratio'] = pd.to_numeric(df['hold_ratio'], errors='coerce')
            df['hold_value'] = pd.to_numeric(df['hold_value'], errors='coerce')
            df['hold_shares'] = pd.to_numeric(df['hold_shares'], errors='coerce')
            return df
        else:
            return pd.DataFrame()
    
    def test_api_parsing(self, fund_code='014192', year=2024):
        """
        æµ‹è¯•APIè§£æåŠŸèƒ½ - å¢å¼ºæµ‹è¯•
        """
        print(f"\nğŸ§ª æµ‹è¯•APIè§£æ - åŸºé‡‘ {fund_code} {year}å¹´")
        
        # æµ‹è¯•æ–°æ™ºèƒ½æ–¹æ³•
        print("\n1. æµ‹è¯•æ™ºèƒ½æ ¼å¼æ£€æµ‹æ–¹æ³•:")
        holdings_smart = self.get_fund_holdings_from_api(fund_code, years=[year])
        
        if not holdings_smart.empty:
            print(f"âœ… æ™ºèƒ½æ–¹æ³•æˆåŠŸ! è·å– {len(holdings_smart)} æ¡è®°å½•")
            print("\næ ¼å¼åˆ†å¸ƒ:")
            print(holdings_smart['format'].value_counts())
            print("\nå‰5æ¡è®°å½•:")
            display_cols = ['year', 'quarter', 'rank', 'stock_code', 'stock_name', 'hold_ratio', 'hold_value', 'format']
            print(holdings_smart[display_cols].head().to_string(index=False))
        else:
            print("âŒ æ™ºèƒ½æ–¹æ³•å¤±è´¥")
        
        # æµ‹è¯•HTMLè§£æ
        print("\n2. æµ‹è¯•HTMLä¸“ç”¨è§£æ:")
        url_html = f"https://fundf10.eastmoney.com/FundArchivesDatas.aspx?type=jjcc&code={fund_code}&topline=10&year={year}"
        response_html = self.session.get(url_html, timeout=10)
        match_html = re.search(r'var apidata=(.*?);', response_html.text, re.DOTALL)
        if match_html:
            content_match_html = re.search(r'content:"(.*)"', match_html.group(1), re.DOTALL | re.MULTILINE)
            content_html = content_match_html.group(1) if content_match_html else ''
            format_html = self._detect_content_format(content_html)
            print(f"    æ£€æµ‹æ ¼å¼: {format_html}")
            
            if format_html == 'html':
                holdings_html = self._parse_html_content(content_html, fund_code, year)
                print(f"    HTMLè§£æ: {len(holdings_html)} æ¡è®°å½•")
                if holdings_html:
                    df_html = pd.DataFrame(holdings_html)
                    print(df_html[['quarter', 'rank', 'stock_code', 'stock_name', 'hold_ratio']].head(3).to_string(index=False))
            else:
                print(f"    éHTMLæ ¼å¼: {content_html[:100]}...")
        
        # æµ‹è¯•æ–‡æœ¬è§£æ
        print("\n3. æµ‹è¯•æ–‡æœ¬ä¸“ç”¨è§£æ:")
        # æ¨¡æ‹Ÿæ–‡æœ¬å†…å®¹ï¼ˆåŸºäºä½ çš„ç¤ºä¾‹ï¼‰
        sample_text = f"""å¹¿å‘å…ˆè¿›åˆ¶é€ è‚¡ç¥¨å‘èµ·å¼C  {year}å¹´4å­£åº¦è‚¡ç¥¨æŠ•èµ„æ˜ç»†    æ¥æºï¼šå¤©å¤©åŸºé‡‘    æˆªæ­¢è‡³ï¼š{year}-12-31
åºå·	è‚¡ç¥¨ä»£ç 	è‚¡ç¥¨åç§°	ç›¸å…³èµ„è®¯	å å‡€å€¼
æ¯”ä¾‹	æŒè‚¡æ•°
ï¼ˆä¸‡è‚¡ï¼‰	æŒä»“å¸‚å€¼
ï¼ˆä¸‡å…ƒï¼‰
1	002463	æ²ªç”µè‚¡ä»½	è‚¡å§è¡Œæƒ…	10.21%	134.44	5,330.55
2	300502	æ–°æ˜“ç››	è‚¡å§è¡Œæƒ…	9.27%	41.83	4,835.27"""
        
        holdings_text = self._parse_text_content(sample_text, fund_code, year)
        print(f"    æ–‡æœ¬è§£æ: {len(holdings_text)} æ¡è®°å½•")
        if holdings_text:
            df_text = pd.DataFrame(holdings_text)
            print(df_text[['quarter', 'rank', 'stock_code', 'stock_name', 'hold_ratio']].head().to_string(index=False))
    
    def batch_crawl_fund_holdings(self, fund_list, max_funds=100, years=None, use_backup=False):
        """
        æ‰¹é‡çˆ¬å–åŸºé‡‘æŒä»“æ•°æ® - å¢å¼ºç‰ˆ
        """
        if years is None:
            years = [datetime.now().year]
        
        all_data = []
        failed_funds = []
        successful_funds = []
        format_stats = {}
        
        print(f"\nğŸ”„ å¼€å§‹æ‰¹é‡çˆ¬å– {min(max_funds, len(fund_list))} åªåŸºé‡‘")
        print(f"   çˆ¬å–å¹´ä»½: {', '.join(map(str, years))}")
        print(f"   ä½¿ç”¨æ–¹æ³•: {'å¤‡ä»½æ–¹æ³•' if use_backup else 'æ™ºèƒ½ä¸»æ–¹æ³•'}")
        
        for idx, fund in fund_list.iterrows():
            if idx >= max_funds:
                break
                
            fund_code = fund['fund_code']
            fund_name = fund.get('fund_name', f'åŸºé‡‘{fund_code}')
            print(f"\n[{idx+1}/{min(max_funds, len(fund_list))}] æ­£åœ¨å¤„ç†: {fund_name} ({fund_code})")
            
            # è·å–åŸºé‡‘åŸºæœ¬ä¿¡æ¯
            fund_info = self.get_fund_info(fund_code)
            full_fund_name = fund_info.get('fund_name', fund_name)
            company = fund_info.get('company', 'æœªçŸ¥')
            
            # æ ¹æ®å‚æ•°é€‰æ‹©ä½¿ç”¨ä¸»æ–¹æ³•è¿˜æ˜¯å¤‡ä»½æ–¹æ³•
            if use_backup:
                holdings = self.get_fund_holdings_from_api_backup(fund_code, years)
            else:
                # ä¸»æ–¹æ³•ï¼šæ™ºèƒ½æ ¼å¼æ£€æµ‹
                holdings = self.get_fund_holdings_from_api(fund_code, years)
                
                if holdings.empty:
                    print(f"    æ™ºèƒ½æ–¹æ³•å¤±è´¥ï¼Œå°è¯•Seleniumå¤‡ä»½...")
                    holdings = self.get_fund_holdings(fund_code, years)
                
                if holdings.empty:
                    print(f"    Seleniumå¤‡ä»½ä¹Ÿå¤±è´¥ï¼Œè·³è¿‡æ­¤åŸºé‡‘")
                    failed_funds.append(fund_code)
                    continue
            
            if not holdings.empty:
                # ç»Ÿè®¡æ ¼å¼ä½¿ç”¨æƒ…å†µ
                if 'format' in holdings.columns:
                    for fmt, count in holdings['format'].value_counts().items():
                        format_stats[fmt] = format_stats.get(fmt, 0) + count
                
                # åˆå¹¶åŸºæœ¬ä¿¡æ¯å’ŒæŒä»“æ•°æ®
                holdings['fund_name'] = full_fund_name
                holdings['manager'] = fund_info.get('manager', '')
                holdings['company'] = company
                all_data.append(holdings)
                successful_funds.append(fund_code)
                print(f"    âœ“ æˆåŠŸè·å– {len(holdings)} æ¡è®°å½• (å…¬å¸: {company})")
            else:
                failed_funds.append(fund_code)
                print(f"    âœ— è·å–å¤±è´¥")
            
            # é¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(2)
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        if all_data:
            result_df = pd.concat(all_data, ignore_index=True)
            
            # æ•°æ®è´¨é‡æ£€æŸ¥
            print(f"\nğŸ“Š æ‰¹é‡çˆ¬å–å®Œæˆç»Ÿè®¡:")
            print(f"   æˆåŠŸåŸºé‡‘: {len(successful_funds)} åª")
            print(f"   å¤±è´¥åŸºé‡‘: {len(failed_funds)} åª")
            print(f"   æ€»è®°å½•æ•°: {len(result_df):,}")
            print(f"   æ¶‰åŠè‚¡ç¥¨: {result_df['stock_name'].nunique()}")
            
            if len(result_df) > 0:
                print(f"   å¹³å‡æŒä»“æ¯”ä¾‹: {result_df['hold_ratio'].mean():.2f}%")
                print(f"   æ€»æŒä»“å¸‚å€¼: {result_df['hold_value'].sum():,.2f}ä¸‡å…ƒ")
                
                # æ ¼å¼ç»Ÿè®¡
                if 'format' in result_df.columns:
                    print(f"   æ•°æ®æ ¼å¼: {result_df['format'].value_counts().to_dict()}")
            
            # ä¿å­˜ç»“æœ
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'fund_holdings_{timestamp}.csv'
            output_path = os.path.join(self.output_dir, filename)
            result_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            
            # ä¿å­˜æˆåŠŸåŸºé‡‘åˆ—è¡¨
            success_file = os.path.join(self.output_dir, f'successful_funds_{timestamp}.txt')
            with open(success_file, 'w', encoding='utf-8') as f:
                for code in successful_funds:
                    fund_info = self.get_fund_info(code)
                    f.write(f"{code}\t{fund_info.get('fund_name', 'æœªçŸ¥')}\n")
            
            # ä¿å­˜å¤±è´¥åŸºé‡‘åˆ—è¡¨
            if failed_funds:
                failed_file = os.path.join(self.output_dir, f'failed_funds_{timestamp}.txt')
                with open(failed_file, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(failed_funds))
                print(f"   å¤±è´¥åŸºé‡‘åˆ—è¡¨å·²ä¿å­˜è‡³: {failed_file}")
            
            print(f"\nğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {output_path}")
            print(f"   æˆåŠŸåŸºé‡‘åˆ—è¡¨å·²ä¿å­˜è‡³: {success_file}")
            
            return result_df
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æ•°æ®")
            return pd.DataFrame()
    
    def analyze_holdings(self, holdings_df):
        """
        åˆ†ææŒä»“æ•°æ® - å¢å¼ºç‰ˆ
        """
        if holdings_df.empty:
            print("âŒ æ²¡æœ‰æ•°æ®å¯åˆ†æ")
            return
        
        print("\n" + "="*80)
        print("                    åŸºé‡‘æŒä»“æ•°æ®åˆ†ææŠ¥å‘Š")
        print("="*80)
        
        # 1. åŸºæœ¬ç»Ÿè®¡
        print(f"\nğŸ“Š åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»è®°å½•æ•°: {len(holdings_df):,}")
        print(f"   æ¶‰åŠåŸºé‡‘æ•°: {holdings_df['fund_code'].nunique()}")
        print(f"   æ¶‰åŠè‚¡ç¥¨æ•°: {holdings_df['stock_name'].nunique()}")
        print(f"   æ•°æ®å¹´ä»½èŒƒå›´: {holdings_df['year'].min()}-{holdings_df['year'].max()}")
        
        if 'quarter' in holdings_df.columns:
            quarter_dist = holdings_df['quarter'].value_counts().sort_index()
            print(f"   å­£åº¦åˆ†å¸ƒ: {dict(quarter_dist)}")
        
        if 'format' in holdings_df.columns:
            print(f"   æ•°æ®æ ¼å¼: {holdings_df['format'].value_counts().to_dict()}")
        
        # 2. æŒ‰åŸºé‡‘å…¬å¸ç»Ÿè®¡
        if 'company' in holdings_df.columns and holdings_df['company'].notna().any():
            print(f"\nğŸ¢ å„åŸºé‡‘å…¬å¸æŒä»“æ¦‚è§ˆ (Top 5):")
            company_stats = holdings_df.groupby('company').agg({
                'stock_name': 'nunique',
                'hold_value': 'sum',
                'fund_code': 'nunique'
            }).round(2)
            company_stats.columns = ['æŒä»“è‚¡ç¥¨æ•°', 'æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)', 'ç®¡ç†åŸºé‡‘æ•°']
            company_stats = company_stats.sort_values('æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)', ascending=False).head(5)
            print(company_stats.to_string())
        
        # 3. çƒ­é—¨è‚¡ç¥¨ç»Ÿè®¡
        print(f"\nğŸ”¥ çƒ­é—¨æŒä»“è‚¡ç¥¨ Top 10:")
        hot_stocks = holdings_df.groupby('stock_name').agg({
            'fund_code': 'nunique',
            'hold_value': 'sum'
        }).round(2)
        hot_stocks.columns = ['æŒæœ‰åŸºé‡‘æ•°', 'æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)']
        hot_stocks = hot_stocks.sort_values('æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)', ascending=False).head(10)
        print(hot_stocks.to_string())
        
        # 4. æŒä»“é›†ä¸­åº¦åˆ†æ
        print(f"\nğŸ¯ æŒä»“é›†ä¸­åº¦åˆ†æ (Top 5):")
        concentration = holdings_df.groupby('fund_code').apply(
            lambda x: x['hold_ratio'].sum() if not x.empty else 0
        ).sort_values(ascending=False).head(5)
        
        for fund_code, conc in concentration.items():
            fund_name = holdings_df[holdings_df['fund_code'] == fund_code]['fund_name'].iloc[0] if 'fund_name' in holdings_df.columns else f'åŸºé‡‘{fund_code}'
            print(f"   {fund_name} ({fund_code}): {conc:.1f}%")
        
        print(f"   å¹³å‡é›†ä¸­åº¦: {concentration.mean():.1f}%")
        
        # 5. å¸‚åœºåˆ†å¸ƒåˆ†æ
        if 'stock_code' in holdings_df.columns:
            print(f"\nğŸ“ˆ è‚¡ç¥¨å¸‚åœºåˆ†å¸ƒ:")
            def classify_stock(code):
                if pd.isna(code) or not str(code):
                    return 'æ¸¯è‚¡/å…¶ä»–'
                code_str = str(code).lstrip('0.1').zfill(6)  # æ¸…ç†å‰ç¼€å¹¶è¡¥é½6ä½
                if code_str.startswith('002'):
                    return 'ä¸­å°æ¿'
                elif code_str.startswith('300'):
                    return 'åˆ›ä¸šæ¿'
                elif code_str.startswith('6') or code_str.startswith('688'):
                    return 'ä¸»æ¿'
                else:
                    return 'æ¸¯è‚¡/å…¶ä»–'
            
            holdings_df['market'] = holdings_df['stock_code'].apply(classify_stock)
            
            market_dist = holdings_df.groupby('market').agg({
                'hold_value': 'sum',
                'stock_name': 'nunique'
            }).round(2)
            market_dist.columns = ['æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)', 'è‚¡ç¥¨æ•°']
            if len(market_dist) > 0:
                market_dist['å æ¯”'] = (market_dist['æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)'] / market_dist['æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)'].sum() * 100).round(1)
                print(market_dist.sort_values('æ€»æŒä»“å¸‚å€¼(ä¸‡å…ƒ)', ascending=False).to_string())

def get_fund_codes_from_report(file_path):
    """
    ä»å¸‚åœºç›‘æ§æŠ¥å‘Šä¸­è¯»å–"å¼±ä¹°å…¥"å’Œ"å¼ºä¹°å…¥"çš„åŸºé‡‘ä»£ç ã€‚
    """
    fund_codes = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…"å¼±ä¹°å…¥"æˆ–"å¼ºä¹°å…¥"è¡Œ
            pattern = re.compile(r'\|\s*(\d{6})\s*\|.*?\s*\|\s*(å¼±ä¹°å…¥|å¼ºä¹°å…¥)\s*\|')
            matches = pattern.findall(content)
            for code, signal in matches:
                # ç¡®ä¿æ¯ä¸ªä»£ç åªæ·»åŠ ä¸€æ¬¡
                if code not in fund_codes:
                    fund_codes.append(code)
        print(f"âœ… ä»æŠ¥å‘Šä¸­è·å–åˆ° {len(fund_codes)} ä¸ªå¾…çˆ¬å–çš„åŸºé‡‘ä»£ç ã€‚")
        if fund_codes:
            print(f"   ç¤ºä¾‹: {fund_codes[:5]}...")
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°æ–‡ä»¶ {file_path}")
        # æä¾›é»˜è®¤æµ‹è¯•åŸºé‡‘ä»£ç 
        print("   ä½¿ç”¨é»˜è®¤æµ‹è¯•åŸºé‡‘ä»£ç : 014192")
        return ['014192']
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return []
    
    return fund_codes

def main():
    """ä¸»ç¨‹åº - å¢å¼ºç‰ˆ"""
    crawler = FundDataCrawler()
    
    try:
        print("ğŸš€ å¯åŠ¨åŸºé‡‘æŒä»“æ•°æ®çˆ¬å–ç³»ç»Ÿ")
        print("=" * 60)
        
        # === æµ‹è¯•æ¨¡å¼ï¼ˆæ¨èå…ˆè¿è¡Œæµ‹è¯•ï¼‰ ===
        # å–æ¶ˆä¸‹é¢è¿™è¡Œçš„æ³¨é‡Šæ¥è¿è¡Œæµ‹è¯•
        crawler.test_api_parsing('014192', 2024)
        # return
        
        # æ­¥éª¤1: ä»æŠ¥å‘Šæ–‡ä»¶ä¸­è·å–åŸºé‡‘åˆ—è¡¨
        print("\nğŸ“‹ æ­¥éª¤1: ä»æŠ¥å‘Šä¸­è¯»å–åŸºé‡‘åˆ—è¡¨")
        report_file = 'market_monitor_report.md'
        codes_to_crawl = get_fund_codes_from_report(report_file)
        
        if not codes_to_crawl:
            print("âŒ æœªæ‰¾åˆ°éœ€è¦çˆ¬å–çš„åŸºé‡‘ä»£ç ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•åŸºé‡‘")
            fund_list_df = pd.DataFrame({
                'fund_code': ['014192'], 
                'fund_name': ['å¹¿å‘å…ˆè¿›åˆ¶é€ è‚¡ç¥¨å‘èµ·å¼C']
            })
        else:
            # å°†ä»£ç åˆ—è¡¨è½¬æ¢ä¸ºDataFrameæ ¼å¼ä»¥é€‚åº”åŸæœ‰å‡½æ•°
            fund_list_df = pd.DataFrame({'fund_code': codes_to_crawl, 'fund_name': ''})
        
        print(f"ğŸ“ˆ å‡†å¤‡å¤„ç† {len(fund_list_df)} åªåŸºé‡‘")
        
        # æ­¥éª¤2: æ‰¹é‡çˆ¬å–æŒä»“æ•°æ®
        print(f"\nğŸ” æ­¥éª¤2: æ‰¹é‡çˆ¬å–æŒä»“æ•°æ®")
        years_to_crawl = [2024, 2023, 2022]  # æ›´æ–°ä¸ºå®é™…å¯ç”¨å¹´ä»½
        
        # å¯ä»¥è®¾ç½® use_backup=True ä½¿ç”¨å¤‡ä»½æ–¹æ³•è¿›è¡Œæµ‹è¯•
        holdings_data = crawler.batch_crawl_fund_holdings(
            fund_list_df, 
            max_funds=len(fund_list_df),
            years=years_to_crawl,
            use_backup=False  # Falseä½¿ç”¨æ™ºèƒ½ä¸»æ–¹æ³•ï¼ŒTrueä½¿ç”¨å¤‡ä»½æ–¹æ³•
        )
        
        # æ­¥éª¤3: æ•°æ®åˆ†æ
        if not holdings_data.empty:
            print(f"\nğŸ“Š æ­¥éª¤3: æ•°æ®åˆ†æ")
            crawler.analyze_holdings(holdings_data)
        else:
            print("âŒ æœªè·å–åˆ°ä»»ä½•æŒä»“æ•°æ®")
            print("ğŸ’¡ å»ºè®®: è¿è¡Œæµ‹è¯•æ¨¡å¼æ£€æŸ¥APIæ˜¯å¦æ­£å¸¸")
            print("   åœ¨main()å‡½æ•°ä¸­å–æ¶ˆ test_api_parsing() çš„æ³¨é‡Š")
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        crawler.close_driver()
        print("\nğŸ‘‹ ç¨‹åºç»“æŸï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")

def quick_test():
    """å¿«é€Ÿæµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯• - å•ä¸ªåŸºé‡‘")
    crawler = FundDataCrawler()
    
    # æµ‹è¯•å•ä¸ªåŸºé‡‘
    fund_code = '014192'
    year = 2024
    holdings = crawler.get_fund_holdings_from_api(fund_code, years=[year])
    
    if not holdings.empty:
        print(f"âœ… æµ‹è¯•æˆåŠŸ! è·å– {len(holdings)} æ¡è®°å½•")
        print(f"\næ•°æ®æ ¼å¼åˆ†å¸ƒ: {holdings['format'].value_counts().to_dict()}")
        print("\nå‰10æ¡æŒä»“:")
        display_cols = ['year', 'quarter', 'rank', 'stock_code', 'stock_name', 'hold_ratio', 'hold_shares', 'hold_value', 'format']
        print(holdings[display_cols].head(10).to_string(index=False))
        
        # ç®€å•åˆ†æ
        print(f"\nğŸ“ˆ å¿«é€Ÿåˆ†æ:")
        print(f"   æ€»æŒä»“æ¯”ä¾‹: {holdings['hold_ratio'].sum():.2f}%")
        print(f"   æ€»æŒä»“å¸‚å€¼: {holdings['hold_value'].sum():,.2f}ä¸‡å…ƒ")
        print(f"   Top3æŒä»“:")
        top3 = holdings.nlargest(3, 'hold_value')[['quarter', 'stock_name', 'hold_ratio', 'hold_value']]
        for _, row in top3.iterrows():
            print(f"     Q{row['quarter']} - {row['stock_name']}: {row['hold_ratio']:.1f}% ({row['hold_value']:,.0f}ä¸‡å…ƒ)")
    else:
        print("âŒ æµ‹è¯•å¤±è´¥")
        print("ğŸ’¡ å°è¯•ä½¿ç”¨å¤‡ä»½æ–¹æ³•:")
        holdings_backup = crawler.get_fund_holdings_from_api_backup(fund_code, years=[year])
        if not holdings_backup.empty:
            print(f"âœ… å¤‡ä»½æ–¹æ³•æˆåŠŸ: {len(holdings_backup)} æ¡è®°å½•")
        else:
            print("âŒ æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
    
    crawler.close_driver()

if __name__ == "__main__":
    # è¿è¡Œå¿«é€Ÿæµ‹è¯•
    # quick_test()
    
    # è¿è¡Œä¸»ç¨‹åº
    main()
