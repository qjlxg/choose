import pandas as pd
import glob
import os
import sys
from datetime import datetime

def load_stock_categories(category_path):
    """
    åŠ è½½è‚¡ç¥¨åˆ†ç±»æ•°æ®ï¼Œä¿æŒåŸæœ‰é€»è¾‘ä½†å¢å¼ºé”™è¯¯å¤„ç†å’Œæ€§èƒ½
    """
    all_categories = {}
    xlsx_files = glob.glob(os.path.join(category_path, "*.xlsx"))
    
    if not xlsx_files:
        print(f"âš ï¸  åœ¨ '{category_path}' ç›®å½•ä¸­æœªæ‰¾åˆ° XLSX æ–‡ä»¶")
        return all_categories

    for f in xlsx_files:
        try:
            category_name = os.path.basename(f).split('.')[0]
            df = pd.read_excel(f, header=0, engine='openpyxl')
            
            # ä¸¥æ ¼æ£€æŸ¥å¿…è¦åˆ—
            if 'è‚¡ç¥¨ä»£ç ' not in df.columns or 'è‚¡ç¥¨åç§°' not in df.columns:
                print(f"âš ï¸  æ–‡ä»¶ {f} ç¼ºå°‘å¿…è¦åˆ—ï¼Œè·³è¿‡")
                continue
            
            # æ‰¹é‡å¤„ç†ï¼Œé¿å…å¾ªç¯
            df['è‚¡ç¥¨ä»£ç '] = df['è‚¡ç¥¨ä»£ç '].astype(str).str.strip().str.zfill(6)
            new_categories = dict(zip(df['è‚¡ç¥¨ä»£ç '], [category_name] * len(df)))
            
            # åˆå¹¶åˆ†ç±»ï¼Œä¼˜å…ˆä½¿ç”¨å·²å­˜åœ¨çš„
            for code, cat in new_categories.items():
                if code not in all_categories:
                    all_categories[code] = cat
                    
        except Exception as e:
            print(f"âŒ è¯»å– {f} å‡ºé”™: {e}")
            continue
    
    print(f"âœ… åŠ è½½äº† {len(all_categories)} åªè‚¡ç¥¨çš„åˆ†ç±»")
    return all_categories

def clean_dataframe(df, fund_code, use_detailed_categories, stock_categories, sector_mapping):
    """
    é›†ä¸­å¤„ç†æ•°æ®æ¸…æ´—é€»è¾‘
    """
    # åˆ—åæ ‡å‡†åŒ–
    column_mapping = {
        'å å‡€å€¼ æ¯”ä¾‹': 'å å‡€å€¼æ¯”ä¾‹', 
        'å å‡€å€¼æ¯”ä¾‹': 'å å‡€å€¼æ¯”ä¾‹',
        'æŒä»“å¸‚å€¼ ï¼ˆä¸‡å…ƒï¼‰': 'æŒä»“å¸‚å€¼',
        'æŒä»“å¸‚å€¼': 'æŒä»“å¸‚å€¼',
        'å¸‚å€¼': 'æŒä»“å¸‚å€¼',
        'æŒä»“å¸‚å€¼ ï¼ˆä¸‡å…ƒäººæ°‘å¸ï¼‰': 'æŒä»“å¸‚å€¼',
        'è‚¡ç¥¨åç§°': 'è‚¡ç¥¨åç§°',
        'è‚¡ç¥¨ä»£ç ': 'è‚¡ç¥¨ä»£ç ',
        'å­£åº¦': 'å­£åº¦'
    }
    
    df.columns = [column_mapping.get(col, col) for col in df.columns]

    # éªŒè¯å¿…è¦åˆ—
    required_cols = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'å å‡€å€¼æ¯”ä¾‹', 'æŒä»“å¸‚å€¼', 'å­£åº¦']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        raise ValueError(f"ç¼ºå°‘åˆ—: {missing_cols}")

    # æ¸…æ´—å å‡€å€¼æ¯”ä¾‹
    df['å å‡€å€¼æ¯”ä¾‹'] = (df['å å‡€å€¼æ¯”ä¾‹']
                       .astype(str)
                       .str.replace('%', '', regex=False)
                       .str.replace(',', '', regex=False)
                       .pipe(pd.to_numeric, errors='coerce'))
    
    # æ¸…æ´—è‚¡ç¥¨ä»£ç 
    df['è‚¡ç¥¨ä»£ç '] = df['è‚¡ç¥¨ä»£ç '].astype(str).str.strip().str.zfill(6)
    
    # æ·»åŠ è¡Œä¸šåˆ†ç±»
    if use_detailed_categories and stock_categories:
        df['è¡Œä¸š'] = df['è‚¡ç¥¨ä»£ç '].map(stock_categories).fillna('å…¶ä»–')
    else:
        df['è¡Œä¸š'] = df['è‚¡ç¥¨ä»£ç '].str[:3].map(sector_mapping).fillna('å…¶ä»–')
    
    df['åŸºé‡‘ä»£ç '] = fund_code
    return df

def process_temporal_data(df):
    """
    å¤„ç†æ—¶é—´ç»´åº¦æ•°æ®
    """
    df = df.copy()
    
    # æ ‡å‡†åŒ–å­£åº¦æ ¼å¼
    df['å­£åº¦'] = df['å­£åº¦'].astype(str).str.replace('å¹´', '-Q', regex=False)
    
    # æå–å¹´ä»½å’Œå­£åº¦ç¼–å·
    df['å¹´ä»½'] = df['å­£åº¦'].str.split('-').str[0].astype(int)
    df['å­£åº¦ç¼–å·'] = (df['å­£åº¦']
                     .str.split('-')
                     .str[1]
                     .str.replace('å­£åº¦', '')
                     .astype(int))
    
    # æŒ‰æ—¶é—´æ’åº
    df = df.sort_values(['å¹´ä»½', 'å­£åº¦ç¼–å·']).reset_index(drop=True)
    return df

def analyze_single_fund(fund_code, files, stock_categories, use_detailed_categories, sector_mapping):
    """
    åˆ†æå•ä¸ªåŸºé‡‘çš„æ ¸å¿ƒé€»è¾‘
    """
    df_list = []
    
    for f in files:
        try:
            df = pd.read_csv(f, encoding='utf-8')
            df = clean_dataframe(df, fund_code, use_detailed_categories, 
                               stock_categories, sector_mapping)
            df_list.append(df)
        except Exception as e:
            print(f"âš ï¸  å¤„ç† {f} å‡ºé”™: {e}")
            continue
    
    if not df_list:
        return []
    
    # åˆå¹¶å¹¶å¤„ç†æ—¶é—´æ•°æ®
    combined_df = pd.concat(df_list, ignore_index=True)
    combined_df = process_temporal_data(combined_df)
    
    return generate_fund_report(fund_code, combined_df)

def generate_fund_report(fund_code, df):
    """
    ç”Ÿæˆå•ä¸ªåŸºé‡‘çš„æŠ¥å‘Šï¼Œä¿æŒåŸæœ‰é€»è¾‘
    """
    report = [f"## åŸºé‡‘ä»£ç : {fund_code} æŒä»“åˆ†ææŠ¥å‘Š", "---"]
    
    # æœªåˆ†ç±»è‚¡ç¥¨
    unclassified_stocks = df[df['è¡Œä¸š'] == 'å…¶ä»–']
    if not unclassified_stocks.empty:
        report.extend(generate_unclassified_section(unclassified_stocks))
    
    # é‡ä»“è‚¡å˜åŠ¨
    report.extend(generate_stock_changes_section(df))
    
    # è¡Œä¸šåå¥½å’Œé›†ä¸­åº¦
    report.extend(generate_sector_analysis_section(df))
    
    # è¶‹åŠ¿æ€»ç»“
    report.extend(generate_trend_summary_section(df))
    
    return report

def generate_unclassified_section(unclassified_stocks):
    """ç”Ÿæˆæœªåˆ†ç±»è‚¡ç¥¨éƒ¨åˆ†"""
    lines = ["\n### æœªèƒ½åŒ¹é…åˆ°è¡Œä¸šåˆ†ç±»çš„è‚¡ç¥¨åˆ—è¡¨", "---"]
    
    for quarter, group in unclassified_stocks.groupby('å­£åº¦'):
        lines.append(f"#### {quarter}")
        for _, row in group.iterrows():
            lines.append(f"- **{row['è‚¡ç¥¨åç§°']}** ({row['è‚¡ç¥¨ä»£ç ']}): {row['å å‡€å€¼æ¯”ä¾‹']:.2f}%")
    
    lines.append("---\n")
    return lines

def generate_stock_changes_section(df):
    """ç”Ÿæˆé‡ä»“è‚¡å˜åŠ¨éƒ¨åˆ†"""
    lines = ["### 1. é‡ä»“è‚¡å˜åŠ¨"]
    quarters = sorted(df['å­£åº¦'].unique())
    
    for i in range(len(quarters) - 1):
        current_q = quarters[i]
        next_q = quarters[i + 1]
        
        current_holdings = set(df[df['å­£åº¦'] == current_q]['è‚¡ç¥¨ä»£ç '])
        next_holdings = set(df[df['å­£åº¦'] == next_q]['è‚¡ç¥¨ä»£ç '])
        
        new_additions = next_holdings - current_holdings
        removed = current_holdings - next_holdings
        
        lines.append(f"\n#### ä» {current_q} åˆ° {next_q} çš„å˜åŠ¨")
        
        if new_additions:
            new_stocks = (df[(df['å­£åº¦'] == next_q) & 
                           (df['è‚¡ç¥¨ä»£ç '].isin(new_additions))]['è‚¡ç¥¨åç§°']
                         .tolist())
            lines.append(f"- **æ–°å¢è‚¡ç¥¨**ï¼š{', '.join(new_stocks)}")
        
        if removed:
            removed_stocks = (df[(df['å­£åº¦'] == current_q) & 
                               (df['è‚¡ç¥¨ä»£ç '].isin(removed))]['è‚¡ç¥¨åç§°']
                             .tolist())
            lines.append(f"- **ç§»é™¤è‚¡ç¥¨**ï¼š{', '.join(removed_stocks)}")
    
    return lines

def generate_sector_analysis_section(df):
    """ç”Ÿæˆè¡Œä¸šåˆ†æéƒ¨åˆ†"""
    lines = ["### 2. è¡Œä¸šåå¥½å’ŒæŒä»“é›†ä¸­åº¦"]
    
    # è¡Œä¸šæ±‡æ€»
    sector_summary = df.groupby(['å¹´ä»½', 'è¡Œä¸š'])['å å‡€å€¼æ¯”ä¾‹'].sum().unstack().fillna(0)
    
    lines.append("\n#### è¡Œä¸šåå¥½ï¼ˆå å‡€å€¼æ¯”ä¾‹ä¹‹å’Œï¼‰")
    # æ ¼å¼åŒ–è¡¨æ ¼è¾“å‡º
    formatted_table = sector_summary.round(2).applymap(lambda x: f"{x:.2f}%" if x > 0 else "")
    lines.append(formatted_table.to_markdown())
    
    # é›†ä¸­åº¦
    concentration_summary = df.groupby('å­£åº¦')['å å‡€å€¼æ¯”ä¾‹'].sum()
    
    lines.append("\n#### å‰åå¤§æŒä»“é›†ä¸­åº¦ï¼ˆå å‡€å€¼æ¯”ä¾‹ä¹‹å’Œï¼‰")
    conc_df = pd.DataFrame({
        'å­£åº¦': concentration_summary.index,
        'é›†ä¸­åº¦': concentration_summary.round(2).apply(lambda x: f"{x:.2f}%")
    })
    lines.append(conc_df.to_markdown(index=False))
    
    return lines

def generate_trend_summary_section(df):
    """ç”Ÿæˆè¶‹åŠ¿æ€»ç»“éƒ¨åˆ†"""
    lines = ["\n### 3. è¶‹åŠ¿æ€»ç»“å’ŒæŠ•èµ„å»ºè®®"]
    
    # å…è´£å£°æ˜
    lines.append("> **å…è´£å£°æ˜**ï¼šæœ¬æŠ¥å‘ŠåŸºäºå†å²æŒä»“æ•°æ®è¿›è¡Œåˆ†æï¼Œä¸æ„æˆä»»ä½•æŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚")
    
    # é›†ä¸­åº¦åˆ†æ
    concentration_summary = df.groupby('å­£åº¦')['å å‡€å€¼æ¯”ä¾‹'].sum()
    if len(concentration_summary) > 1:
        first_concentration = concentration_summary.iloc[0]
        last_concentration = concentration_summary.iloc[-1]
        concentration_diff = last_concentration - first_concentration
        
        if concentration_diff > 10:
            trend_desc = "æ˜¾è‘—**ä¸Šå‡**"
        elif concentration_diff < -10:
            trend_desc = "æ˜¾è‘—**ä¸‹é™**"
        else:
            trend_desc = "ç›¸å¯¹**ç¨³å®š**"
        
        lines.append(f"- **æŒä»“é›†ä¸­åº¦**ï¼šåœ¨åˆ†ææœŸå†…ï¼Œè¯¥åŸºé‡‘çš„æŒä»“é›†ä¸­åº¦{trend_desc}ã€‚")
    
    # è¡Œä¸šåå¥½åˆ†æ
    sector_summary = df.groupby(['å¹´ä»½', 'è¡Œä¸š'])['å å‡€å€¼æ¯”ä¾‹'].sum().unstack().fillna(0)
    if len(sector_summary) > 1:
        try:
            first_year_summary = sector_summary.iloc[0]
            last_year_summary = sector_summary.iloc[-1]
            
            first_dominant_sector = first_year_summary.idxmax()
            last_dominant_sector = last_year_summary.idxmax()
            
            if first_dominant_sector != last_dominant_sector:
                lines.append(f"- **è¡Œä¸šåå¥½**ï¼šåŸºé‡‘çš„æŠ•èµ„åå¥½å‘ç”Ÿäº†æ˜æ˜¾å˜åŒ–ï¼Œä»**{first_dominant_sector}**è½¬å‘äº†**{last_dominant_sector}**ã€‚")
            else:
                lines.append(f"- **è¡Œä¸šåå¥½**ï¼šè¯¥åŸºé‡‘åœ¨åˆ†ææœŸå†…ä¸»è¦åå‘äº**{first_dominant_sector}**è¡Œä¸šã€‚")
        except ValueError:
            lines.append("- **è¡Œä¸šåå¥½**ï¼šç”±äºæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æè¡Œä¸šåå¥½å˜åŒ–ã€‚")
    
    # æŠ•èµ„å»ºè®®
    lines.extend([
        "",
        "**æ€»ç»“ä¸å»ºè®®ï¼š**",
        "  åœ¨è€ƒè™‘æŠ•èµ„è¯¥åŸºé‡‘æ—¶ï¼Œå»ºè®®å°†ä¸Šè¿°åˆ†æç»“æœä¸å…¶ä»–å› ç´ ç»“åˆè€ƒé‡ï¼Œä¾‹å¦‚åŸºé‡‘çš„è¿‡å¾€ä¸šç»©ã€åŸºé‡‘ç»ç†çš„ç®¡ç†ç»éªŒã€åŸºé‡‘è§„æ¨¡ä»¥åŠè´¹ç‡ç­‰ã€‚"
    ])
    
    return lines

def analyze_holdings():
    """
    ä¸»åˆ†æå‡½æ•°ï¼Œä¼˜åŒ–åçš„ç‰ˆæœ¬
    """
    base_path = 'fund_data'
    category_path = 'åˆ†ç±»è¡¨'
    
    print("ğŸ”„ å¼€å§‹åˆ†æåŸºé‡‘æŒä»“æ•°æ®...")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    all_files = glob.glob(os.path.join(base_path, "*.csv"))
    if not all_files:
        print("âŒ åœ¨ 'fund_data' ç›®å½•ä¸­æœªæ‰¾åˆ° CSV æ–‡ä»¶")
        return

    # åŠ è½½åˆ†ç±»
    stock_categories = load_stock_categories(category_path)
    use_detailed_categories = bool(stock_categories)
    
    if not use_detailed_categories:
        print("âš ï¸  ä½¿ç”¨é»˜è®¤æ¿å—åˆ†ç±»")
        sector_mapping = {
            '688': 'ç§‘åˆ›æ¿', '300': 'åˆ›ä¸šæ¿', '002': 'ä¸­å°æ¿',
            '000': 'ä¸»æ¿', '600': 'ä¸»æ¿', '601': 'ä¸»æ¿',
            '603': 'ä¸»æ¿', '605': 'ä¸»æ¿', '005': 'ä¸»æ¿', '006': 'ä¸»æ¿',
        }
    else:
        sector_mapping = None

    # æŒ‰åŸºé‡‘åˆ†ç»„æ–‡ä»¶
    fund_files = {}
    for f in all_files:
        try:
            # è§£ææ–‡ä»¶åï¼šå‡è®¾æ ¼å¼ä¸º *_{fund_code}_*.csv
            filename = os.path.basename(f)
            if '_' not in filename:
                continue
                
            parts = filename.split('_')
            # æŸ¥æ‰¾åŸºé‡‘ä»£ç ï¼ˆé€šå¸¸æ˜¯6ä½æ•°å­—ï¼‰
            fund_code = None
            for part in parts:
                if part.isdigit() and len(part) == 6:
                    fund_code = part
                    break
            
            if fund_code and fund_code not in fund_files:
                fund_files[fund_code] = []
            
            if fund_code:
                fund_files[fund_code].append(f)
                
        except Exception:
            continue

    if not fund_files:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆåŸºé‡‘æ–‡ä»¶")
        return

    print(f"ğŸ“Š å‘ç° {len(fund_files)} åªåŸºé‡‘ï¼Œå¼€å§‹åˆ†æ...")

    # ç”ŸæˆæŠ¥å‘Š
    report = [f"# åŸºé‡‘æŒä»“åˆ†ææŠ¥å‘Š", 
              f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
              "", "---", ""]

    for fund_code, files in fund_files.items():
        print(f"  åˆ†æåŸºé‡‘: {fund_code} ({len(files)} ä¸ªå­£åº¦)")
        fund_report = analyze_single_fund(fund_code, files, stock_categories, 
                                        use_detailed_categories, sector_mapping)
        report.extend(fund_report)

    # ä¿å­˜æŠ¥å‘Š
    with open('analysis_report.md', 'w', encoding='utf-8') as f:
        f.write('\n'.join(report))
    
    print(f"âœ… åˆ†æå®Œæˆï¼ŒæŠ¥å‘Šå·²ä¿å­˜: analysis_report.md")

if __name__ == "__main__":
    analyze_holdings()
