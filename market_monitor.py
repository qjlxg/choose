# -*- coding: UTF-8 -*-

import os
import re
import random
import time as time_module
import pandas as pd
import numpy as np
from datetime import date, datetime, timedelta
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from tenacity import retry, stop_after_attempt, wait_fixed, after_log

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

# å¸¸é‡è®¾ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
FUND_DATA_DIR = os.path.join(BASE_DIR, 'fund_data')
REPORT_FILE = os.path.join(BASE_DIR, 'analysis_report.md')
HOLIDAYS_FILE = os.path.join(BASE_DIR, 'holidays.txt')
HOLIDAYS_URL = "http://www.szse.cn/api/report/ShowReport?SHOWTYPE=xlsx&CATALOGID=1803&tab1PAGENO=1&tab1PAGECOUNT=50&tab1CATEGORY=1073&tab1KEYWORD=%E4%BC%91%E5%B8%82&tab1CURPAGE=1&random=0.291775794770026"

# ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
os.makedirs(FUND_DATA_DIR, exist_ok=True)

class MarketMonitor:
    """
    ä¸€ä¸ªå®Œæ•´çš„åŸºé‡‘å¸‚åœºç›‘æ§ä¸æŠ€æœ¯åˆ†æç³»ç»Ÿã€‚
    """
    def __init__(self, filter_mode='strong_buy', top_n=5, holdings=None):
        """
        åˆå§‹åŒ– MarketMonitorã€‚

        Args:
            filter_mode (str): è¿‡æ»¤æ¨¡å¼ï¼Œå¯é€‰ 'strong_buy', 'low_rsi_buy' ç­‰ã€‚
            top_n (int): åœ¨æŠ¥å‘Šä¸­æ˜¾ç¤ºçš„å‰ N ä¸ªåŸºé‡‘ã€‚
            holdings (list): ç”¨æˆ·æŒä»“åŸºé‡‘ä»£ç åˆ—è¡¨ã€‚
        """
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.fund_codes = self._get_fund_codes_from_report()
        self.sh_index_data = self._get_sh_index_data()
        self.filter_mode = filter_mode
        self.top_n = top_n
        self.holdings = holdings if holdings else []
        self.holidays = self._get_holidays()

    def _get_fund_codes_from_report(self):
        """
        ä» analysis_report.md ä¸­æå–åŸºé‡‘ä»£ç åˆ—è¡¨ã€‚
        """
        try:
            with open(REPORT_FILE, 'r', encoding='utf-8') as f:
                content = f.read()
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ä»£ç å—ä¸­çš„åŸºé‡‘ä»£ç 
            matches = re.findall(r"```python\s*funds = \[(.*?)\]\s*```", content, re.DOTALL)
            if matches:
                codes = matches[0].replace("'", "").replace('"', "").replace(" ", "").split(',')
                logging.info(f"ä»æŠ¥å‘Šä¸­æˆåŠŸæå– {len(codes)} ä¸ªåŸºé‡‘ä»£ç ã€‚")
                return [code for code in codes if code]
        except FileNotFoundError:
            logging.error(f"æŠ¥å‘Šæ–‡ä»¶æœªæ‰¾åˆ°ï¼š{REPORT_FILE}")
        return []

    def _get_holidays(self):
        """
        è·å–èŠ‚å‡æ—¥ä¿¡æ¯ï¼Œä¼˜å…ˆä»æœ¬åœ°æ–‡ä»¶åŠ è½½ï¼Œå¦åˆ™ä»ç½‘ç»œçˆ¬å–ã€‚
        """
        if os.path.exists(HOLIDAYS_FILE):
            with open(HOLIDAYS_FILE, 'r', encoding='utf-8') as f:
                return {line.strip() for line in f}
        try:
            response = self.session.get(HOLIDAYS_URL, timeout=10)
            df = pd.read_excel(response.content, engine='openpyxl')
            holidays = set(df['èŠ‚å‡æ—¥'].dt.strftime('%Y-%m-%d'))
            with open(HOLIDAYS_FILE, 'w', encoding='utf-8') as f:
                for h in holidays:
                    f.write(f"{h}\n")
            logging.info(f"æˆåŠŸè·å–å¹¶ç¼“å­˜äº† {len(holidays)} ä¸ªèŠ‚å‡æ—¥ã€‚")
            return holidays
        except Exception as e:
            logging.error(f"æ— æ³•è·å–èŠ‚å‡æ—¥ä¿¡æ¯ï¼š{e}")
            return set()

    def _get_sh_index_data(self):
        """
        è·å–æ²ªæ·±300æŒ‡æ•°æ•°æ®ã€‚
        """
        try:
            url = "http://push2.eastmoney.com/api/qt/stock/kline/get?cb=jQuery112404095400977226164_1625463137537&secid=1.000300&ut=fa5fd1943c7112009228b3f17d721a71&fields1=f1%2Cf2%2Cf3%2Cf4%2Cf5&fields2=f51%2Cf52%2Cf53%2Cf54%2Cf55%2Cf56%2Cf57%2Cf58%2Cf59%2Cf60%2Cf61&klt=101&fqt=1&end=20500101&lmt=120"
            response = self.session.get(url, timeout=10)
            match = re.search(r'\(({.*?})\)', response.text)
            if not match:
                raise ValueError("æ— æ³•è§£ææŒ‡æ•°æ•°æ®ã€‚")
            data = pd.DataFrame(eval(match.group(1))['data']['klines']).iloc[::-1]
            data.columns = ['date', 'open', 'close', 'high', 'low', 'volume', 'turnover', 'amplitude', 'change_percent', 'change_amount']
            data['date'] = pd.to_datetime(data['date']).dt.date
            data['change_percent'] = pd.to_numeric(data['change_percent'])
            return data
        except Exception as e:
            logging.error(f"è·å–å¤§ç›˜æ•°æ®å¤±è´¥ï¼š{e}")
            return pd.DataFrame()

    def _get_market_trend(self):
        """
        æ ¹æ®æœ€è¿‘äº¤æ˜“æ—¥çš„å¤§ç›˜æ¶¨è·Œæƒ…å†µåˆ¤æ–­å¸‚åœºè¶‹åŠ¿ã€‚
        """
        if self.sh_index_data.empty:
            return 'æœªçŸ¥'
        
        today = date.today()
        latest_trading_date_df = self.sh_index_data[self.sh_index_data['date'] <= today].iloc[-1]
        
        change_percent = latest_trading_date_df['change_percent']
        trend_date = latest_trading_date_df['date'].strftime('%Y-%m-%d')
        
        if change_percent > 1.5:
            trend = "å¼ºåŠ¿"
        elif change_percent > 0:
            trend = "æ¸©å’Œ"
        elif change_percent < -1.5:
            trend = "å¼±åŠ¿"
        else:
            trend = "éœ‡è¡"
        
        logging.info(f"å¤§ç›˜è¶‹åŠ¿ ({trend_date}): {trend} ({change_percent:.2f}%)")
        return trend

    @retry(stop=stop_after_attempt(3), wait=wait_fixed(2), after=after_log(logging.getLogger(__name__), logging.WARNING))
    def _fetch_fund_data(self, fund_code, page_index=1):
        """
        ä»ä¸œè´¢ API çˆ¬å–å•é¡µåŸºé‡‘å†å²å‡€å€¼æ•°æ®ã€‚
        """
        url = f"http://fund.eastmoney.com/f10/F10DataApi.aspx?type=lsjz&code={fund_code}&page={page_index}&per=20"
        try:
            response = self.session.get(url, timeout=10)
            response.raise_for_status()
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–åŒ…å«æ•°æ®çš„å­—ç¬¦ä¸²
            match = re.search(r'content:"(.*?)",records', response.text, re.DOTALL)
            if not match:
                logging.warning(f"åŸºé‡‘ {fund_code} APIè¿”å›å†…å®¹ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
                return None, 0, 0
            
            html_content = match.group(1).replace('\\"', '"').replace('\\n', '')
            
            # ä½¿ç”¨ pandas è§£æ HTML è¡¨æ ¼
            tables = pd.read_html(html_content)
            if not tables or tables[0].empty:
                return None, 0, 0
                
            df = tables[0]
            
            # åŠ¨æ€å¤„ç†ä¸åŒåˆ—æ•°çš„æƒ…å†µ
            num_cols = df.shape[1]
            if num_cols == 7:
                # æ­£å¸¸ä¸ƒåˆ—ï¼ˆè‚¡ç¥¨/æ··åˆåŸºé‡‘ï¼‰
                df.columns = ['date', 'net_value', 'accum_net_value', 'daily_growth', 'purchase_status', 'redemption_status', 'dividend_info']
                df['net_value'] = pd.to_numeric(df['net_value'], errors='coerce')
                logging.info(f"åŸºé‡‘ {fund_code} APIè¿”å›7åˆ—æ•°æ®")
            elif num_cols == 6:
                # ä¿®æ­£ï¼šå¤„ç†è´§å¸åŸºé‡‘è¿”å›çš„6åˆ—æ•°æ®
                # å¤´éƒ¨æ˜¯ å‡€å€¼æ—¥æœŸ, æ¯ä¸‡ä»½æ”¶ç›Š, 7æ—¥å¹´åŒ–æ”¶ç›Šç‡ï¼ˆ%ï¼‰, ç”³è´­çŠ¶æ€, èµå›çŠ¶æ€, åˆ†çº¢é€é…
                # è¿™é‡Œå°† 'æ¯ä¸‡ä»½æ”¶ç›Š' ä½œä¸ºå‡€å€¼æ¥è®¡ç®—æŒ‡æ ‡
                df.columns = ['date', 'yield_per_10k', 'annualized_yield_7d', 'purchase_status', 'redemption_status', 'dividend_info']
                df['net_value'] = pd.to_numeric(df['yield_per_10k'], errors='coerce')
                df['accum_net_value'] = np.nan # ç´¯ç§¯å‡€å€¼ä¸å­˜åœ¨ï¼Œè®¾ç½®ä¸ºNaN
                df['daily_growth'] = np.nan # æ—¥å¢é•¿ç‡ä¸å­˜åœ¨ï¼Œè®¾ç½®ä¸ºNaN
                logging.warning(f"åŸºé‡‘ {fund_code} APIè¿”å›6åˆ—æ•°æ®ï¼Œå·²å°† 'æ¯ä¸‡ä»½æ”¶ç›Š' ä½œä¸ºå‡€å€¼å¤„ç†ã€‚")
            else:
                logging.error(f"åŸºé‡‘ {fund_code} è¿”å›äº†æœªçŸ¥åˆ—æ•° ({num_cols}) çš„æ•°æ®ï¼Œè·³è¿‡ã€‚")
                return None, 0, 0
                
            # æå–æ€»è®°å½•æ•°å’Œæ€»é¡µæ•°
            records = int(re.search(r'records:(\d+)', response.text).group(1))
            pages = int(re.search(r'pages:(\d+)', response.text).group(1))
            
            df['date'] = pd.to_datetime(df['date']).dt.date
            
            return df, records, pages
        except Exception as e:
            logging.error(f"åŸºé‡‘ {fund_code} åœ¨ç¬¬ {page_index} é¡µçˆ¬å–å¤±è´¥: {e}")
            return None, 0, 0

    def _read_local_data(self, fund_code):
        """
        è¯»å–æœ¬åœ°ç¼“å­˜çš„åŸºé‡‘æ•°æ®ã€‚
        """
        filepath = os.path.join(FUND_DATA_DIR, f"{fund_code}.csv")
        if os.path.exists(filepath):
            try:
                df = pd.read_csv(filepath, parse_dates=['date'])
                df['date'] = df['date'].dt.date
                logging.info(f"æˆåŠŸè¯»å–åŸºé‡‘ {fund_code} çš„æœ¬åœ°ç¼“å­˜æ•°æ®ã€‚")
                return df
            except Exception as e:
                logging.warning(f"è¯»å–åŸºé‡‘ {fund_code} æœ¬åœ°ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
        return pd.DataFrame()

    def _save_to_local_file(self, df, fund_code):
        """
        ä¿å­˜åŸºé‡‘æ•°æ®åˆ°æœ¬åœ°æ–‡ä»¶ã€‚
        """
        filepath = os.path.join(FUND_DATA_DIR, f"{fund_code}.csv")
        try:
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            logging.info(f"æˆåŠŸå°†åŸºé‡‘ {fund_code} æ•°æ®ä¿å­˜åˆ°æœ¬åœ°ã€‚")
        except Exception as e:
            logging.error(f"ä¿å­˜åŸºé‡‘ {fund_code} æ•°æ®åˆ°æœ¬åœ°å¤±è´¥: {e}")

    def _calculate_indicators(self, df):
        """
        è®¡ç®—åŸºé‡‘çš„æŠ€æœ¯æŒ‡æ ‡ã€‚
        """
        df = df.sort_values(by='date')
        df['net_value'] = pd.to_numeric(df['net_value'], errors='coerce')
        
        # MACD
        df['ema12'] = df['net_value'].ewm(span=12, adjust=False).mean()
        df['ema26'] = df['net_value'].ewm(span=26, adjust=False).mean()
        df['macd'] = df['ema12'] - df['ema26']
        df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()
        df['macd_diff'] = df['macd'] - df['signal']
        
        # RSI
        delta = df['net_value'].diff(1)
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / loss
        df['rsi'] = 100 - (100 / (1 + rs))

        # å¸ƒæ—å¸¦ (BBands)
        df['ma20'] = df['net_value'].rolling(window=20).mean()
        df['std20'] = df['net_value'].rolling(window=20).std()
        df['upper_band'] = df['ma20'] + (df['std20'] * 2)
        df['lower_band'] = df['ma20'] - (df['std20'] * 2)
        
        # MA50
        df['ma50'] = df['net_value'].rolling(window=50).mean()
        df['ma50_ratio'] = df['net_value'] / df['ma50']
        
        return df

    def _get_latest_signals(self, df, fund_code):
        """
        ç”Ÿæˆæœ€æ–°çš„æŠ€æœ¯ä¿¡å·ã€‚
        """
        if df.shape[0] < 50:
            return "æ•°æ®ä¸è¶³"
        
        latest_data = df.iloc[-1]
        
        # ä¿®æ­£MACDé‡‘å‰/æ­»å‰åˆ¤æ–­é€»è¾‘
        if len(df) >= 2:
            yesterday_diff = df.iloc[-2]['macd_diff']
            today_diff = latest_data['macd_diff']
            macd_signal = "æ— "
            if today_diff > 0 and yesterday_diff <= 0:
                macd_signal = "é‡‘å‰(ä¹°å…¥)"
            elif today_diff < 0 and yesterday_diff >= 0:
                macd_signal = "æ­»å‰(å–å‡º)"
        else:
            macd_signal = "æ•°æ®ä¸è¶³"
        
        rsi_signal = "ä¸­æ€§"
        if latest_data['rsi'] < 30:
            rsi_signal = "è¶…å–(ä¹°å…¥)"
        elif latest_data['rsi'] > 70:
            rsi_signal = "è¶…ä¹°(å–å‡º)"
            
        bbands_signal = "ä¸­æ€§"
        if latest_data['net_value'] < latest_data['lower_band']:
            bbands_signal = "è·Œç ´ä¸‹è½¨(ä¹°å…¥)"
        elif latest_data['net_value'] > latest_data['upper_band']:
            bbands_signal = "çªç ´ä¸Šè½¨(å–å‡º)"
            
        ma50_signal = "ä¸­æ€§"
        if latest_data['ma50_ratio'] < 0.95:
            ma50_signal = "å¤§å¹…ä½äºMA50(ä¹°å…¥)"
        elif latest_data['ma50_ratio'] > 1.05:
            ma50_signal = "å¤§å¹…é«˜äºMA50(å–å‡º)"
            
        signals = {
            "ä»£ç ": fund_code,
            "æ—¥æœŸ": latest_data['date'],
            "å‡€å€¼": round(latest_data['net_value'], 4),
            "å‡€å€¼æ—¥æœŸ": latest_data['date'],
            "MACDä¿¡å·": macd_signal,
            "RSIä¿¡å·": rsi_signal,
            "å¸ƒæ—å¸¦ä¿¡å·": bbands_signal,
            "MA50ä¿¡å·": ma50_signal,
        }
        
        # ç»¼åˆä¿¡å·
        strong_buy = (
            (macd_signal == "é‡‘å‰(ä¹°å…¥)") and
            (rsi_signal == "è¶…å–(ä¹°å…¥)")
        )
        low_rsi_buy = (
            (rsi_signal == "è¶…å–(ä¹°å…¥)") and
            (bbands_signal == "è·Œç ´ä¸‹è½¨(ä¹°å…¥)")
        )
        
        signals['è¡ŒåŠ¨ä¿¡å·'] = 'æ— '
        if strong_buy:
            signals['è¡ŒåŠ¨ä¿¡å·'] = 'å¼ºçƒˆä¹°å…¥'
        elif low_rsi_buy:
            signals['è¡ŒåŠ¨ä¿¡å·'] = 'ä¹°å…¥'
        
        return signals

    def _process_single_fund(self, fund_code):
        """
        å¤„ç†å•ä¸ªåŸºé‡‘çš„æ•°æ®ï¼šè¯»å–æœ¬åœ°ã€å¢é‡æ›´æ–°ã€è®¡ç®—æŒ‡æ ‡å¹¶ç”Ÿæˆä¿¡å·ã€‚
        """
        logging.info(f"--- æ­£åœ¨å¤„ç†åŸºé‡‘ {fund_code} ---")
        
        local_df = self._read_local_data(fund_code)
        
        # è·å–æœ€æ–°æ—¥æœŸä»¥è¿›è¡Œå¢é‡æ›´æ–°
        start_date = local_df['date'].max() if not local_df.empty else date(2000, 1, 1)
        latest_data_date = date.today()
        
        # æ£€æŸ¥æ˜¯å¦å·²æ˜¯æœ€æ–°ï¼Œå¹¶è€ƒè™‘èŠ‚å‡æ—¥
        if not local_df.empty and local_df['date'].max() == latest_data_date and str(latest_data_date) not in self.holidays:
            logging.info(f"åŸºé‡‘ {fund_code} æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œè·³è¿‡ä¸‹è½½ã€‚")
            df = local_df
        else:
            # å¢é‡ä¸‹è½½æ–°æ•°æ®
            new_df = pd.DataFrame()
            page_index = 1
            total_pages = 1
            
            while page_index <= total_pages:
                time_module.sleep(random.uniform(0.5, 1.5))
                logging.info(f"æ­£åœ¨è·å–åŸºé‡‘ {fund_code} çš„ç¬¬ {page_index} é¡µæ•°æ®...")
                temp_df, total_records, total_pages = self._fetch_fund_data(fund_code, page_index)
                
                if temp_df is None or temp_df.empty:
                    logging.warning(f"è·å–åŸºé‡‘ {fund_code} æ•°æ®æ—¶ API æœªè¿”å›å†…å®¹ã€‚")
                    break
                    
                # åˆå¹¶æ•°æ®
                if new_df.empty:
                    new_df = temp_df
                else:
                    new_df = pd.concat([new_df, temp_df], ignore_index=True)
                
                # æ£€æŸ¥æ˜¯å¦å·²è¾¾åˆ°æœ¬åœ°æœ€æ–°æ—¥æœŸï¼Œå¦‚æœå·²è¾¾åˆ°åˆ™åœæ­¢ä¸‹è½½
                if not local_df.empty and (new_df['date'] <= start_date).any():
                    logging.info(f"å·²ä¸‹è½½è‡³æœ¬åœ°æœ€æ–°æ•°æ®ï¼Œåœæ­¢çˆ¬å–ã€‚")
                    break
                
                page_index += 1
            
            # åˆå¹¶æœ¬åœ°å’Œæ–°æ•°æ®
            if not new_df.empty:
                df = pd.concat([local_df, new_df], ignore_index=True)
                df.drop_duplicates(subset=['date'], keep='last', inplace=True)
                df.sort_values(by='date', inplace=True)
                self._save_to_local_file(df, fund_code)
            else:
                df = local_df

        if df.empty or df.shape[0] < 50:
            logging.warning(f"åŸºé‡‘ {fund_code} æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡ŒæŠ€æœ¯åˆ†æã€‚")
            return None
        
        processed_df = self._calculate_indicators(df)
        signals = self._get_latest_signals(processed_df, fund_code)
        
        # é¢å¤–æ·»åŠ MACDå’ŒRSIå€¼åˆ°ç»“æœä¸­
        latest_data = processed_df.iloc[-1]
        signals['RSI'] = round(latest_data['rsi'], 2)
        signals['MACD'] = round(latest_data['macd'], 4)
        signals['Signal'] = round(latest_data['signal'], 4)
        
        return signals

    def get_fund_data(self):
        """
        å¤šçº¿ç¨‹è·å–æ‰€æœ‰åŸºé‡‘æ•°æ®å¹¶ç”Ÿæˆåˆ†æä¿¡å·ã€‚
        """
        fund_signals = []
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_fund = {executor.submit(self._process_single_fund, code): code for code in self.fund_codes}
            for future in as_completed(future_to_fund):
                fund_code = future_to_fund[future]
                try:
                    result = future.result()
                    if result:
                        fund_signals.append(result)
                except Exception as exc:
                    logging.error(f"å¤„ç†åŸºé‡‘ {fund_code} æ—¶å‘ç”Ÿå¼‚å¸¸: {exc}")
        
        return fund_signals

    def generate_report(self):
        """
        ç”Ÿæˆ Markdown æ ¼å¼çš„æŠ•èµ„å»ºè®®æŠ¥å‘Šã€‚
        """
        all_signals = self.get_fund_data()
        
        # æ ¹æ®è¿‡æ»¤æ¨¡å¼ç­›é€‰å’Œæ’åº
        if self.filter_mode == 'strong_buy':
            filtered_signals = [s for s in all_signals if s['è¡ŒåŠ¨ä¿¡å·'] == 'å¼ºçƒˆä¹°å…¥']
        elif self.filter_mode == 'low_rsi_buy':
            filtered_signals = [s for s in all_signals if s['RSI'] < 30]
        else:
            filtered_signals = [s for s in all_signals if s['è¡ŒåŠ¨ä¿¡å·'] != 'æ— ']

        # ä¼˜å…ˆæ˜¾ç¤ºæŒä»“åŸºé‡‘
        holding_signals = [s for s in filtered_signals if s['ä»£ç '] in self.holdings]
        other_signals = [s for s in filtered_signals if s['ä»£ç '] not in self.holdings]
        
        # æ ¹æ®RSIæˆ–MACDè¿›è¡Œæ’åº
        sorted_signals = sorted(holding_signals, key=lambda x: x['RSI']) + sorted(other_signals, key=lambda x: x['RSI'])
        
        # è·å–å¤§ç›˜è¶‹åŠ¿
        market_trend = self._get_market_trend()
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = f"# åŸºé‡‘å¸‚åœºæŠ€æœ¯åˆ†ææŠ¥å‘Š\n\n"
        report_content += f"**ç”Ÿæˆæ—¥æœŸ**: {date.today().strftime('%Y-%m-%d')}\n"
        report_content += f"**å¤§ç›˜è¶‹åŠ¿ï¼ˆæ²ªæ·±300ï¼‰**: {market_trend}\n\n"
        report_content += f"## æŠ•èµ„å»ºè®®\n\n"
        report_content += f"ä»¥ä¸‹æ˜¯æ ¹æ® `{self.filter_mode}` æ¨¡å¼ç­›é€‰å‡ºçš„ï¼Œä¸”ç»“åˆå¤§ç›˜è¶‹åŠ¿çš„å»ºè®®ã€‚\n\n"
        
        if market_trend == "å¼ºåŠ¿":
            report_content += "ğŸ’¡ **å¸‚åœºæƒ…ç»ªç§¯æï¼Œå¯é€‚å½“å…³æ³¨æŠ€æœ¯ä¹°å…¥ä¿¡å·ã€‚**\n\n"
        elif market_trend == "å¼±åŠ¿":
            report_content += "âš ï¸ **å¸‚åœºæƒ…ç»ªè°¨æ…ï¼ŒæŠ€æœ¯ä¿¡å·å¼ºåº¦é™ä½ï¼Œå»ºè®®è§‚æœ›æˆ–å°é¢è¯•æ¢ã€‚**\n\n"
        
        if sorted_signals:
            report_content += "| åŸºé‡‘ä»£ç  | åŸºé‡‘å‡€å€¼ | å‡€å€¼æ—¥æœŸ | è¡ŒåŠ¨ä¿¡å· | MACDä¿¡å· | RSIä¿¡å· | å¸ƒæ—å¸¦ä¿¡å· | MA50ä¿¡å· |\n"
            report_content += "|---|---|---|---|---|---|---|---|\n"
            for s in sorted_signals[:self.top_n]:
                report_content += f"| {s['ä»£ç ']} | {s['å‡€å€¼']} | {s['å‡€å€¼æ—¥æœŸ']} | **{s['è¡ŒåŠ¨ä¿¡å·']}** | {s['MACDä¿¡å·']} | {s['RSI']} | {s['å¸ƒæ—å¸¦ä¿¡å·']} | {s['MA50ä¿¡å·']} |\n"
        else:
            report_content += "ç›®å‰æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„åŸºé‡‘ã€‚\n"
        
        # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
        with open(REPORT_FILE, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logging.info(f"æŠ¥å‘Šå·²ç”Ÿæˆè‡³ {REPORT_FILE}")
        return report_content

if __name__ == "__main__":
    monitor = MarketMonitor(holdings=['000013', '161725'])
    monitor.generate_report()
