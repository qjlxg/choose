import pandas as pd
import numpy as np
import re
import os
import logging
from datetime import datetime, timedelta, time
import random
from io import StringIO
import requests
import tenacity
import concurrent.futures
import time as time_module

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('market_monitor.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å®šä¹‰æœ¬åœ°æ•°æ®å­˜å‚¨ç›®å½•
DATA_DIR = 'fund_data'
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

class FundAllocator:
    """èµ„é‡‘åˆ†é…å»ºè®®ç±»"""
    
    @staticmethod
    def calculate_allocation_score(row):
        """è®¡ç®—åŸºé‡‘çš„åˆ†é…æƒé‡å¾—åˆ†ï¼ˆ0-100åˆ†ï¼‰"""
        score = 0
        
        # 1. è¡ŒåŠ¨ä¿¡å·æƒé‡ (40åˆ†)
        action_map = {
            "å¼ºçƒˆå¼ºä¹°å…¥": 40, "å¼ºä¹°å…¥": 35, "å¼±ä¹°å…¥": 25,
            "æŒæœ‰/è§‚å¯Ÿ": 15, "å¼±å–å‡º/è§„é¿": 5, "å¼ºå–å‡º/è§„é¿": 0, "N/A": 0
        }
        score += action_map.get(row['è¡ŒåŠ¨ä¿¡å·'], 0)
        
        # 2. RSIå¾—åˆ† (20åˆ†) - è¶Šä½è¶Šå¥½ï¼ˆè¶…å–æœºä¼šï¼‰
        rsi = pd.to_numeric(row['RSI'], errors='coerce')
        if not pd.isna(rsi):
            if rsi < 30:
                score += 20
            elif rsi < 40:
                score += 15
            elif rsi < 50:
                score += 10
            else:
                score += 5
        
        # 3. å‡€å€¼/MA50å¾—åˆ† (15åˆ†) - è¶Šæ¥è¿‘1è¶Šå¥½ï¼ˆåœ¨å‡çº¿é™„è¿‘ï¼‰
        ma_ratio = pd.to_numeric(row['å‡€å€¼/MA50'], errors='coerce')
        if not pd.isna(ma_ratio):
            if 0.95 <= ma_ratio <= 1.05:
                score += 15
            elif 0.9 <= ma_ratio <= 1.1:
                score += 10
            elif 0.85 <= ma_ratio <= 1.15:
                score += 5
        
        # 4. MACDä¿¡å· (15åˆ†)
        if 'é‡‘å‰' in str(row['MACDä¿¡å·']):
            score += 15
        elif 'æ­»å‰' in str(row['MACDä¿¡å·']):
            score -= 5  # æ­»å‰æ‰£åˆ†
        
        # 5. å¸ƒæ—å¸¦ä½ç½® (10åˆ†) - ä¸‹è½¨é™„è¿‘æœºä¼šæ›´å¤§
        bb_pos = str(row['å¸ƒæ—å¸¦ä½ç½®'])
        if 'ä¸‹è½¨' in bb_pos:
            score += 10
        elif 'ä¸­è½¨' in bb_pos:
            score += 5
        
        # ç¡®ä¿å¾—åˆ†åœ¨0-100ä¹‹é—´
        return max(0, min(100, score))
    
    @staticmethod
    def suggest_portfolio(filtered_df, total_budget=5000, max_positions=3):
        """å»ºè®®æŠ•èµ„ç»„åˆ"""
        # è®¡ç®—åˆ†é…å¾—åˆ†
        filtered_df['åˆ†é…å¾—åˆ†'] = filtered_df.apply(FundAllocator.calculate_allocation_score, axis=1)
        
        # æŒ‰å¾—åˆ†æ’åº
        scored_df = filtered_df.sort_values('åˆ†é…å¾—åˆ†', ascending=False)
        
        # é€‰æ‹©å‰Nä¸ªï¼ˆè€ƒè™‘èµ„é‡‘é™åˆ¶ï¼‰
        n_positions = min(max_positions, len(scored_df))
        selected_funds = scored_df.head(n_positions).copy()
        
        # è®¡ç®—æ¯åªåŸºé‡‘çš„å»ºè®®é‡‘é¢
        total_score = selected_funds['åˆ†é…å¾—åˆ†'].sum()
        if total_score > 0:
            selected_funds['å»ºè®®æƒé‡'] = (selected_funds['åˆ†é…å¾—åˆ†'] / total_score * 100).round(1)
            selected_funds['å»ºè®®é‡‘é¢'] = (selected_funds['å»ºè®®æƒé‡'] / 100 * total_budget).round(0)
        else:
            selected_funds['å»ºè®®æƒé‡'] = 0
            selected_funds['å»ºè®®é‡‘é¢'] = 0
        
        return scored_df, selected_funds
    
    @staticmethod
    def generate_allocation_report(selected_funds, total_budget):
        """ç”Ÿæˆèµ„é‡‘åˆ†é…æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("\n## ğŸ’° èµ„é‡‘åˆ†é…å»ºè®®")
        report_lines.append(f"**æ€»æŠ•èµ„é¢„ç®—**: {total_budget:,} å…ƒ")
        report_lines.append(f"**å»ºè®®ä»“ä½æ•°**: {len(selected_funds)} åªåŸºé‡‘")
        report_lines.append("\n| åŸºé‡‘ä»£ç  | åˆ†é…å¾—åˆ† | å»ºè®®æƒé‡ | å»ºè®®é‡‘é¢ | è¡ŒåŠ¨ä¿¡å· | æŠ•èµ„ç†ç”± |")
        report_lines.append("|----|----|----|----|----|----|")
        
        for _, row in selected_funds.iterrows():
            amount = f"{row['å»ºè®®é‡‘é¢']:,}"
            weight = f"{row['å»ºè®®æƒé‡']}%"
            score = f"{row['åˆ†é…å¾—åˆ†']:.0f}"
            signal = row['è¡ŒåŠ¨ä¿¡å·']
            reason = FundAllocator._get_investment_reason(row)
            
            report_lines.append(f"| {row['åŸºé‡‘ä»£ç ']} | {score} | {weight} | {amount}å…ƒ | {signal} | {reason} |")
        
        # æ€»è®¡éªŒè¯
        total_amount = selected_funds['å»ºè®®é‡‘é¢'].sum()
        report_lines.append(f"\n**æ€»è®¡**: {total_amount:,.0f}å…ƒ ({(total_amount/total_budget*100):.1f}% é¢„ç®—ä½¿ç”¨ç‡)")
        
        if total_amount < total_budget * 0.9:
            report_lines.append("\n**ğŸ’¡ å»ºè®®**: å½“å‰å»ºè®®ä»“ä½ä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯è€ƒè™‘:")
            report_lines.append("- å¢åŠ ä»“ä½æ•°é‡ï¼ˆåˆ†æ•£é£é™©ï¼‰")
            report_lines.append("- ç­‰å¾…æ›´å¤šä¹°å…¥ä¿¡å·")
            report_lines.append("- è°ƒæ•´æŠ•èµ„é¢„ç®—")
        elif total_amount > total_budget * 1.1:
            report_lines.append("\n**âš ï¸ æé†’**: å»ºè®®é‡‘é¢è¶…å‡ºé¢„ç®—ï¼Œå»ºè®®æŒ‰æ¯”ä¾‹ç¼©å‡")
        
        return report_lines
    
    @staticmethod
    def _get_investment_reason(row):
        """ç”ŸæˆæŠ•èµ„ç†ç”±æ‘˜è¦"""
        reasons = []
        
        # RSIç†ç”±
        rsi = pd.to_numeric(row['RSI'], errors='coerce')
        if not pd.isna(rsi):
            if rsi < 30:
                reasons.append("RSIè¶…å–")
            elif rsi < 40:
                reasons.append("RSIä½ä½")
        
        # å‡çº¿ç†ç”±
        ma_ratio = pd.to_numeric(row['å‡€å€¼/MA50'], errors='coerce')
        if not pd.isna(ma_ratio) and 0.95 <= ma_ratio <= 1.05:
            reasons.append("è´´è¿‘å‡çº¿")
        
        # MACDç†ç”±
        if 'é‡‘å‰' in str(row['MACDä¿¡å·']):
            reasons.append("MACDé‡‘å‰")
        
        # å¸ƒæ—å¸¦ç†ç”±
        if 'ä¸‹è½¨' in str(row['å¸ƒæ—å¸¦ä½ç½®']):
            reasons.append("å¸ƒæ—ä¸‹è½¨")
        elif 'ä¸­è½¨' in str(row['å¸ƒæ—å¸¦ä½ç½®']):
            reasons.append("å¸ƒæ—ä¸­è½¨")
        
        return "ã€".join(reasons) if reasons else "ç»¼åˆæŠ€æœ¯æŒ‡æ ‡"

class MarketMonitor:
    def __init__(self, report_file='analysis_report.md', output_file='market_monitor_report.md', filter_mode='all', rsi_threshold=None, holdings=None):
        self.report_file = report_file
        self.output_file = output_file
        self.filter_mode = filter_mode  # 'all', 'strong_buy', 'low_rsi_buy'
        self.rsi_threshold = rsi_threshold  # e.g., 40, only for low_rsi_buy
        self.holdings = holdings or []  # List of held fund codes, for prioritization
        self.fund_codes = []
        self.fund_data = {}
        self.index_data = pd.DataFrame()  # å¤§ç›˜æ•°æ®
        self.index_indicators = None  # å¤§ç›˜æŒ‡æ ‡
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36'
        }

    def _load_index_data(self):
        """åŠ è½½å¤§ç›˜æ•°æ®"""
        index_file = os.path.join('index_data', '000300.csv')
        if os.path.exists(index_file):
            try:
                self.index_data = pd.read_csv(index_file, parse_dates=['date'])
                self.index_data = self.index_data.sort_values(by='date', ascending=True).reset_index(drop=True)
                logger.info("å¤§ç›˜æ•°æ®åŠ è½½æˆåŠŸï¼Œå…± %d è¡Œï¼Œæœ€æ–°æ—¥æœŸ: %s", len(self.index_data), self.index_data['date'].max().date())
                # è®¡ç®—å¤§ç›˜æŒ‡æ ‡
                self.index_indicators = self._calculate_indicators(self.index_data)
                if self.index_indicators is not None:
                    logger.info("å¤§ç›˜æŒ‡æ ‡è®¡ç®—å®Œæˆ")
                else:
                    logger.warning("å¤§ç›˜æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æŒ‡æ ‡")
            except Exception as e:
                logger.error("åŠ è½½å¤§ç›˜æ•°æ®å¤±è´¥: %s", e)
                self.index_data = pd.DataFrame()
        else:
            logger.warning("å¤§ç›˜æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: %s", index_file)
            self.index_data = pd.DataFrame()

    def _get_index_market_trend(self):
        """è·å–å¤§ç›˜è¶‹åŠ¿ä¿¡å·"""
        if self.index_indicators is None or self.index_indicators.empty:
            return "ä¸­æ€§"
        
        latest_index = self.index_indicators.iloc[-1]
        ma_ratio = latest_index['ma_ratio']
        macd_diff = latest_index['macd'] - latest_index['signal']
        rsi = latest_index['rsi']
        
        if not np.isnan(ma_ratio) and ma_ratio > 1 and not np.isnan(macd_diff) and macd_diff > 0 and not np.isnan(rsi) and rsi < 70:
            return "å¼ºåŠ¿"
        elif not np.isnan(ma_ratio) and ma_ratio < 0.95 or not np.isnan(macd_diff) and macd_diff < 0 or not np.isnan(rsi) and rsi > 70:
            return "å¼±åŠ¿"
        else:
            return "ä¸­æ€§"

    def _get_expected_latest_date(self):
        """æ ¹æ®å½“å‰æ—¶é—´ç¡®å®šæœŸæœ›çš„æœ€æ–°æ•°æ®æ—¥æœŸ"""
        now = datetime.now()
        # å‡è®¾å‡€å€¼æ›´æ–°æ—¶é—´ä¸ºæ™šä¸Š21:00
        update_time = time(21, 0)
        if now.time() < update_time:
            # å¦‚æœå½“å‰æ—¶é—´æ—©äº21:00ï¼Œåˆ™æœŸæœ›æœ€æ–°æ—¥æœŸä¸ºæ˜¨å¤©
            expected_date = now.date() - timedelta(days=1)
        else:
            # å¦åˆ™ï¼ŒæœŸæœ›æœ€æ–°æ—¥æœŸä¸ºä»Šå¤©
            expected_date = now.date()
        logger.info("å½“å‰æ—¶é—´: %s, æœŸæœ›æœ€æ–°æ•°æ®æ—¥æœŸ: %s", now.strftime('%Y-%m-%d %H:%M:%S'), expected_date)
        return expected_date

    def _parse_report(self, report_path='analysis_report.md'):
        """ä» analysis_report.md æå–æ¨èåŸºé‡‘ä»£ç """
        logger.info("æ­£åœ¨è§£æ %s è·å–æ¨èåŸºé‡‘ä»£ç ...", report_path)
        if not os.path.exists(report_path):
            logger.error("æŠ¥å‘Šæ–‡ä»¶ %s ä¸å­˜åœ¨", report_path)
            # å¦‚æœåˆ†ææŠ¥å‘Šä¸å­˜åœ¨ï¼Œå°è¯•åŠ è½½ä½ çš„ä¹°å…¥ä¿¡å·CSV
            return self._parse_buy_signals_csv()
        
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            pattern = re.compile(r'(?:^\| +(\d{6})|### åŸºé‡‘ (\d{6}))', re.M)
            matches = pattern.findall(content)

            extracted_codes = set()
            for match in matches:
                code = match[0] if match[0] else match[1]
                extracted_codes.add(code)
            
            sorted_codes = sorted(list(extracted_codes))
            self.fund_codes = sorted_codes[:1000]
            
            if not self.fund_codes:
                logger.warning("æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆåŸºé‡‘ä»£ç ï¼Œè¯·æ£€æŸ¥ analysis_report.md")
                # å°è¯•åŠ è½½CSVä½œä¸ºå¤‡é€‰
                self._parse_buy_signals_csv()
            else:
                logger.info("æå–åˆ° %d ä¸ªåŸºé‡‘ï¼ˆæµ‹è¯•é™åˆ¶å‰1000ä¸ªï¼‰: %s", len(self.fund_codes), self.fund_codes[:5])
            
        except Exception as e:
            logger.error("è§£ææŠ¥å‘Šæ–‡ä»¶å¤±è´¥: %s", e)
            # å¤‡é€‰æ–¹æ¡ˆï¼šå°è¯•CSV
            self._parse_buy_signals_csv()

    def _parse_buy_signals_csv(self, csv_file="ä¹°å…¥ä¿¡å·åŸºé‡‘_20250922.csv"):
        """ä»ä¹°å…¥ä¿¡å·CSVæ–‡ä»¶è§£æåŸºé‡‘ä»£ç """
        logger.info("å°è¯•ä»ä¹°å…¥ä¿¡å·CSVæ–‡ä»¶è§£æåŸºé‡‘ä»£ç : %s", csv_file)
        if not os.path.exists(csv_file):
            logger.error("ä¹°å…¥ä¿¡å·æ–‡ä»¶ %s ä¸å­˜åœ¨", csv_file)
            return False
        
        try:
            df = pd.read_csv(csv_file)
            if 'fund_code' in df.columns:
                self.fund_codes = df['fund_code'].astype(str).str.zfill(6).tolist()
                logger.info("ä»CSVæ–‡ä»¶æå–åˆ° %d ä¸ªå¼ºä¹°å…¥åŸºé‡‘: %s", len(self.fund_codes), self.fund_codes)
                return True
            else:
                logger.warning("CSVæ–‡ä»¶ç¼ºå°‘ 'fund_code' åˆ—")
                return False
        except Exception as e:
            logger.error("è§£æCSVæ–‡ä»¶å¤±è´¥: %s", e)
            return False

    def _read_local_data(self, fund_code):
        """è¯»å–æœ¬åœ°æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™è¿”å›DataFrame"""
        file_path = os.path.join(DATA_DIR, f"{fund_code}.csv")
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path, parse_dates=['date'])
                if not df.empty and 'date' in df.columns and 'net_value' in df.columns:
                    df = df.sort_values(by='date', ascending=True).reset_index(drop=True)
                    logger.info("æœ¬åœ°å·²å­˜åœ¨åŸºé‡‘ %s æ•°æ®ï¼Œå…± %d è¡Œï¼Œæœ€æ–°æ—¥æœŸä¸º: %s", fund_code, len(df), df['date'].max().date())
                    return df
            except Exception as e:
                logger.warning("è¯»å–æœ¬åœ°æ–‡ä»¶ %s å¤±è´¥: %s", file_path, e)
        return pd.DataFrame()

    def _save_to_local_file(self, fund_code, df):
        """å°†DataFrameä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œè¦†ç›–æ—§æ–‡ä»¶"""
        file_path = os.path.join(DATA_DIR, f"{fund_code}.csv")
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        df.to_csv(file_path, index=False)
        logger.info("åŸºé‡‘ %s æ•°æ®å·²æˆåŠŸä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶: %s", fund_code, file_path)

    def _clean_fund_html_content(self, raw_content_html):
        """æ¸…ç†åŸºé‡‘HTMLå†…å®¹ï¼Œç§»é™¤ç‰¹æ®Šæ ‡è®°ç¬¦å·"""
        if not raw_content_html:
            return raw_content_html
        
        # ç§»é™¤æ—¥æœŸåé¢çš„ç‰¹æ®Šæ ‡è®°ç¬¦å·ï¼ˆå¦‚ *ï¼‰ï¼Œé€šå¸¸ç”¨äºæ ‡è®°å‘¨æœ«æˆ–èŠ‚å‡æ—¥åŒå€æ”¶ç›Š
        # æ¨¡å¼ï¼šåŒ¹é…æ—¥æœŸåé¢ç´§è·Ÿçš„ * ç¬¦å·ï¼Œå¹¶å°†å…¶ç§»é™¤
        cleaned_content = re.sub(r'(\d{4}-\d{2}-\d{2})\*', r'\1', raw_content_html)
        
        # ç§»é™¤å¯èƒ½å­˜åœ¨çš„å…¶ä»–ç‰¹æ®Šå­—ç¬¦ï¼Œç¡®ä¿è¡¨æ ¼æ ¼å¼æ­£ç¡®
        cleaned_content = re.sub(r'[^\w\s%\-â€“â€”\d\.\,/:]', ' ', cleaned_content)
        
        logger.debug("åŸå§‹å†…å®¹é•¿åº¦: %d, æ¸…ç†åé•¿åº¦: %d", len(raw_content_html), len(cleaned_content))
        return cleaned_content

    @tenacity.retry(
        stop=tenacity.stop_after_attempt(5),
        wait=tenacity.wait_fixed(10),
        retry=tenacity.retry_if_exception_type((requests.exceptions.RequestException, ValueError)),
        before_sleep=lambda retry_state: logger.info(f"é‡è¯•åŸºé‡‘ {retry_state.args[0]}ï¼Œç¬¬ {retry_state.attempt_number} æ¬¡")
    )
    def _fetch_fund_data(self, fund_code, latest_local_date=None):
        """
        ä»ç½‘ç»œè·å–åŸºé‡‘æ•°æ®ï¼Œå®ç°çœŸæ­£çš„å¢é‡æ›´æ–°ã€‚
        å¦‚æœ latest_local_date ä¸ä¸ºç©ºï¼Œåˆ™åªè·å–å…¶ä¹‹åçš„æ•°æ®ã€‚
        """
        all_new_data = []
        page_index = 1
        has_new_data = False
        
        while True:
            url = f"http://fundf10.eastmoney.com/F10DataApi.aspx?type=lsjz&code={fund_code}&page={page_index}&per=20"
            logger.info("æ­£åœ¨è·å–åŸºé‡‘ %s çš„ç¬¬ %d é¡µæ•°æ®...", fund_code, page_index)
            
            try:
                response = requests.get(url, headers=self.headers, timeout=30)
                response.raise_for_status()
                
                content_match = re.search(r'content:"(.*?)"', response.text, re.S)
                pages_match = re.search(r'pages:(\d+)', response.text)
                
                if not content_match or not pages_match:
                    logger.error("åŸºé‡‘ %s APIè¿”å›å†…å®¹æ ¼å¼ä¸æ­£ç¡®ï¼Œå¯èƒ½å·²æ— æ•°æ®æˆ–æ¥å£å˜æ›´", fund_code)
                    break

                raw_content_html = content_match.group(1).replace('\\"', '"')
                total_pages = int(pages_match.group(1))
                
                # æ–°å¢ï¼šæ¸…ç†HTMLå†…å®¹ï¼Œç§»é™¤ç‰¹æ®Šæ ‡è®°ç¬¦å·
                cleaned_content_html = self._clean_fund_html_content(raw_content_html)
                
                tables = pd.read_html(StringIO(cleaned_content_html))
                
                if not tables:
                    logger.warning("åŸºé‡‘ %s åœ¨ç¬¬ %d é¡µæœªæ‰¾åˆ°æ•°æ®è¡¨æ ¼ï¼Œçˆ¬å–ç»“æŸ", fund_code, page_index)
                    break
                
                df_page = tables[0]
                
                # åŠ¨æ€æ£€æµ‹åˆ—æ•°å¹¶è°ƒæ•´åˆ—å
                if len(df_page.columns) == 6:
                    # è´§å¸åŸºé‡‘æ ¼å¼ï¼šå‡€å€¼æ—¥æœŸã€æ¯ä¸‡ä»½æ”¶ç›Šã€7æ—¥å¹´åŒ–æ”¶ç›Šç‡ã€ç”³è´­çŠ¶æ€ã€èµå›çŠ¶æ€ã€åˆ†çº¢é€é…
                    df_page.columns = ['date', 'net_value', 'annualized_return', 'purchase_status', 'redemption_status', 'dividend']
                    df_page = df_page[['date', 'net_value']].copy()
                elif len(df_page.columns) == 7:
                    # è‚¡ç¥¨/æ··åˆåŸºé‡‘æ ¼å¼ï¼šå‡€å€¼æ—¥æœŸã€æ—¥å¢é•¿ç‡ã€ç´¯è®¡å‡€å€¼ã€ç”³è´­çŠ¶æ€ã€èµå›çŠ¶æ€ã€åˆ†çº¢é€é…
                    df_page.columns = ['date', 'daily_growth_rate', 'cumulative_net_value', 'purchase_status', 'redemption_status', 'dividend', 'extra']
                    df_page = df_page[['date', 'daily_growth_rate']].copy()
                    df_page.rename(columns={'daily_growth_rate': 'net_value'}, inplace=True)
                else:
                    logger.warning("åŸºé‡‘ %s è¡¨æ ¼åˆ—æ•°å¼‚å¸¸: %d åˆ—ï¼Œè·³è¿‡æ­¤é¡µ", fund_code, len(df_page.columns))
                    break
                
                df_page['date'] = pd.to_datetime(df_page['date'], errors='coerce')
                df_page['net_value'] = pd.to_numeric(df_page['net_value'], errors='coerce')
                df_page = df_page.dropna(subset=['date', 'net_value'])
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å·²è·å–åˆ°æœ¬åœ°æœ€æ–°æ•°æ®ä¹‹å‰çš„æ•°æ®
                if latest_local_date:
                    new_df_page = df_page[df_page['date'].dt.date > latest_local_date]
                    if new_df_page.empty:
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”ä¹‹å‰å·²ç»å‘ç°è¿‡æ–°æ•°æ®ï¼Œåˆ™åœæ­¢çˆ¬å–
                        if has_new_data:
                            logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                        # å¦‚æœå½“å‰é¡µæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æ˜¯ç¬¬ä¸€é¡µï¼Œåˆ™è¯´æ˜æ²¡æœ‰æ–°æ•°æ®
                        elif page_index == 1:
                            logger.info("åŸºé‡‘ %s æ— æ–°æ•°æ®ï¼Œçˆ¬å–ç»“æŸã€‚", fund_code)
                            break
                    else:
                        has_new_data = True
                        all_new_data.append(new_df_page)
                        logger.info("ç¬¬ %d é¡µ: å‘ç° %d è¡Œæ–°æ•°æ®", page_index, len(new_df_page))
                else:
                    # å¦‚æœæ˜¯é¦–æ¬¡ä¸‹è½½ï¼Œåˆ™è·å–æ‰€æœ‰æ•°æ®
                    all_new_data.append(df_page)

                logger.info("åŸºé‡‘ %s æ€»é¡µæ•°: %d, å½“å‰é¡µ: %d, å½“å‰é¡µè¡Œæ•°: %d", fund_code, total_pages, page_index, len(df_page))
                
                # å¦‚æœæ˜¯å¢é‡æ›´æ–°æ¨¡å¼ï¼Œä¸”å½“å‰é¡µæ•°æ®æ¯”æœ€æ–°æ•°æ®æ—¥æœŸæ—©ï¼Œåˆ™ç»“æŸå¾ªç¯
                if latest_local_date and (df_page['date'].dt.date <= latest_local_date).any():
                    logger.info("åŸºé‡‘ %s å·²è¿½æº¯åˆ°æœ¬åœ°æ•°æ®ï¼Œå¢é‡çˆ¬å–ç»“æŸã€‚", fund_code)
                    break

                if page_index >= total_pages:
                    logger.info("åŸºé‡‘ %s å·²è·å–æ‰€æœ‰å†å²æ•°æ®ï¼Œå…± %d é¡µï¼Œçˆ¬å–ç»“æŸ", fund_code, total_pages)
                    break
                
                page_index += 1
                time_module.sleep(random.uniform(1, 2))  # å»¶é•¿sleepåˆ°1-2ç§’ï¼Œå‡å°‘é™é€Ÿé£é™©
                
            except requests.exceptions.RequestException as e:
                logger.error("åŸºé‡‘ %s APIè¯·æ±‚å¤±è´¥: %s", fund_code, str(e))
                raise
            except Exception as e:
                logger.error("åŸºé‡‘ %s APIæ•°æ®è§£æå¤±è´¥: %s", fund_code, str(e))
                # å°è¯•ä½¿ç”¨åŸå§‹å†…å®¹è¿›è¡Œè°ƒè¯•
                if 'raw_content_html' in locals():
                    logger.debug("åŸå§‹HTMLå†…å®¹ç‰‡æ®µ: %s", raw_content_html[:500])
                    logger.debug("æ¸…ç†åHTMLå†…å®¹ç‰‡æ®µ: %s", self._clean_fund_html_content(raw_content_html)[:500])
                raise

        # åˆå¹¶æ–°æ•°æ®å¹¶è¿”å›
        if all_new_data:
            new_combined_df = pd.concat(all_new_data, ignore_index=True)
            return new_combined_df[['date', 'net_value']]
        else:
            return pd.DataFrame()

    def _calculate_indicators(self, df):
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å¹¶ç”Ÿæˆç»“æœå­—å…¸"""
        if df is None or df.empty or len(df) < 26:
            return None

        df = df.sort_values(by='date', ascending=True)
        
        # MACD
        exp12 = df['net_value'].ewm(span=12, adjust=False).mean()
        exp26 = df['net_value'].ewm(span=26, adjust=False).mean()
        df['macd'] = exp12 - exp26
        df['signal'] = df['macd'].ewm(span=9, adjust=False).mean()

        # å¸ƒæ—å¸¦
        window = 20
        df['bb_mid'] = df['net_value'].rolling(window=window, min_periods=1).mean()
        df['bb_std'] = df['net_value'].rolling(window=window, min_periods=1).std()
        df['bb_upper'] = df['bb_mid'] + (df['bb_std'] * 2)
        df['bb_lower'] = df['bb_mid'] - (df['bb_std'] * 2)
        
        # RSI
        delta = df['net_value'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=14, min_periods=1).mean()
        avg_loss = loss.rolling(window=14, min_periods=1).mean()
        
        rs = avg_gain / avg_loss.replace(0, np.nan)
        df['rsi'] = 100 - (100 / (1 + rs))

        # MA50
        df['ma50'] = df['net_value'].rolling(window=min(50, len(df)), min_periods=1).mean()
        df['ma_ratio'] = df['net_value'] / df['ma50']

        return df

    def _get_latest_signals(self, fund_code, df):
        """æ ¹æ®æœ€æ–°æ•°æ®è®¡ç®—ä¿¡å·ï¼Œç»“åˆå¤§ç›˜è¶‹åŠ¿è°ƒæ•´"""
        try:
            processed_df = self._calculate_indicators(df)
            if processed_df is None:
                logger.warning("åŸºé‡‘ %s æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®¡ç®—", fund_code)
                return {
                    'fund_code': fund_code, 'latest_net_value': "æ•°æ®è·å–å¤±è´¥", 'rsi': np.nan, 'ma_ratio': np.nan,
                    'macd_diff': np.nan, 'bb_upper': np.nan, 'bb_lower': np.nan, 'advice': "è§‚å¯Ÿ", 'action_signal': 'N/A'
                }
            
            latest_data = processed_df.iloc[-1]
            latest_net_value = latest_data['net_value']
            latest_rsi = latest_data['rsi']
            latest_ma50_ratio = latest_data['ma_ratio']
            latest_macd_diff = latest_data['macd'] - latest_data['signal']
            latest_bb_upper = latest_data['bb_upper']
            latest_bb_lower = latest_data['bb_lower']

            # è·å–å¤§ç›˜è¶‹åŠ¿
            market_trend = self._get_index_market_trend()

            advice = "è§‚å¯Ÿ"
            if (not np.isnan(latest_rsi) and latest_rsi > 70) or \
               (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
               (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                advice = "ç­‰å¾…å›è°ƒ"
                # å¦‚æœå¤§ç›˜å¼±åŠ¿ï¼Œè¿›ä¸€æ­¥ç¡®è®¤å–å‡º
                if market_trend == "å¼±åŠ¿":
                    advice = "å¼ºçƒˆç­‰å¾…å›è°ƒ"
            elif (not np.isnan(latest_rsi) and latest_rsi < 30) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.8):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
                # å¦‚æœå¤§ç›˜å¼ºåŠ¿ï¼ŒåŠ å¼ºä¹°å…¥
                if market_trend == "å¼ºåŠ¿":
                    advice = "å¼ºçƒˆåˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                advice = "å¯åˆ†æ‰¹ä¹°å…¥"
                if market_trend == "å¼ºåŠ¿":
                    advice = "å¼ºçƒˆåˆ†æ‰¹ä¹°å…¥"
            elif (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                advice = "ç­‰å¾…å›è°ƒ"
                if market_trend == "å¼±åŠ¿":
                    advice = "å¼ºçƒˆç­‰å¾…å›è°ƒ"

            action_signal = "æŒæœ‰/è§‚å¯Ÿ"
            if not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.95:
                action_signal = "å¼ºå–å‡º/è§„é¿"
                if market_trend == "å¼±åŠ¿":
                    action_signal = "å¼ºçƒˆå¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 70) and \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff < 0):
                action_signal = "å¼ºå–å‡º/è§„é¿"
                if market_trend == "å¼±åŠ¿":
                    action_signal = "å¼ºçƒˆå¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi > 65) or \
                 (not np.isnan(latest_bb_upper) and latest_net_value > latest_bb_upper) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio > 1.2):
                action_signal = "å¼±å–å‡º/è§„é¿"
                if market_trend == "å¼±åŠ¿":
                    action_signal = "å¼ºå–å‡º/è§„é¿"
            elif (not np.isnan(latest_rsi) and latest_rsi < 35) and \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 0.9) and \
                 (not np.isnan(latest_macd_diff) and latest_macd_diff > 0):
                action_signal = "å¼ºä¹°å…¥"
                if market_trend == "å¼ºåŠ¿":
                    action_signal = "å¼ºçƒˆå¼ºä¹°å…¥"
            elif (not np.isnan(latest_rsi) and latest_rsi < 45) or \
                 (not np.isnan(latest_bb_lower) and latest_net_value < latest_bb_lower) or \
                 (not np.isnan(latest_ma50_ratio) and latest_ma50_ratio < 1):
                action_signal = "å¼±ä¹°å…¥"
                if market_trend == "å¼ºåŠ¿":
                    action_signal = "å¼ºä¹°å…¥"
            
            # åœ¨ç»“æœä¸­æ·»åŠ å¤§ç›˜è¶‹åŠ¿
            return {
                'fund_code': fund_code,
                'latest_net_value': latest_net_value,
                'rsi': latest_rsi,
                'ma_ratio': latest_ma50_ratio,
                'macd_diff': latest_macd_diff,
                'bb_upper': latest_bb_upper,
                'bb_lower': latest_bb_lower,
                'advice': advice,
                'action_signal': action_signal,
                'market_trend': market_trend
            }
        except Exception as e:
            logger.error("å¤„ç†åŸºé‡‘ %s æ—¶å‘ç”Ÿå¼‚å¸¸: %s", fund_code, str(e))
            return {
                'fund_code': fund_code,
                'latest_net_value': "æ•°æ®è·å–å¤±è´¥",
                'rsi': np.nan,
                'ma_ratio': np.nan,
                'macd_diff': np.nan,
                'bb_upper': np.nan,
                'bb_lower': np.nan,
                'advice': "è§‚å¯Ÿ",
                'action_signal': 'N/A',
                'market_trend': self._get_index_market_trend()
            }

    def get_fund_data(self):
        """ä¸»æ§å‡½æ•°ï¼šä¼˜å…ˆä»æœ¬åœ°åŠ è½½ï¼Œä»…åœ¨æ•°æ®éæœ€æ–°æˆ–ä¸å®Œæ•´æ—¶ä¸‹è½½"""
        # åŠ è½½å¤§ç›˜æ•°æ®
        self._load_index_data()
        
        # æ­¥éª¤1: è§£ææ¨èåŸºé‡‘ä»£ç 
        self._parse_report()
        if not self.fund_codes:
            logger.error("æ²¡æœ‰æå–åˆ°ä»»ä½•åŸºé‡‘ä»£ç ï¼Œæ— æ³•ç»§ç»­å¤„ç†")
            return

        # æ­¥éª¤2: é¢„åŠ è½½æœ¬åœ°æ•°æ®å¹¶æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸‹è½½
        logger.info("å¼€å§‹é¢„åŠ è½½æœ¬åœ°ç¼“å­˜æ•°æ®...")
        fund_codes_to_fetch = []
        expected_latest_date = self._get_expected_latest_date()
        min_data_points = 26  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŠ€æœ¯æŒ‡æ ‡

        for fund_code in self.fund_codes:
            local_df = self._read_local_data(fund_code)
            
            if not local_df.empty:
                latest_local_date = local_df['date'].max().date()
                data_points = len(local_df)
                
                # æ£€æŸ¥æ•°æ®æ˜¯å¦æœ€æ–°ä¸”å®Œæ•´
                if latest_local_date >= expected_latest_date and data_points >= min_data_points:
                    logger.info("åŸºé‡‘ %s çš„æœ¬åœ°æ•°æ®å·²æ˜¯æœ€æ–° (%s, æœŸæœ›: %s) ä¸”æ•°æ®é‡è¶³å¤Ÿ (%d è¡Œ)ï¼Œç›´æ¥åŠ è½½ã€‚",
                                 fund_code, latest_local_date, expected_latest_date, data_points)
                    self.fund_data[fund_code] = self._get_latest_signals(fund_code, local_df.tail(100))
                    continue
                else:
                    if latest_local_date < expected_latest_date:
                        logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®å·²è¿‡æ—¶ï¼ˆæœ€æ–°æ—¥æœŸä¸º %sï¼ŒæœŸæœ› %sï¼‰ï¼Œéœ€è¦ä»ç½‘ç»œè·å–æ–°æ•°æ®ã€‚",
                                     fund_code, latest_local_date, expected_latest_date)
                    if data_points < min_data_points:
                        logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®é‡ä¸è¶³ï¼ˆä»… %d è¡Œï¼Œéœ€è‡³å°‘ %d è¡Œï¼‰ï¼Œéœ€è¦ä»ç½‘ç»œè·å–ã€‚",
                                     fund_code, data_points, min_data_points)
            else:
                logger.info("åŸºé‡‘ %s æœ¬åœ°æ•°æ®ä¸å­˜åœ¨ï¼Œéœ€è¦ä»ç½‘ç»œè·å–ã€‚", fund_code)
            
            fund_codes_to_fetch.append(fund_code)

        # æ­¥éª¤3: å¤šçº¿ç¨‹ç½‘ç»œä¸‹è½½å’Œå¤„ç†
        if fund_codes_to_fetch:
            logger.info("å¼€å§‹ä½¿ç”¨å¤šçº¿ç¨‹è·å– %d ä¸ªåŸºé‡‘çš„æ–°æ•°æ®...", len(fund_codes_to_fetch))
            with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
                future_to_code = {executor.submit(self._process_single_fund, code): code for code in fund_codes_to_fetch}
                for future in concurrent.futures.as_completed(future_to_code):
                    fund_code = future_to_code[future]
                    try:
                        result = future.result()
                        if result:
                            self.fund_data[fund_code] = result
                    except Exception as e:
                        logger.error("å¤„ç†åŸºé‡‘ %s æ•°æ®æ—¶å‡ºé”™: %s", fund_code, str(e))
                        self.fund_data[fund_code] = {
                            'fund_code': fund_code, 'latest_net_value': "æ•°æ®è·å–å¤±è´¥", 'rsi': np.nan,
                            'ma_ratio': np.nan, 'macd_diff': np.nan, 'bb_upper': np.nan, 'bb_lower': np.nan, 'advice': "è§‚å¯Ÿ", 'action_signal': 'N/A',
                            'market_trend': self._get_index_market_trend()
                        }
        else:
            logger.info("æ‰€æœ‰åŸºé‡‘æ•°æ®å‡æ¥è‡ªæœ¬åœ°ç¼“å­˜ï¼Œæ— éœ€ç½‘ç»œä¸‹è½½ã€‚")
        
        # é¢å¤–å¤„ç†ï¼šå¦‚æœæ˜¯ä»CSVåŠ è½½çš„ï¼Œç›´æ¥ä½¿ç”¨CSVæ•°æ®
        if not fund_codes_to_fetch and not any(fund_code in self.fund_data for fund_code in self.fund_codes):
            self._load_csv_data_directly()
        
        if len(self.fund_data) > 0:
            logger.info("æ‰€æœ‰åŸºé‡‘æ•°æ®å¤„ç†å®Œæˆã€‚")
        else:
            logger.error("æ‰€æœ‰åŸºé‡‘æ•°æ®å‡è·å–å¤±è´¥ã€‚")

    def _load_csv_data_directly(self):
        """ç›´æ¥ä»CSVåŠ è½½æ•°æ®ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ"""
        csv_file = "ä¹°å…¥ä¿¡å·åŸºé‡‘_20250922.csv"
        if os.path.exists(csv_file):
            try:
                df_csv = pd.read_csv(csv_file)
                logger.info("æˆåŠŸåŠ è½½ä¹°å…¥ä¿¡å·CSVï¼ŒåŒ…å« %d åªåŸºé‡‘", len(df_csv))
                
                # å°†CSVæ•°æ®è½¬æ¢ä¸ºæˆ‘ä»¬çš„æ ¼å¼
                for _, row in df_csv.iterrows():
                    fund_code = str(row['fund_code']).zfill(6)
                    self.fund_data[fund_code] = {
                        'fund_code': fund_code,
                        'latest_net_value': row['æœ€æ–°å‡€å€¼'],
                        'rsi': row['RSI'],
                        'ma_ratio': row['å‡€å€¼/MA50'],
                        'macd_diff': 0 if row['MACDä¿¡å·'] == 'æ­»å‰' else 1,  # ç®€åŒ–å¤„ç†
                        'bb_upper': row['æœ€æ–°å‡€å€¼'] * 1.05 if row['å¸ƒæ—å¸¦ä½ç½®'] == 'ä¸Šè½¨ä¸Šæ–¹' else None,
                        'bb_lower': row['æœ€æ–°å‡€å€¼'] * 0.95 if row['å¸ƒæ—å¸¦ä½ç½®'] == 'ä¸‹è½¨ä¸‹æ–¹' else None,
                        'advice': row['æŠ•èµ„å»ºè®®'],
                        'action_signal': row['è¡ŒåŠ¨ä¿¡å·'],
                        'market_trend': self._get_index_market_trend()
                    }
                
                self.fund_codes = df_csv['fund_code'].astype(str).str.zfill(6).tolist()
                logger.info("CSVæ•°æ®è½¬æ¢å®Œæˆï¼Œå…± %d åªåŸºé‡‘", len(self.fund_codes))
                
            except Exception as e:
                logger.error("ç›´æ¥åŠ è½½CSVæ•°æ®å¤±è´¥: %s", e)

    def _process_single_fund(self, fund_code):
        """å¤„ç†å•ä¸ªåŸºé‡‘æ•°æ®ï¼šè¯»å–æœ¬åœ°ï¼Œä¸‹è½½å¢é‡ï¼Œåˆå¹¶ï¼Œä¿å­˜ï¼Œå¹¶è®¡ç®—ä¿¡å·"""
        local_df = self._read_local_data(fund_code)
        latest_local_date = local_df['date'].max().date() if not local_df.empty else None

        new_df = self._fetch_fund_data(fund_code, latest_local_date)
        
        if not new_df.empty:
            df_final = pd.concat([local_df, new_df]).drop_duplicates(subset=['date'], keep='last').sort_values(by='date', ascending=True)
            self._save_to_local_file(fund_code, df_final)
            return self._get_latest_signals(fund_code, df_final.tail(100))
        elif not local_df.empty:
            # å¦‚æœæ²¡æœ‰æ–°æ•°æ®ï¼Œä¸”æœ¬åœ°æœ‰æ•°æ®ï¼Œåˆ™ä½¿ç”¨æœ¬åœ°æ•°æ®è®¡ç®—ä¿¡å·
            logger.info("åŸºé‡‘ %s æ— æ–°æ•°æ®ï¼Œä½¿ç”¨æœ¬åœ°å†å²æ•°æ®è¿›è¡Œåˆ†æ", fund_code)
            return self._get_latest_signals(fund_code, local_df.tail(100))
        else:
            # å¦‚æœæ—¢æ²¡æœ‰æ–°æ•°æ®ï¼Œæœ¬åœ°åˆæ²¡æœ‰æ•°æ®ï¼Œåˆ™è¿”å›å¤±è´¥
            logger.error("åŸºé‡‘ %s æœªè·å–åˆ°ä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œä¸”æœ¬åœ°æ— ç¼“å­˜", fund_code)
            return None

    def generate_report(self):
        """ç”Ÿæˆå¸‚åœºæƒ…ç»ªä¸æŠ€æœ¯æŒ‡æ ‡ç›‘æ§æŠ¥å‘Š"""
        logger.info("æ­£åœ¨ç”Ÿæˆå¸‚åœºç›‘æ§æŠ¥å‘Š...")
        report_df_list = []
        market_trend = self._get_index_market_trend()
        
        for fund_code in self.fund_codes:
            data = self.fund_data.get(fund_code)
            if data is not None:
                latest_net_value_str = f"{data['latest_net_value']:.4f}" if isinstance(data['latest_net_value'], (float, int)) else str(data['latest_net_value'])
                rsi_str = f"{data['rsi']:.2f}" if isinstance(data['rsi'], (float, int)) and not np.isnan(data['rsi']) else "N/A"
                ma_ratio_str = f"{data['ma_ratio']:.2f}" if isinstance(data['ma_ratio'], (float, int)) and not np.isnan(data['ma_ratio']) else "N/A"
                
                macd_signal = "N/A"
                if isinstance(data['macd_diff'], (float, int)) and not np.isnan(data['macd_diff']):
                    macd_signal = "é‡‘å‰" if data['macd_diff'] > 0 else "æ­»å‰"
                
                bollinger_pos = "ä¸­è½¨"  # é»˜è®¤ä¸­è½¨
                if isinstance(data['latest_net_value'], (float, int)):
                    if isinstance(data['bb_upper'], (float, int)) and not np.isnan(data['bb_upper']) and data['latest_net_value'] > data['bb_upper']:
                        bollinger_pos = "ä¸Šè½¨ä¸Šæ–¹"
                    elif isinstance(data['bb_lower'], (float, int)) and not np.isnan(data['bb_lower']) and data['latest_net_value'] < data['bb_lower']:
                        bollinger_pos = "ä¸‹è½¨ä¸‹æ–¹"
                else:
                    bollinger_pos = "N/A"
                
                report_df_list.append({
                    "åŸºé‡‘ä»£ç ": fund_code,
                    "æœ€æ–°å‡€å€¼": latest_net_value_str,
                    "RSI": rsi_str,
                    "å‡€å€¼/MA50": ma_ratio_str,
                    "MACDä¿¡å·": macd_signal,
                    "å¸ƒæ—å¸¦ä½ç½®": bollinger_pos,
                    "æŠ•èµ„å»ºè®®": data['advice'],
                    "è¡ŒåŠ¨ä¿¡å·": data['action_signal']
                })
            else:
                report_df_list.append({
                    "åŸºé‡‘ä»£ç ": fund_code,
                    "æœ€æ–°å‡€å€¼": "æ•°æ®è·å–å¤±è´¥",
                    "RSI": "N/A",
                    "å‡€å€¼/MA50": "N/A",
                    "MACDä¿¡å·": "N/A",
                    "å¸ƒæ—å¸¦ä½ç½®": "N/A",
                    "æŠ•èµ„å»ºè®®": "è§‚å¯Ÿ",
                    "è¡ŒåŠ¨ä¿¡å·": "N/A"
                })

        report_df = pd.DataFrame(report_df_list)

        # æ–°å¢ï¼šæ ¹æ®æŒä»“ä¼˜å…ˆæ’åºï¼ˆæŒä»“åŸºé‡‘æ’å‰ï¼‰
        if self.holdings:
            report_df['is_holding'] = report_df['åŸºé‡‘ä»£ç '].isin(self.holdings).astype(int)
            report_df = report_df.sort_values(by='is_holding', ascending=False).drop(columns=['is_holding'])

        # æ–°å¢ï¼šæ ¹æ®filter_modeè¿‡æ»¤
        filtered_df = report_df.copy()
        if self.filter_mode == 'strong_buy':
            filtered_df = filtered_df[filtered_df['è¡ŒåŠ¨ä¿¡å·'].str.contains('å¼ºä¹°å…¥', na=False)]
        elif self.filter_mode == 'low_rsi_buy' and self.rsi_threshold:
            # è½¬æ¢ä¸ºæ•°å€¼
            filtered_df['RSI_num'] = pd.to_numeric(filtered_df['RSI'], errors='coerce')
            buy_signals = filtered_df['è¡ŒåŠ¨ä¿¡å·'].str.contains('ä¹°å…¥', na=False)
            filtered_df = filtered_df[(buy_signals) & (filtered_df['RSI_num'] < self.rsi_threshold)].drop(columns=['RSI_num'])
        # 'all' ä¸è¿‡æ»¤

        # å®šä¹‰æ’åºä¼˜å…ˆçº§
        order_map_action = {
            "å¼ºçƒˆå¼ºä¹°å…¥": 1,
            "å¼ºä¹°å…¥": 1,
            "å¼±ä¹°å…¥": 2,
            "æŒæœ‰/è§‚å¯Ÿ": 3,
            "å¼±å–å‡º/è§„é¿": 4,
            "å¼ºå–å‡º/è§„é¿": 5,
            "å¼ºçƒˆå¼ºå–å‡º/è§„é¿": 5,
            "N/A": 6
        }
        order_map_advice = {
            "å¼ºçƒˆåˆ†æ‰¹ä¹°å…¥": 1,
            "å¯åˆ†æ‰¹ä¹°å…¥": 1,
            "è§‚å¯Ÿ": 2,
            "ç­‰å¾…å›è°ƒ": 3,
            "å¼ºçƒˆç­‰å¾…å›è°ƒ": 3,
            "N/A": 4
        }
        
        filtered_df['sort_order_action'] = filtered_df['è¡ŒåŠ¨ä¿¡å·'].map(order_map_action)
        filtered_df['sort_order_advice'] = filtered_df['æŠ•èµ„å»ºè®®'].map(order_map_advice)
        
        # å°† NaN æ›¿æ¢ä¸º N/A å¹¶å¯¹å‡€å€¼ç­‰æ•°æ®ç±»å‹è¿›è¡Œå¤„ç†
        filtered_df['æœ€æ–°å‡€å€¼'] = pd.to_numeric(filtered_df['æœ€æ–°å‡€å€¼'], errors='coerce')
        filtered_df['RSI'] = pd.to_numeric(filtered_df['RSI'], errors='coerce')
        filtered_df['å‡€å€¼/MA50'] = pd.to_numeric(filtered_df['å‡€å€¼/MA50'], errors='coerce')

        # æŒ‰ç…§æ‚¨çš„æ–°æ’åºè§„åˆ™è¿›è¡Œæ’åº
        filtered_df = filtered_df.sort_values(
            by=['sort_order_action', 'sort_order_advice', 'RSI'],
            ascending=[True, True, True] # ä¼˜å…ˆæŒ‰è¡ŒåŠ¨ä¿¡å·ã€å…¶æ¬¡æŒ‰æŠ•èµ„å»ºè®®ã€æœ€åæŒ‰RSIä»ä½åˆ°é«˜æ’åº
        ).drop(columns=['sort_order_action', 'sort_order_advice'])

        # å°†æµ®ç‚¹æ•°æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸²ï¼Œæ–¹ä¾¿Markdownè¾“å‡º
        filtered_df['æœ€æ–°å‡€å€¼'] = filtered_df['æœ€æ–°å‡€å€¼'].apply(lambda x: f"{x:.4f}" if not pd.isna(x) else "N/A")
        filtered_df['RSI'] = filtered_df['RSI'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")
        filtered_df['å‡€å€¼/MA50'] = filtered_df['å‡€å€¼/MA50'].apply(lambda x: f"{x:.2f}" if not pd.isna(x) else "N/A")

        # æ–°å¢ï¼šç”Ÿæˆèµ„é‡‘åˆ†é…å»ºè®®
        total_budget = 5000  # å›ºå®šä¸º5000å…ƒé¢„ç®—
        max_positions = 3    # å›ºå®šä¸º3åªåŸºé‡‘
        scored_df, selected_funds = FundAllocator.suggest_portfolio(filtered_df, total_budget, max_positions)
        allocation_report = FundAllocator.generate_allocation_report(selected_funds, total_budget)

        # å°†ä¸Šè¿°æ’åºåçš„ DataFrame è½¬æ¢ä¸º Markdown
        markdown_table = filtered_df.to_markdown(index=False)
        
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(f"# å¸‚åœºæƒ…ç»ªä¸æŠ€æœ¯æŒ‡æ ‡ç›‘æ§æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## å¤§ç›˜è¶‹åŠ¿åˆ†æ\n")
            f.write(f"å¤§ç›˜ï¼ˆæ²ªæ·±300ï¼‰å½“å‰è¶‹åŠ¿: **{market_trend}**\n")
            f.write(f"**è¯´æ˜ï¼š** å†³ç­–å·²ç»“åˆå¤§ç›˜è¶‹åŠ¿è°ƒæ•´ï¼Œä¾‹å¦‚å¤§ç›˜å¼ºåŠ¿æ—¶åŠ å¼ºä¹°å…¥ä¿¡å·ã€‚\n\n")
            if self.holdings:
                f.write(f"**æŒä»“åŸºé‡‘ä¼˜å…ˆæ˜¾ç¤º**ï¼š{', '.join(self.holdings)}\n\n")
            if self.filter_mode != 'all':
                f.write(f"**è¿‡æ»¤æ¨¡å¼**ï¼š{self.filter_mode} (RSIé˜ˆå€¼: {self.rsi_threshold if self.rsi_threshold else 'N/A'})\n\n")
            f.write(f"## æ¨èåŸºé‡‘æŠ€æœ¯æŒ‡æ ‡ (å¤„ç†åŸºé‡‘æ•°: {len(filtered_df)} / åŸå§‹{len(report_df)})\n")
            f.write("æ­¤è¡¨æ ¼å·²æŒ‰**è¡ŒåŠ¨ä¿¡å·ä¼˜å…ˆçº§**æ’åºï¼Œ'å¼ºä¹°å…¥'åŸºé‡‘å°†æ’åœ¨æœ€å‰é¢ã€‚\n")
            f.write("**æ³¨æ„ï¼š** å½“'è¡ŒåŠ¨ä¿¡å·'å’Œ'æŠ•èµ„å»ºè®®'å†²çªæ—¶ï¼Œè¯·ä»¥**è¡ŒåŠ¨ä¿¡å·**ä¸ºå‡†ï¼Œå…¶æ¡ä»¶æ›´ä¸¥æ ¼ï¼Œæ›´é€‚åˆæœºæ¢°åŒ–å†³ç­–ã€‚\n\n")
            f.write(markdown_table)
            
            # æ·»åŠ èµ„é‡‘åˆ†é…å»ºè®®
            f.write("\n".join(allocation_report))
            f.write("\n\n")
            
            f.write("## ğŸ“‹ æ“ä½œå»ºè®®\n")
            f.write("""
### 1. **ç«‹å³è¡ŒåŠ¨** (é«˜ä¼˜å…ˆçº§)
- æŒ‰å»ºè®®é‡‘é¢åˆ†æ‰¹å»ºä»“å‰3åªåŸºé‡‘
- å»ºè®®å•ç¬”æŠ•èµ„ä¸è¶…è¿‡æ€»é¢„ç®—çš„30%

### 2. **é£é™©æ§åˆ¶**
- è®¾ç½®æ­¢æŸçº¿ï¼šä¹°å…¥åè·Œç ´MA50æ—¶å‡ä»“
- åŠ¨æ€è°ƒæ•´ï¼šæ¯å‘¨å¤ç›˜æŠ€æœ¯ä¿¡å·å˜åŒ–

### 3. **èµ„é‡‘ç®¡ç†**
- ä¿æŒç°é‡‘å‚¨å¤‡20-30%ç”¨äºåç»­æœºä¼š
- é¿å…è¿½é«˜ï¼Œå…³æ³¨RSI<40çš„ä½ä½ä¹°å…¥æœºä¼š

**âš ï¸ å…è´£å£°æ˜**: æœ¬æŠ¥å‘Šä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…ã€‚
            """)
        
        logger.info("æŠ¥å‘Šç”Ÿæˆå®Œæˆ: %s (è¿‡æ»¤ååŸºé‡‘æ•°: %d, å»ºè®®ä»“ä½: %dåª)", self.output_file, len(filtered_df), len(selected_funds))


if __name__ == "__main__":
    try:
        logger.info("è„šæœ¬å¯åŠ¨")
        # ç¤ºä¾‹ï¼šä½¿ç”¨è¿‡æ»¤æ¨¡å¼ï¼Œåªæ˜¾ç¤ºå¼ºä¹°å…¥ï¼Œé¢„ç®—5000å…ƒï¼Œæœ€å¤š3åªä»“ä½
        monitor = MarketMonitor(
            filter_mode='strong_buy', 
            holdings=['005118']  # å¦‚æœä½ å·²æœ‰æŒä»“
        )
        monitor.get_fund_data()
        monitor.generate_report()
        logger.info("è„šæœ¬æ‰§è¡Œå®Œæˆ")
        print(f"\nğŸ’° åŸºäº5000å…ƒé¢„ç®—ï¼Œå»ºè®®æŠ•èµ„3åªåŸºé‡‘")
        print("ğŸ“„ è¯¦ç»†åˆ†é…æ–¹æ¡ˆè¯·æŸ¥çœ‹ market_monitor_report.md")
    except Exception as e:
        logger.error("è„šæœ¬è¿è¡Œå¤±è´¥: %s", e, exc_info=True)
        raise
